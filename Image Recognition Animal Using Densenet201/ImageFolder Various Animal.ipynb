{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import statistics as st\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cane',\n",
       " 'cavallo',\n",
       " 'elefante',\n",
       " 'farfalla',\n",
       " 'gallina',\n",
       " 'gatto',\n",
       " 'mucca',\n",
       " 'pecora',\n",
       " 'ragno',\n",
       " 'scoiattolo']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = \"Various Animal\"\n",
    "os.listdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforming = transforms.Compose([transforms.Resize(256),\n",
    "                                   transforms.CenterCrop(225),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                                                       std=[0.229,0.224,0.225])\n",
    "                                   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26179"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = ImageFolder(root = os.path.join(root_dir),transform = transforming)\n",
    "len(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cane', 'cavallo', 'elefante', 'farfalla', 'gallina', 'gatto', 'mucca', 'pecora', 'ragno', 'scoiattolo']\n",
      "{'cane': 0, 'cavallo': 1, 'elefante': 2, 'farfalla': 3, 'gallina': 4, 'gatto': 5, 'mucca': 6, 'pecora': 7, 'ragno': 8, 'scoiattolo': 9}\n"
     ]
    }
   ],
   "source": [
    "# n=0\n",
    "# while n<20:\n",
    "#     print(total_data[n][1])\n",
    "#     n+=1\n",
    "\n",
    "print(total_data.classes)\n",
    "print(total_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x281b8ef2f88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.transpose(total_data[0][0],(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 22000\n",
    "test = len(total_data)-train\n",
    "\n",
    "training,testing = torch.utils.data.random_split(total_data,[train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=20\n",
    "training_data = DataLoader(training,batch_size=batch_size,shuffle=False,num_workers=1,pin_memory=True)\n",
    "testing_data = DataLoader(testing,batch_size=batch_size,shuffle=False,num_workers=1,pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 225, 225])\n",
      "tensor([4, 0, 8, 1, 0, 8, 8, 8, 1, 5, 2, 5, 7, 6, 2, 3, 2, 8, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "for x,y in training_data:\n",
    "    print(x.shape)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlexNet',\n",
       " 'DenseNet',\n",
       " 'GoogLeNet',\n",
       " 'GoogLeNetOutputs',\n",
       " 'Inception3',\n",
       " 'InceptionOutputs',\n",
       " 'MNASNet',\n",
       " 'MobileNetV2',\n",
       " 'ResNet',\n",
       " 'ShuffleNetV2',\n",
       " 'SqueezeNet',\n",
       " 'VGG',\n",
       " '_GoogLeNetOutputs',\n",
       " '_InceptionOutputs',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_utils',\n",
       " 'alexnet',\n",
       " 'densenet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'detection',\n",
       " 'googlenet',\n",
       " 'inception',\n",
       " 'inception_v3',\n",
       " 'mnasnet',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet',\n",
       " 'mobilenet_v2',\n",
       " 'quantization',\n",
       " 'resnet',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext50_32x4d',\n",
       " 'segmentation',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'shufflenetv2',\n",
       " 'squeezenet',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'utils',\n",
       " 'vgg',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'video',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model for model in dir(models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer25): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer26): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer27): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer28): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer29): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer30): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer31): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer32): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer33): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer34): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer35): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer36): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer37): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer38): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer39): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer40): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer41): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer42): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer43): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer44): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer45): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer46): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer47): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer48): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer25): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer26): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer27): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer28): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer29): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer30): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer31): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer32): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1920, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "den = models.densenet201(pretrained=True)\n",
    "for para in den.parameters():\n",
    "    para.require_grad=False\n",
    "\n",
    "#check den structure\n",
    "den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mynetwork(\n",
       "  (network): Sequential(\n",
       "    (0): DenseNet(\n",
       "      (features): Sequential(\n",
       "        (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu0): ReLU(inplace=True)\n",
       "        (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (denseblock1): _DenseBlock(\n",
       "          (denselayer1): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer2): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer3): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer4): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer5): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer6): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (transition1): _Transition(\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (denseblock2): _DenseBlock(\n",
       "          (denselayer1): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer2): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer3): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer4): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer5): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer6): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer7): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer8): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer9): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer10): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer11): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer12): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (transition2): _Transition(\n",
       "          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (denseblock3): _DenseBlock(\n",
       "          (denselayer1): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer2): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer3): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer4): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer5): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer6): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer7): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer8): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer9): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer10): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer11): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer12): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer13): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer14): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer15): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer16): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer17): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer18): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer19): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer20): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer21): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer22): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer23): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer24): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer25): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer26): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer27): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer28): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer29): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer30): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer31): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer32): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer33): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer34): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer35): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer36): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer37): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer38): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer39): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer40): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer41): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer42): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer43): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer44): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer45): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer46): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer47): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer48): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (transition3): _Transition(\n",
       "          (norm): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv): Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (denseblock4): _DenseBlock(\n",
       "          (denselayer1): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer2): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer3): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer4): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer5): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer6): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer7): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer8): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer9): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer10): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer11): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer12): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer13): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer14): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer15): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer16): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer17): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer18): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer19): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer20): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer21): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer22): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer23): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer24): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer25): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer26): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer27): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer28): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer29): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer30): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer31): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "          (denselayer32): _DenseLayer(\n",
       "            (norm1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu1): ReLU(inplace=True)\n",
       "            (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu2): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (norm5): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (classifier): Linear(in_features=1920, out_features=1000, bias=True)\n",
       "    )\n",
       "    (1): Linear(in_features=1000, out_features=500, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=500, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class mynetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(den.train(),\n",
    "                                    nn.Linear(1000,500),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(500,10))\n",
    "    def forward(self,x):\n",
    "        return self.network(x)\n",
    "model = mynetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = F.cross_entropy\n",
    "opi = torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini batch accuracy:0.6 and loss 1.3229529857635498\n",
      "mini batch accuracy:0.5 and loss 1.5113564729690552\n",
      "mini batch accuracy:0.6 and loss 1.06233811378479\n",
      "mini batch accuracy:0.65 and loss 1.1962049007415771\n",
      "mini batch accuracy:0.45 and loss 1.2870802879333496\n",
      "mini batch accuracy:0.6 and loss 1.225564956665039\n",
      "mini batch accuracy:0.65 and loss 1.1392467021942139\n",
      "mini batch accuracy:0.65 and loss 1.1259948015213013\n",
      "mini batch accuracy:0.45 and loss 1.3881033658981323\n",
      "mini batch accuracy:0.65 and loss 1.005366563796997\n",
      "mini batch accuracy:0.5 and loss 1.4951226711273193\n",
      "mini batch accuracy:0.85 and loss 0.6796962022781372\n",
      "mini batch accuracy:0.65 and loss 1.2047375440597534\n",
      "mini batch accuracy:0.7 and loss 0.9112194180488586\n",
      "mini batch accuracy:0.8 and loss 0.9326197504997253\n",
      "mini batch accuracy:0.45 and loss 2.032240629196167\n",
      "mini batch accuracy:0.55 and loss 1.1708557605743408\n",
      "mini batch accuracy:0.75 and loss 1.175126314163208\n",
      "mini batch accuracy:0.65 and loss 1.1578881740570068\n",
      "mini batch accuracy:0.8 and loss 0.5916175842285156\n",
      "mini batch accuracy:0.65 and loss 1.148772954940796\n",
      "mini batch accuracy:0.75 and loss 1.1216695308685303\n",
      "mini batch accuracy:0.4 and loss 1.992889642715454\n",
      "mini batch accuracy:0.7 and loss 0.9559600949287415\n",
      "mini batch accuracy:0.6 and loss 1.1144219636917114\n",
      "mini batch accuracy:0.65 and loss 1.041931390762329\n",
      "mini batch accuracy:0.85 and loss 0.5901771187782288\n",
      "mini batch accuracy:0.7 and loss 0.9102182388305664\n",
      "mini batch accuracy:0.7 and loss 0.8735896944999695\n",
      "mini batch accuracy:0.65 and loss 1.026341438293457\n",
      "mini batch accuracy:0.7 and loss 0.9605180025100708\n",
      "mini batch accuracy:0.8 and loss 0.7279483675956726\n",
      "mini batch accuracy:0.7 and loss 1.0387330055236816\n",
      "mini batch accuracy:0.6 and loss 0.8395448923110962\n",
      "mini batch accuracy:0.85 and loss 0.48341646790504456\n",
      "mini batch accuracy:0.6 and loss 1.2171930074691772\n",
      "mini batch accuracy:0.75 and loss 1.1306568384170532\n",
      "mini batch accuracy:0.8 and loss 0.6271500587463379\n",
      "mini batch accuracy:0.9 and loss 0.27562662959098816\n",
      "mini batch accuracy:0.75 and loss 0.7418310046195984\n",
      "mini batch accuracy:0.75 and loss 0.6829347610473633\n",
      "mini batch accuracy:0.6 and loss 1.6053762435913086\n",
      "mini batch accuracy:0.8 and loss 0.8551534414291382\n",
      "mini batch accuracy:0.7 and loss 0.6401487588882446\n",
      "mini batch accuracy:0.75 and loss 0.878596305847168\n",
      "mini batch accuracy:0.75 and loss 0.6552775502204895\n",
      "mini batch accuracy:0.65 and loss 1.1203348636627197\n",
      "mini batch accuracy:0.55 and loss 1.274390697479248\n",
      "mini batch accuracy:0.55 and loss 1.8341861963272095\n",
      "mini batch accuracy:0.75 and loss 0.8458312749862671\n",
      "mini batch accuracy:0.65 and loss 1.2658555507659912\n",
      "mini batch accuracy:0.85 and loss 0.5589512586593628\n",
      "mini batch accuracy:0.8 and loss 0.8541792631149292\n",
      "mini batch accuracy:0.85 and loss 0.7046626210212708\n",
      "mini batch accuracy:0.95 and loss 0.3174874186515808\n",
      "mini batch accuracy:0.7 and loss 0.8950420618057251\n",
      "mini batch accuracy:0.85 and loss 0.6022184491157532\n",
      "mini batch accuracy:0.75 and loss 0.8175725936889648\n",
      "mini batch accuracy:0.4 and loss 1.618354082107544\n",
      "mini batch accuracy:0.85 and loss 0.8825279474258423\n",
      "mini batch accuracy:0.9 and loss 0.5195282101631165\n",
      "mini batch accuracy:0.85 and loss 0.5188606977462769\n",
      "mini batch accuracy:0.85 and loss 0.6822986006736755\n",
      "mini batch accuracy:0.85 and loss 0.4886476397514343\n",
      "mini batch accuracy:0.75 and loss 0.5755696296691895\n",
      "mini batch accuracy:0.85 and loss 0.7497483491897583\n",
      "mini batch accuracy:0.75 and loss 0.577830970287323\n",
      "mini batch accuracy:0.75 and loss 0.8111497759819031\n",
      "mini batch accuracy:0.6 and loss 1.2723829746246338\n",
      "mini batch accuracy:0.65 and loss 1.137908935546875\n",
      "mini batch accuracy:0.85 and loss 0.6567034721374512\n",
      "mini batch accuracy:0.7 and loss 0.7196436524391174\n",
      "mini batch accuracy:1.0 and loss 0.2870178818702698\n",
      "mini batch accuracy:0.75 and loss 0.8743427395820618\n",
      "mini batch accuracy:0.65 and loss 0.8374870419502258\n",
      "mini batch accuracy:0.8 and loss 0.6248583197593689\n",
      "mini batch accuracy:0.75 and loss 0.5758717656135559\n",
      "mini batch accuracy:0.85 and loss 0.6005562543869019\n",
      "mini batch accuracy:0.65 and loss 1.1008152961730957\n",
      "mini batch accuracy:0.85 and loss 0.690676748752594\n",
      "mini batch accuracy:0.75 and loss 0.7552642822265625\n",
      "mini batch accuracy:0.6 and loss 1.4229793548583984\n",
      "mini batch accuracy:0.75 and loss 0.8122347593307495\n",
      "mini batch accuracy:0.55 and loss 1.4949994087219238\n",
      "mini batch accuracy:0.65 and loss 0.893179714679718\n",
      "mini batch accuracy:0.75 and loss 0.836932361125946\n",
      "mini batch accuracy:0.75 and loss 0.8500138521194458\n",
      "mini batch accuracy:0.7 and loss 0.773321270942688\n",
      "mini batch accuracy:0.75 and loss 0.9711141586303711\n",
      "mini batch accuracy:0.85 and loss 0.7189417481422424\n",
      "mini batch accuracy:0.75 and loss 1.0744942426681519\n",
      "mini batch accuracy:0.65 and loss 1.3013519048690796\n",
      "mini batch accuracy:0.5 and loss 1.1711469888687134\n",
      "mini batch accuracy:0.85 and loss 0.4615640640258789\n",
      "mini batch accuracy:0.75 and loss 0.702396035194397\n",
      "mini batch accuracy:0.8 and loss 0.5396862030029297\n",
      "mini batch accuracy:0.8 and loss 0.7648005485534668\n",
      "mini batch accuracy:0.7 and loss 0.8174785375595093\n",
      "mini batch accuracy:0.7 and loss 0.8559261560440063\n",
      "mini batch accuracy:0.75 and loss 0.7619792819023132\n",
      "mini batch accuracy:0.75 and loss 0.6309273838996887\n",
      "mini batch accuracy:0.9 and loss 0.44344693422317505\n",
      "mini batch accuracy:0.8 and loss 0.7825645804405212\n",
      "mini batch accuracy:0.8 and loss 0.5231863856315613\n",
      "mini batch accuracy:0.6 and loss 0.7882710695266724\n",
      "mini batch accuracy:0.75 and loss 0.4874296188354492\n",
      "mini batch accuracy:0.85 and loss 0.4517812132835388\n",
      "mini batch accuracy:0.85 and loss 0.4318580627441406\n",
      "mini batch accuracy:0.75 and loss 0.796979546546936\n",
      "mini batch accuracy:0.6 and loss 1.2891274690628052\n",
      "Epoch [1/10] with accuracy of0.7087272727272728 and loss1.2891274690628052\n",
      "mini batch accuracy:0.95 and loss 0.35879436135292053\n",
      "mini batch accuracy:0.75 and loss 0.989777684211731\n",
      "mini batch accuracy:0.8 and loss 0.6079634428024292\n",
      "mini batch accuracy:0.85 and loss 0.5062915682792664\n",
      "mini batch accuracy:0.65 and loss 1.0284650325775146\n",
      "mini batch accuracy:0.7 and loss 0.7958115339279175\n",
      "mini batch accuracy:0.85 and loss 0.384745329618454\n",
      "mini batch accuracy:0.85 and loss 0.4018878936767578\n",
      "mini batch accuracy:0.85 and loss 0.9296960830688477\n",
      "mini batch accuracy:0.75 and loss 0.6445838809013367\n",
      "mini batch accuracy:0.6 and loss 1.249886155128479\n",
      "mini batch accuracy:0.95 and loss 0.195596843957901\n",
      "mini batch accuracy:0.8 and loss 0.6001955270767212\n",
      "mini batch accuracy:0.85 and loss 0.5497204661369324\n",
      "mini batch accuracy:0.9 and loss 0.2700275778770447\n",
      "mini batch accuracy:0.85 and loss 0.6452540159225464\n",
      "mini batch accuracy:0.75 and loss 0.6821908950805664\n",
      "mini batch accuracy:0.9 and loss 0.3383152186870575\n",
      "mini batch accuracy:0.75 and loss 0.6407693028450012\n",
      "mini batch accuracy:0.9 and loss 0.3975113034248352\n",
      "mini batch accuracy:0.65 and loss 1.0653260946273804\n",
      "mini batch accuracy:0.7 and loss 0.9315671920776367\n",
      "mini batch accuracy:0.65 and loss 1.4491918087005615\n",
      "mini batch accuracy:0.85 and loss 0.5458629727363586\n",
      "mini batch accuracy:0.95 and loss 0.44589003920555115\n",
      "mini batch accuracy:0.85 and loss 0.6546208262443542\n",
      "mini batch accuracy:0.75 and loss 0.7250781655311584\n",
      "mini batch accuracy:0.7 and loss 0.9110990762710571\n",
      "mini batch accuracy:0.8 and loss 0.5930466055870056\n",
      "mini batch accuracy:0.85 and loss 0.5159362554550171\n",
      "mini batch accuracy:0.95 and loss 0.41403040289878845\n",
      "mini batch accuracy:0.85 and loss 0.37630146741867065\n",
      "mini batch accuracy:0.75 and loss 0.7241336703300476\n",
      "mini batch accuracy:0.8 and loss 0.671988844871521\n",
      "mini batch accuracy:0.85 and loss 0.6071540117263794\n",
      "mini batch accuracy:0.8 and loss 0.7978561520576477\n",
      "mini batch accuracy:0.7 and loss 1.020471215248108\n",
      "mini batch accuracy:0.9 and loss 0.3493664860725403\n",
      "mini batch accuracy:0.95 and loss 0.19502033293247223\n",
      "mini batch accuracy:0.75 and loss 1.069982886314392\n",
      "mini batch accuracy:0.9 and loss 0.383270800113678\n",
      "mini batch accuracy:0.7 and loss 0.7827948331832886\n",
      "mini batch accuracy:0.95 and loss 0.41128501296043396\n",
      "mini batch accuracy:0.8 and loss 0.4223513603210449\n",
      "mini batch accuracy:0.8 and loss 0.4542964994907379\n",
      "mini batch accuracy:0.85 and loss 0.4959734082221985\n",
      "mini batch accuracy:0.8 and loss 0.6395207643508911\n",
      "mini batch accuracy:0.7 and loss 0.9691109657287598\n",
      "mini batch accuracy:0.6 and loss 1.0138601064682007\n",
      "mini batch accuracy:0.9 and loss 0.34532812237739563\n",
      "mini batch accuracy:0.9 and loss 0.5469992160797119\n",
      "mini batch accuracy:0.9 and loss 0.39388373494148254\n",
      "mini batch accuracy:0.8 and loss 0.8243702054023743\n",
      "mini batch accuracy:0.7 and loss 0.7761580944061279\n",
      "mini batch accuracy:1.0 and loss 0.15738271176815033\n",
      "mini batch accuracy:0.8 and loss 0.677006721496582\n",
      "mini batch accuracy:0.85 and loss 0.37370532751083374\n",
      "mini batch accuracy:0.75 and loss 0.8962820172309875\n",
      "mini batch accuracy:0.65 and loss 1.0743687152862549\n",
      "mini batch accuracy:0.85 and loss 0.46170854568481445\n",
      "mini batch accuracy:0.9 and loss 0.459627628326416\n",
      "mini batch accuracy:0.85 and loss 0.5515660643577576\n",
      "mini batch accuracy:0.9 and loss 0.3111392855644226\n",
      "mini batch accuracy:0.75 and loss 0.6998856067657471\n",
      "mini batch accuracy:0.95 and loss 0.34646734595298767\n",
      "mini batch accuracy:0.8 and loss 0.7075352668762207\n",
      "mini batch accuracy:0.85 and loss 0.3383388817310333\n",
      "mini batch accuracy:0.75 and loss 0.5624539852142334\n",
      "mini batch accuracy:0.6 and loss 1.3066308498382568\n",
      "mini batch accuracy:0.5 and loss 1.1592185497283936\n",
      "mini batch accuracy:0.8 and loss 0.6984755396842957\n",
      "mini batch accuracy:0.95 and loss 0.3550064265727997\n",
      "mini batch accuracy:1.0 and loss 0.07182322442531586\n",
      "mini batch accuracy:0.9 and loss 0.4768214225769043\n",
      "mini batch accuracy:0.9 and loss 0.6384272575378418\n",
      "mini batch accuracy:0.8 and loss 0.576084554195404\n",
      "mini batch accuracy:0.9 and loss 0.32388338446617126\n",
      "mini batch accuracy:0.8 and loss 0.5565868020057678\n",
      "mini batch accuracy:0.8 and loss 0.7562687993049622\n",
      "mini batch accuracy:0.75 and loss 0.5491249561309814\n",
      "mini batch accuracy:0.75 and loss 0.7563890218734741\n",
      "mini batch accuracy:0.75 and loss 0.7203583121299744\n",
      "mini batch accuracy:0.9 and loss 0.38777652382850647\n",
      "mini batch accuracy:0.7 and loss 1.0872886180877686\n",
      "mini batch accuracy:0.8 and loss 0.42767134308815\n",
      "mini batch accuracy:0.75 and loss 0.5287492275238037\n",
      "mini batch accuracy:0.85 and loss 0.5318719148635864\n",
      "mini batch accuracy:0.95 and loss 0.2637859582901001\n",
      "mini batch accuracy:0.85 and loss 0.5091849565505981\n",
      "mini batch accuracy:0.85 and loss 0.36926501989364624\n",
      "mini batch accuracy:0.95 and loss 0.6144832372665405\n",
      "mini batch accuracy:0.7 and loss 0.904401957988739\n",
      "mini batch accuracy:0.55 and loss 1.0023164749145508\n",
      "mini batch accuracy:0.8 and loss 0.5415163040161133\n",
      "mini batch accuracy:0.9 and loss 0.49137410521507263\n",
      "mini batch accuracy:0.85 and loss 0.4061073362827301\n",
      "mini batch accuracy:0.9 and loss 0.18992748856544495\n",
      "mini batch accuracy:0.7 and loss 0.9625037908554077\n",
      "mini batch accuracy:0.7 and loss 0.9034152030944824\n",
      "mini batch accuracy:0.95 and loss 0.2505141794681549\n",
      "mini batch accuracy:0.85 and loss 0.4228377342224121\n",
      "mini batch accuracy:0.9 and loss 0.1994738131761551\n",
      "mini batch accuracy:0.75 and loss 0.5556162595748901\n",
      "mini batch accuracy:0.8 and loss 0.6253926753997803\n",
      "mini batch accuracy:0.75 and loss 0.5987157225608826\n",
      "mini batch accuracy:0.65 and loss 0.7583370208740234\n",
      "mini batch accuracy:0.9 and loss 0.29344162344932556\n",
      "mini batch accuracy:0.9 and loss 0.27324604988098145\n",
      "mini batch accuracy:0.75 and loss 0.6958757638931274\n",
      "mini batch accuracy:0.7 and loss 0.7279517650604248\n",
      "Epoch [2/10] with accuracy of0.8105454545454546 and loss0.7279517650604248\n",
      "mini batch accuracy:0.9 and loss 0.35310012102127075\n",
      "mini batch accuracy:0.65 and loss 1.2307900190353394\n",
      "mini batch accuracy:0.85 and loss 0.4608075022697449\n",
      "mini batch accuracy:0.75 and loss 0.8342603445053101\n",
      "mini batch accuracy:0.75 and loss 0.8672895431518555\n",
      "mini batch accuracy:0.8 and loss 0.6235677599906921\n",
      "mini batch accuracy:0.9 and loss 0.47290652990341187\n",
      "mini batch accuracy:0.85 and loss 0.326829731464386\n",
      "mini batch accuracy:0.9 and loss 0.35377585887908936\n",
      "mini batch accuracy:0.9 and loss 0.40808171033859253\n",
      "mini batch accuracy:0.95 and loss 0.32802024483680725\n",
      "mini batch accuracy:1.0 and loss 0.059634238481521606\n",
      "mini batch accuracy:0.75 and loss 0.5617451071739197\n",
      "mini batch accuracy:0.9 and loss 0.33092811703681946\n",
      "mini batch accuracy:0.85 and loss 0.6460806727409363\n",
      "mini batch accuracy:0.8 and loss 0.5173455476760864\n",
      "mini batch accuracy:0.85 and loss 0.49151745438575745\n",
      "mini batch accuracy:0.9 and loss 0.15217287838459015\n",
      "mini batch accuracy:0.9 and loss 0.4243277609348297\n",
      "mini batch accuracy:0.9 and loss 0.3903130888938904\n",
      "mini batch accuracy:0.8 and loss 0.47515612840652466\n",
      "mini batch accuracy:0.85 and loss 0.5423197746276855\n",
      "mini batch accuracy:0.8 and loss 0.6840208172798157\n",
      "mini batch accuracy:0.95 and loss 0.3688657879829407\n",
      "mini batch accuracy:0.95 and loss 0.21606433391571045\n",
      "mini batch accuracy:0.95 and loss 0.1831299513578415\n",
      "mini batch accuracy:0.85 and loss 0.42841386795043945\n",
      "mini batch accuracy:0.85 and loss 0.2276683747768402\n",
      "mini batch accuracy:0.85 and loss 0.37939971685409546\n",
      "mini batch accuracy:0.9 and loss 0.36383843421936035\n",
      "mini batch accuracy:0.9 and loss 0.30342400074005127\n",
      "mini batch accuracy:0.8 and loss 0.40906038880348206\n",
      "mini batch accuracy:0.75 and loss 0.5474351048469543\n",
      "mini batch accuracy:0.85 and loss 0.41603630781173706\n",
      "mini batch accuracy:0.9 and loss 0.2869417667388916\n",
      "mini batch accuracy:0.8 and loss 0.7304047346115112\n",
      "mini batch accuracy:0.65 and loss 0.5911831855773926\n",
      "mini batch accuracy:0.95 and loss 0.2640813887119293\n",
      "mini batch accuracy:0.85 and loss 0.2352941334247589\n",
      "mini batch accuracy:0.75 and loss 0.6376105546951294\n",
      "mini batch accuracy:0.9 and loss 0.3824763894081116\n",
      "mini batch accuracy:0.7 and loss 1.2215629816055298\n",
      "mini batch accuracy:0.9 and loss 0.24106959998607635\n",
      "mini batch accuracy:0.8 and loss 0.6393702626228333\n",
      "mini batch accuracy:0.9 and loss 0.34164103865623474\n",
      "mini batch accuracy:1.0 and loss 0.19757893681526184\n",
      "mini batch accuracy:0.9 and loss 0.33548298478126526\n",
      "mini batch accuracy:0.95 and loss 0.4022389352321625\n",
      "mini batch accuracy:0.8 and loss 0.5886603593826294\n",
      "mini batch accuracy:0.9 and loss 0.2658975422382355\n",
      "mini batch accuracy:0.9 and loss 0.5519204139709473\n",
      "mini batch accuracy:1.0 and loss 0.16346247494220734\n",
      "mini batch accuracy:0.95 and loss 0.1936069279909134\n",
      "mini batch accuracy:0.85 and loss 0.3336668908596039\n",
      "mini batch accuracy:1.0 and loss 0.10337983071804047\n",
      "mini batch accuracy:0.9 and loss 0.48470544815063477\n",
      "mini batch accuracy:0.95 and loss 0.1712406724691391\n",
      "mini batch accuracy:0.75 and loss 0.5553326606750488\n",
      "mini batch accuracy:0.75 and loss 1.074912428855896\n",
      "mini batch accuracy:0.75 and loss 0.7971552610397339\n",
      "mini batch accuracy:0.95 and loss 0.2518715262413025\n",
      "mini batch accuracy:0.9 and loss 0.23429016768932343\n",
      "mini batch accuracy:0.9 and loss 0.2882509231567383\n",
      "mini batch accuracy:0.85 and loss 0.3730839788913727\n",
      "mini batch accuracy:0.8 and loss 0.4159793257713318\n",
      "mini batch accuracy:0.9 and loss 0.3953031897544861\n",
      "mini batch accuracy:0.85 and loss 0.6834737658500671\n",
      "mini batch accuracy:0.9 and loss 0.4060012400150299\n",
      "mini batch accuracy:0.65 and loss 1.0432958602905273\n",
      "mini batch accuracy:0.8 and loss 0.6002628207206726\n",
      "mini batch accuracy:0.95 and loss 0.20341220498085022\n",
      "mini batch accuracy:0.9 and loss 0.4696715772151947\n",
      "mini batch accuracy:1.0 and loss 0.026484763249754906\n",
      "mini batch accuracy:0.8 and loss 0.6475045680999756\n",
      "mini batch accuracy:0.95 and loss 0.34517866373062134\n",
      "mini batch accuracy:0.95 and loss 0.2733606994152069\n",
      "mini batch accuracy:1.0 and loss 0.14627185463905334\n",
      "mini batch accuracy:0.85 and loss 0.33950233459472656\n",
      "mini batch accuracy:0.75 and loss 0.841934084892273\n",
      "mini batch accuracy:0.95 and loss 0.2890762984752655\n",
      "mini batch accuracy:0.75 and loss 0.4706459641456604\n",
      "mini batch accuracy:0.7 and loss 1.0309035778045654\n",
      "mini batch accuracy:0.85 and loss 0.652133584022522\n",
      "mini batch accuracy:0.75 and loss 0.9294816255569458\n",
      "mini batch accuracy:0.85 and loss 0.42327386140823364\n",
      "mini batch accuracy:0.85 and loss 0.3875848352909088\n",
      "mini batch accuracy:0.85 and loss 0.35959452390670776\n",
      "mini batch accuracy:0.9 and loss 0.398738831281662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini batch accuracy:0.7 and loss 0.86836177110672\n",
      "mini batch accuracy:0.9 and loss 0.3633875548839569\n",
      "mini batch accuracy:0.85 and loss 0.7409180402755737\n",
      "mini batch accuracy:0.75 and loss 0.5630297660827637\n",
      "mini batch accuracy:0.7 and loss 0.9905509948730469\n",
      "mini batch accuracy:0.95 and loss 0.19862782955169678\n",
      "mini batch accuracy:0.95 and loss 0.5009066462516785\n",
      "mini batch accuracy:0.85 and loss 0.44073963165283203\n",
      "mini batch accuracy:1.0 and loss 0.07523348927497864\n",
      "mini batch accuracy:0.8 and loss 0.5858438014984131\n",
      "mini batch accuracy:0.75 and loss 0.6577595472335815\n",
      "mini batch accuracy:0.8 and loss 0.3121017515659332\n",
      "mini batch accuracy:0.85 and loss 0.4808010160923004\n",
      "mini batch accuracy:1.0 and loss 0.14838381111621857\n",
      "mini batch accuracy:0.95 and loss 0.1509469449520111\n",
      "mini batch accuracy:0.8 and loss 0.6434059143066406\n",
      "mini batch accuracy:0.7 and loss 0.5843900442123413\n",
      "mini batch accuracy:1.0 and loss 0.09743712842464447\n",
      "mini batch accuracy:0.9 and loss 0.4012550413608551\n",
      "mini batch accuracy:0.9 and loss 0.1394285410642624\n",
      "mini batch accuracy:0.85 and loss 0.6077388525009155\n",
      "mini batch accuracy:0.8 and loss 0.6401259899139404\n",
      "Epoch [3/10] with accuracy of0.8547272727272728 and loss0.6401259899139404\n",
      "mini batch accuracy:0.9 and loss 0.2303708791732788\n",
      "mini batch accuracy:0.75 and loss 0.7515898942947388\n",
      "mini batch accuracy:0.9 and loss 0.2648885250091553\n",
      "mini batch accuracy:0.95 and loss 0.23044314980506897\n",
      "mini batch accuracy:0.85 and loss 0.41128841042518616\n",
      "mini batch accuracy:0.6 and loss 0.8664180040359497\n",
      "mini batch accuracy:0.65 and loss 0.787186324596405\n",
      "mini batch accuracy:0.9 and loss 0.2786885201931\n",
      "mini batch accuracy:0.9 and loss 0.44424551725387573\n",
      "mini batch accuracy:0.95 and loss 0.1797109842300415\n",
      "mini batch accuracy:0.9 and loss 0.4312565326690674\n",
      "mini batch accuracy:1.0 and loss 0.03352760151028633\n",
      "mini batch accuracy:0.9 and loss 0.19656528532505035\n",
      "mini batch accuracy:0.85 and loss 0.4585198760032654\n",
      "mini batch accuracy:0.95 and loss 0.39140239357948303\n",
      "mini batch accuracy:0.95 and loss 0.4301684498786926\n",
      "mini batch accuracy:1.0 and loss 0.14472034573554993\n",
      "mini batch accuracy:1.0 and loss 0.16363821923732758\n",
      "mini batch accuracy:0.9 and loss 0.45888200402259827\n",
      "mini batch accuracy:0.9 and loss 0.4180048108100891\n",
      "mini batch accuracy:0.85 and loss 0.3748742341995239\n",
      "mini batch accuracy:0.85 and loss 0.3905044496059418\n",
      "mini batch accuracy:0.85 and loss 0.4653249680995941\n",
      "mini batch accuracy:0.9 and loss 0.30305665731430054\n",
      "mini batch accuracy:0.9 and loss 0.1999177187681198\n",
      "mini batch accuracy:1.0 and loss 0.14050327241420746\n",
      "mini batch accuracy:0.8 and loss 0.3548281788825989\n",
      "mini batch accuracy:0.9 and loss 0.2328524887561798\n",
      "mini batch accuracy:0.85 and loss 0.5162695050239563\n",
      "mini batch accuracy:0.9 and loss 0.304322212934494\n",
      "mini batch accuracy:1.0 and loss 0.09673391282558441\n",
      "mini batch accuracy:0.9 and loss 0.18647319078445435\n",
      "mini batch accuracy:0.85 and loss 0.3726697266101837\n",
      "mini batch accuracy:0.95 and loss 0.1792304962873459\n",
      "mini batch accuracy:0.95 and loss 0.12236376106739044\n",
      "mini batch accuracy:0.9 and loss 0.3173561692237854\n",
      "mini batch accuracy:0.9 and loss 0.31347838044166565\n",
      "mini batch accuracy:0.9 and loss 0.1576230823993683\n",
      "mini batch accuracy:0.95 and loss 0.13745401799678802\n",
      "mini batch accuracy:0.95 and loss 0.31096845865249634\n",
      "mini batch accuracy:0.85 and loss 0.38985711336135864\n",
      "mini batch accuracy:0.55 and loss 1.2920315265655518\n",
      "mini batch accuracy:0.9 and loss 0.32632356882095337\n",
      "mini batch accuracy:0.9 and loss 0.43551477789878845\n",
      "mini batch accuracy:0.8 and loss 0.4615711271762848\n",
      "mini batch accuracy:0.85 and loss 0.31652915477752686\n",
      "mini batch accuracy:0.9 and loss 0.3327597677707672\n",
      "mini batch accuracy:0.8 and loss 0.6449170708656311\n",
      "mini batch accuracy:0.85 and loss 0.5743366479873657\n",
      "mini batch accuracy:0.95 and loss 0.09639307111501694\n",
      "mini batch accuracy:0.85 and loss 0.5106817483901978\n",
      "mini batch accuracy:1.0 and loss 0.05448053032159805\n",
      "mini batch accuracy:0.95 and loss 0.43902772665023804\n",
      "mini batch accuracy:0.85 and loss 0.31053248047828674\n",
      "mini batch accuracy:0.95 and loss 0.09139001369476318\n",
      "mini batch accuracy:0.8 and loss 0.44362273812294006\n",
      "mini batch accuracy:0.95 and loss 0.214115172624588\n",
      "mini batch accuracy:0.85 and loss 0.3216424584388733\n",
      "mini batch accuracy:0.7 and loss 1.2741296291351318\n",
      "mini batch accuracy:0.85 and loss 0.4446028769016266\n",
      "mini batch accuracy:1.0 and loss 0.0761338323354721\n",
      "mini batch accuracy:0.95 and loss 0.20249100029468536\n",
      "mini batch accuracy:1.0 and loss 0.08460143208503723\n",
      "mini batch accuracy:1.0 and loss 0.1809021681547165\n",
      "mini batch accuracy:1.0 and loss 0.1296537071466446\n",
      "mini batch accuracy:0.85 and loss 0.4031291902065277\n",
      "mini batch accuracy:0.85 and loss 0.3081358075141907\n",
      "mini batch accuracy:0.85 and loss 0.45269331336021423\n",
      "mini batch accuracy:0.75 and loss 0.747001051902771\n",
      "mini batch accuracy:0.9 and loss 0.4085818827152252\n",
      "mini batch accuracy:0.95 and loss 0.18198034167289734\n",
      "mini batch accuracy:0.8 and loss 0.563213586807251\n",
      "mini batch accuracy:1.0 and loss 0.023628568276762962\n",
      "mini batch accuracy:0.8 and loss 0.4753033220767975\n",
      "mini batch accuracy:0.8 and loss 0.4293254315853119\n",
      "mini batch accuracy:1.0 and loss 0.20186857879161835\n",
      "mini batch accuracy:0.95 and loss 0.13361741602420807\n",
      "mini batch accuracy:0.9 and loss 0.4212876856327057\n",
      "mini batch accuracy:0.8 and loss 0.5811172723770142\n",
      "mini batch accuracy:0.95 and loss 0.2131304293870926\n",
      "mini batch accuracy:0.8 and loss 0.7663871049880981\n",
      "mini batch accuracy:0.95 and loss 0.28303682804107666\n",
      "mini batch accuracy:0.8 and loss 0.36846157908439636\n",
      "mini batch accuracy:0.7 and loss 1.2102959156036377\n",
      "mini batch accuracy:0.75 and loss 0.5894707441329956\n",
      "mini batch accuracy:0.95 and loss 0.2748218774795532\n",
      "mini batch accuracy:0.85 and loss 0.4508422315120697\n",
      "mini batch accuracy:0.95 and loss 0.21534471213817596\n",
      "mini batch accuracy:0.85 and loss 0.33230841159820557\n",
      "mini batch accuracy:1.0 and loss 0.11983271688222885\n",
      "mini batch accuracy:0.9 and loss 0.6303781270980835\n",
      "mini batch accuracy:0.7 and loss 0.6851226091384888\n",
      "mini batch accuracy:0.75 and loss 0.6030603051185608\n",
      "mini batch accuracy:0.95 and loss 0.19028916954994202\n",
      "mini batch accuracy:0.8 and loss 0.5201127529144287\n",
      "mini batch accuracy:0.95 and loss 0.1318608671426773\n",
      "mini batch accuracy:1.0 and loss 0.10860677063465118\n",
      "mini batch accuracy:0.7 and loss 0.8360713720321655\n",
      "mini batch accuracy:0.85 and loss 0.44541358947753906\n",
      "mini batch accuracy:0.95 and loss 0.1733488142490387\n",
      "mini batch accuracy:0.95 and loss 0.18325522541999817\n",
      "mini batch accuracy:0.85 and loss 0.24812717735767365\n",
      "mini batch accuracy:0.9 and loss 0.15916277468204498\n",
      "mini batch accuracy:0.85 and loss 0.3600088655948639\n",
      "mini batch accuracy:0.8 and loss 0.7503581047058105\n",
      "mini batch accuracy:0.95 and loss 0.3138382136821747\n",
      "mini batch accuracy:0.95 and loss 0.5245664715766907\n",
      "mini batch accuracy:1.0 and loss 0.043973445892333984\n",
      "mini batch accuracy:0.9 and loss 0.6276454925537109\n",
      "mini batch accuracy:0.8 and loss 0.4500950872898102\n",
      "Epoch [4/10] with accuracy of0.8770454545454546 and loss0.4500950872898102\n",
      "mini batch accuracy:0.8 and loss 0.5222155451774597\n",
      "mini batch accuracy:0.8 and loss 0.8369733691215515\n",
      "mini batch accuracy:0.95 and loss 0.23793940246105194\n",
      "mini batch accuracy:0.95 and loss 0.2480003833770752\n",
      "mini batch accuracy:0.9 and loss 0.4827668070793152\n",
      "mini batch accuracy:0.85 and loss 0.4569784104824066\n",
      "mini batch accuracy:0.9 and loss 0.31647324562072754\n",
      "mini batch accuracy:1.0 and loss 0.08384165912866592\n",
      "mini batch accuracy:0.9 and loss 0.1758612096309662\n",
      "mini batch accuracy:0.95 and loss 0.15185785293579102\n",
      "mini batch accuracy:0.9 and loss 0.4099208414554596\n",
      "mini batch accuracy:1.0 and loss 0.012242233380675316\n",
      "mini batch accuracy:0.85 and loss 0.3144644498825073\n",
      "mini batch accuracy:1.0 and loss 0.15881213545799255\n",
      "mini batch accuracy:0.95 and loss 0.17890170216560364\n",
      "mini batch accuracy:0.8 and loss 0.6255039572715759\n",
      "mini batch accuracy:1.0 and loss 0.050119806081056595\n",
      "mini batch accuracy:0.95 and loss 0.12552189826965332\n",
      "mini batch accuracy:0.95 and loss 0.21740517020225525\n",
      "mini batch accuracy:0.9 and loss 0.45666152238845825\n",
      "mini batch accuracy:0.85 and loss 0.4455980360507965\n",
      "mini batch accuracy:0.85 and loss 0.29722288250923157\n",
      "mini batch accuracy:0.85 and loss 0.3849653899669647\n",
      "mini batch accuracy:0.85 and loss 0.4786995053291321\n",
      "mini batch accuracy:0.95 and loss 0.3601053059101105\n",
      "mini batch accuracy:0.95 and loss 0.23181715607643127\n",
      "mini batch accuracy:0.9 and loss 0.3051721453666687\n",
      "mini batch accuracy:0.9 and loss 0.19930675625801086\n",
      "mini batch accuracy:0.9 and loss 0.2577629089355469\n",
      "mini batch accuracy:1.0 and loss 0.09950075298547745\n",
      "mini batch accuracy:0.95 and loss 0.1487157642841339\n",
      "mini batch accuracy:0.95 and loss 0.055474262684583664\n",
      "mini batch accuracy:0.95 and loss 0.21700266003608704\n",
      "mini batch accuracy:0.85 and loss 0.3562658131122589\n",
      "mini batch accuracy:0.95 and loss 0.1829340159893036\n",
      "mini batch accuracy:0.9 and loss 0.22507086396217346\n",
      "mini batch accuracy:0.9 and loss 0.2967740297317505\n",
      "mini batch accuracy:0.95 and loss 0.3185233473777771\n",
      "mini batch accuracy:1.0 and loss 0.047942448407411575\n",
      "mini batch accuracy:0.9 and loss 0.30611783266067505\n",
      "mini batch accuracy:0.75 and loss 0.6553352475166321\n",
      "mini batch accuracy:0.7 and loss 0.8032227754592896\n",
      "mini batch accuracy:0.95 and loss 0.2221928834915161\n",
      "mini batch accuracy:0.8 and loss 0.7575291991233826\n",
      "mini batch accuracy:0.95 and loss 0.2376459538936615\n",
      "mini batch accuracy:0.95 and loss 0.17340993881225586\n",
      "mini batch accuracy:0.9 and loss 0.42950958013534546\n",
      "mini batch accuracy:0.85 and loss 0.31444111466407776\n",
      "mini batch accuracy:0.8 and loss 0.5688776969909668\n",
      "mini batch accuracy:0.95 and loss 0.17084266245365143\n",
      "mini batch accuracy:0.85 and loss 0.4000577926635742\n",
      "mini batch accuracy:0.95 and loss 0.17808905243873596\n",
      "mini batch accuracy:1.0 and loss 0.03354131057858467\n",
      "mini batch accuracy:0.8 and loss 0.7345004677772522\n",
      "mini batch accuracy:1.0 and loss 0.05209552124142647\n",
      "mini batch accuracy:0.9 and loss 0.2860393524169922\n",
      "mini batch accuracy:0.9 and loss 0.2594107687473297\n",
      "mini batch accuracy:0.85 and loss 0.6346825361251831\n",
      "mini batch accuracy:0.8 and loss 0.540576159954071\n",
      "mini batch accuracy:0.85 and loss 0.5153595209121704\n",
      "mini batch accuracy:0.9 and loss 0.16443350911140442\n",
      "mini batch accuracy:0.9 and loss 0.2502102553844452\n",
      "mini batch accuracy:0.95 and loss 0.16229504346847534\n",
      "mini batch accuracy:0.7 and loss 0.4745742678642273\n",
      "mini batch accuracy:0.95 and loss 0.1571190059185028\n",
      "mini batch accuracy:0.85 and loss 0.4042561948299408\n",
      "mini batch accuracy:0.85 and loss 0.4891449809074402\n",
      "mini batch accuracy:0.9 and loss 0.29301103949546814\n",
      "mini batch accuracy:0.8 and loss 0.9589864015579224\n",
      "mini batch accuracy:0.7 and loss 0.8272870182991028\n",
      "mini batch accuracy:1.0 and loss 0.0327327735722065\n",
      "mini batch accuracy:0.85 and loss 0.46174484491348267\n",
      "mini batch accuracy:1.0 and loss 0.007515668869018555\n",
      "mini batch accuracy:0.9 and loss 0.37234121561050415\n",
      "mini batch accuracy:0.9 and loss 0.27795904874801636\n",
      "mini batch accuracy:0.9 and loss 0.48379606008529663\n",
      "mini batch accuracy:1.0 and loss 0.062365949153900146\n",
      "mini batch accuracy:0.9 and loss 0.19860628247261047\n",
      "mini batch accuracy:0.9 and loss 0.19789768755435944\n",
      "mini batch accuracy:0.95 and loss 0.1746845543384552\n",
      "mini batch accuracy:0.75 and loss 0.6613117456436157\n",
      "mini batch accuracy:0.85 and loss 0.49855130910873413\n",
      "mini batch accuracy:0.95 and loss 0.1235722154378891\n",
      "mini batch accuracy:0.75 and loss 0.6493241190910339\n",
      "mini batch accuracy:0.85 and loss 0.3033379018306732\n",
      "mini batch accuracy:0.9 and loss 0.2525847554206848\n",
      "mini batch accuracy:0.85 and loss 0.35870081186294556\n",
      "mini batch accuracy:0.9 and loss 0.3701334297657013\n",
      "mini batch accuracy:0.95 and loss 0.2148762196302414\n",
      "mini batch accuracy:0.95 and loss 0.1045583039522171\n",
      "mini batch accuracy:0.9 and loss 0.5040032863616943\n",
      "mini batch accuracy:0.75 and loss 0.766645073890686\n",
      "mini batch accuracy:0.85 and loss 0.34332433342933655\n",
      "mini batch accuracy:0.95 and loss 0.154034823179245\n",
      "mini batch accuracy:0.85 and loss 0.606339693069458\n",
      "mini batch accuracy:0.9 and loss 0.3702489733695984\n",
      "mini batch accuracy:0.9 and loss 0.13685783743858337\n",
      "mini batch accuracy:0.95 and loss 0.2834325432777405\n",
      "mini batch accuracy:0.85 and loss 0.8897102475166321\n",
      "mini batch accuracy:0.9 and loss 0.28613516688346863\n",
      "mini batch accuracy:1.0 and loss 0.07585712522268295\n",
      "mini batch accuracy:0.95 and loss 0.1159677505493164\n",
      "mini batch accuracy:0.95 and loss 0.13483276963233948\n",
      "mini batch accuracy:0.8 and loss 0.32305508852005005\n",
      "mini batch accuracy:0.8 and loss 0.8326651453971863\n",
      "mini batch accuracy:1.0 and loss 0.09427584707736969\n",
      "mini batch accuracy:0.95 and loss 0.17306865751743317\n",
      "mini batch accuracy:0.95 and loss 0.09861421585083008\n",
      "mini batch accuracy:0.75 and loss 0.8291904330253601\n",
      "mini batch accuracy:0.95 and loss 0.2642514109611511\n",
      "Epoch [5/10] with accuracy of0.8952727272727272 and loss0.2642514109611511\n",
      "mini batch accuracy:0.95 and loss 0.16604897379875183\n",
      "mini batch accuracy:0.75 and loss 0.9688483476638794\n",
      "mini batch accuracy:0.9 and loss 0.3676522970199585\n",
      "mini batch accuracy:0.9 and loss 0.30568811297416687\n",
      "mini batch accuracy:0.9 and loss 0.23329102993011475\n",
      "mini batch accuracy:0.85 and loss 0.4522547125816345\n",
      "mini batch accuracy:0.85 and loss 0.24838800728321075\n",
      "mini batch accuracy:1.0 and loss 0.09569993615150452\n",
      "mini batch accuracy:0.95 and loss 0.20246155560016632\n",
      "mini batch accuracy:0.95 and loss 0.33519190549850464\n",
      "mini batch accuracy:0.95 and loss 0.25002580881118774\n",
      "mini batch accuracy:1.0 and loss 0.010670972056686878\n",
      "mini batch accuracy:0.95 and loss 0.15014643967151642\n",
      "mini batch accuracy:0.9 and loss 0.19027277827262878\n",
      "mini batch accuracy:1.0 and loss 0.043287087231874466\n",
      "mini batch accuracy:0.85 and loss 0.47592657804489136\n",
      "mini batch accuracy:0.9 and loss 0.2292250096797943\n",
      "mini batch accuracy:0.95 and loss 0.1321631819009781\n",
      "mini batch accuracy:0.9 and loss 0.3778131604194641\n",
      "mini batch accuracy:0.95 and loss 0.15313546359539032\n",
      "mini batch accuracy:0.9 and loss 0.2774420380592346\n",
      "mini batch accuracy:0.9 and loss 0.2099454700946808\n",
      "mini batch accuracy:0.9 and loss 0.5914340019226074\n",
      "mini batch accuracy:1.0 and loss 0.1709473878145218\n",
      "mini batch accuracy:1.0 and loss 0.09439079463481903\n",
      "mini batch accuracy:1.0 and loss 0.08168463408946991\n",
      "mini batch accuracy:0.95 and loss 0.34840166568756104\n",
      "mini batch accuracy:0.95 and loss 0.1664334535598755\n",
      "mini batch accuracy:0.9 and loss 0.3490532338619232\n",
      "mini batch accuracy:1.0 and loss 0.08080152422189713\n",
      "mini batch accuracy:1.0 and loss 0.0460733063519001\n",
      "mini batch accuracy:1.0 and loss 0.046302519738674164\n",
      "mini batch accuracy:0.95 and loss 0.10207861661911011\n",
      "mini batch accuracy:1.0 and loss 0.03218280151486397\n",
      "mini batch accuracy:0.95 and loss 0.0777997225522995\n",
      "mini batch accuracy:0.85 and loss 0.6878279447555542\n",
      "mini batch accuracy:0.85 and loss 0.5058716535568237\n",
      "mini batch accuracy:1.0 and loss 0.08532390743494034\n",
      "mini batch accuracy:0.95 and loss 0.18055860698223114\n",
      "mini batch accuracy:0.95 and loss 0.24847082793712616\n",
      "mini batch accuracy:0.9 and loss 0.398707777261734\n",
      "mini batch accuracy:0.8 and loss 0.7206783294677734\n",
      "mini batch accuracy:1.0 and loss 0.05700504779815674\n",
      "mini batch accuracy:0.9 and loss 0.24062910676002502\n",
      "mini batch accuracy:0.95 and loss 0.17509138584136963\n",
      "mini batch accuracy:0.9 and loss 0.1970343142747879\n",
      "mini batch accuracy:0.95 and loss 0.3484524190425873\n",
      "mini batch accuracy:0.75 and loss 0.6845812201499939\n",
      "mini batch accuracy:0.85 and loss 0.3676958680152893\n",
      "mini batch accuracy:0.95 and loss 0.2963097095489502\n",
      "mini batch accuracy:1.0 and loss 0.05876417085528374\n",
      "mini batch accuracy:0.95 and loss 0.1962052583694458\n",
      "mini batch accuracy:0.9 and loss 0.23146049678325653\n",
      "mini batch accuracy:0.95 and loss 0.21893790364265442\n",
      "mini batch accuracy:1.0 and loss 0.06140200048685074\n",
      "mini batch accuracy:0.85 and loss 0.5204063653945923\n",
      "mini batch accuracy:1.0 and loss 0.042072463780641556\n",
      "mini batch accuracy:0.8 and loss 0.5224785804748535\n",
      "mini batch accuracy:0.75 and loss 0.7669423222541809\n",
      "mini batch accuracy:0.95 and loss 0.20635898411273956\n",
      "mini batch accuracy:0.95 and loss 0.18247422575950623\n",
      "mini batch accuracy:0.9 and loss 0.21202178299427032\n",
      "mini batch accuracy:0.85 and loss 0.3043469190597534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini batch accuracy:0.75 and loss 0.7855741381645203\n",
      "mini batch accuracy:1.0 and loss 0.14603619277477264\n",
      "mini batch accuracy:0.9 and loss 0.3809121549129486\n",
      "mini batch accuracy:0.85 and loss 0.4100535809993744\n",
      "mini batch accuracy:1.0 and loss 0.1419338434934616\n",
      "mini batch accuracy:0.75 and loss 0.7697234153747559\n",
      "mini batch accuracy:0.75 and loss 1.0208755731582642\n",
      "mini batch accuracy:1.0 and loss 0.046136461198329926\n",
      "mini batch accuracy:0.95 and loss 0.18893314898014069\n",
      "mini batch accuracy:1.0 and loss 0.00835120677947998\n",
      "mini batch accuracy:1.0 and loss 0.09780503809452057\n",
      "mini batch accuracy:0.8 and loss 0.5255827903747559\n",
      "mini batch accuracy:0.9 and loss 0.32019567489624023\n",
      "mini batch accuracy:1.0 and loss 0.04708991199731827\n",
      "mini batch accuracy:0.95 and loss 0.13626448810100555\n",
      "mini batch accuracy:0.85 and loss 0.6472722291946411\n",
      "mini batch accuracy:0.9 and loss 0.22146162390708923\n",
      "mini batch accuracy:0.8 and loss 0.3971884846687317\n",
      "mini batch accuracy:0.9 and loss 0.28297361731529236\n",
      "mini batch accuracy:0.95 and loss 0.320392906665802\n",
      "mini batch accuracy:0.85 and loss 0.47710227966308594\n",
      "mini batch accuracy:0.8 and loss 0.6244059205055237\n",
      "mini batch accuracy:0.85 and loss 0.3653104305267334\n",
      "mini batch accuracy:0.85 and loss 0.4757121205329895\n",
      "mini batch accuracy:1.0 and loss 0.06417272239923477\n",
      "mini batch accuracy:0.85 and loss 0.5173555016517639\n",
      "mini batch accuracy:0.95 and loss 0.15337058901786804\n",
      "mini batch accuracy:0.95 and loss 0.4110870361328125\n",
      "mini batch accuracy:0.75 and loss 0.603473961353302\n",
      "mini batch accuracy:0.95 and loss 0.30974388122558594\n",
      "mini batch accuracy:0.95 and loss 0.1610349714756012\n",
      "mini batch accuracy:0.9 and loss 0.2466113567352295\n",
      "mini batch accuracy:0.9 and loss 0.2540855407714844\n",
      "mini batch accuracy:1.0 and loss 0.05618885159492493\n",
      "mini batch accuracy:0.9 and loss 0.15022113919258118\n",
      "mini batch accuracy:0.9 and loss 0.1709708869457245\n",
      "mini batch accuracy:0.95 and loss 0.16422177851200104\n",
      "mini batch accuracy:1.0 and loss 0.12690600752830505\n",
      "mini batch accuracy:0.95 and loss 0.13169629871845245\n",
      "mini batch accuracy:0.9 and loss 0.18284936249256134\n",
      "mini batch accuracy:0.9 and loss 0.273767352104187\n",
      "mini batch accuracy:0.9 and loss 0.25132668018341064\n",
      "mini batch accuracy:0.9 and loss 0.6797298789024353\n",
      "mini batch accuracy:0.9 and loss 0.4425656795501709\n",
      "mini batch accuracy:1.0 and loss 0.010953354649245739\n",
      "mini batch accuracy:0.8 and loss 0.4273800849914551\n",
      "mini batch accuracy:1.0 and loss 0.18759584426879883\n",
      "Epoch [6/10] with accuracy of0.906 and loss0.18759584426879883\n",
      "mini batch accuracy:0.9 and loss 0.24839524924755096\n",
      "mini batch accuracy:0.8 and loss 0.8089785575866699\n",
      "mini batch accuracy:1.0 and loss 0.14559833705425262\n",
      "mini batch accuracy:0.95 and loss 0.19621656835079193\n",
      "mini batch accuracy:0.85 and loss 0.3212164342403412\n",
      "mini batch accuracy:0.85 and loss 0.45726823806762695\n",
      "mini batch accuracy:0.9 and loss 0.3664797246456146\n",
      "mini batch accuracy:0.95 and loss 0.10221216827630997\n",
      "mini batch accuracy:0.95 and loss 0.2047799527645111\n",
      "mini batch accuracy:0.95 and loss 0.18256612122058868\n",
      "mini batch accuracy:0.9 and loss 0.2890426516532898\n",
      "mini batch accuracy:1.0 and loss 0.008829629048705101\n",
      "mini batch accuracy:0.95 and loss 0.1984349638223648\n",
      "mini batch accuracy:0.95 and loss 0.19401338696479797\n",
      "mini batch accuracy:0.85 and loss 0.28095921874046326\n",
      "mini batch accuracy:0.85 and loss 0.6124695539474487\n",
      "mini batch accuracy:1.0 and loss 0.08896787464618683\n",
      "mini batch accuracy:1.0 and loss 0.09473587572574615\n",
      "mini batch accuracy:0.85 and loss 0.4898827075958252\n",
      "mini batch accuracy:1.0 and loss 0.06060750409960747\n",
      "mini batch accuracy:0.95 and loss 0.15058425068855286\n",
      "mini batch accuracy:0.9 and loss 0.22914354503154755\n",
      "mini batch accuracy:0.85 and loss 0.3948102295398712\n",
      "mini batch accuracy:0.9 and loss 0.36437875032424927\n",
      "mini batch accuracy:1.0 and loss 0.13337138295173645\n",
      "mini batch accuracy:0.95 and loss 0.2106783092021942\n",
      "mini batch accuracy:0.8 and loss 0.478609174489975\n",
      "mini batch accuracy:1.0 and loss 0.04065210744738579\n",
      "mini batch accuracy:0.95 and loss 0.2328803986310959\n",
      "mini batch accuracy:1.0 and loss 0.04651002958416939\n",
      "mini batch accuracy:1.0 and loss 0.04007638618350029\n",
      "mini batch accuracy:1.0 and loss 0.06641119718551636\n",
      "mini batch accuracy:1.0 and loss 0.028844570741057396\n",
      "mini batch accuracy:0.95 and loss 0.2806246876716614\n",
      "mini batch accuracy:1.0 and loss 0.020002400502562523\n",
      "mini batch accuracy:0.9 and loss 0.30441075563430786\n",
      "mini batch accuracy:0.85 and loss 0.30376043915748596\n",
      "mini batch accuracy:0.9 and loss 0.21120107173919678\n",
      "mini batch accuracy:0.95 and loss 0.1839553415775299\n",
      "mini batch accuracy:0.95 and loss 0.11766134202480316\n",
      "mini batch accuracy:0.9 and loss 0.3772294223308563\n",
      "mini batch accuracy:0.85 and loss 0.42564210295677185\n",
      "mini batch accuracy:0.9 and loss 0.25382542610168457\n",
      "mini batch accuracy:0.9 and loss 0.27225831151008606\n",
      "mini batch accuracy:0.95 and loss 0.28891754150390625\n",
      "mini batch accuracy:0.9 and loss 0.26056164503097534\n",
      "mini batch accuracy:0.9 and loss 0.23375281691551208\n",
      "mini batch accuracy:0.95 and loss 0.10047116130590439\n",
      "mini batch accuracy:0.8 and loss 0.5690668821334839\n",
      "mini batch accuracy:0.95 and loss 0.2980511486530304\n",
      "mini batch accuracy:0.9 and loss 0.2833625078201294\n",
      "mini batch accuracy:1.0 and loss 0.03252992779016495\n",
      "mini batch accuracy:1.0 and loss 0.04311921074986458\n",
      "mini batch accuracy:0.95 and loss 0.23114296793937683\n",
      "mini batch accuracy:1.0 and loss 0.02729128673672676\n",
      "mini batch accuracy:0.95 and loss 0.2676979601383209\n",
      "mini batch accuracy:0.85 and loss 0.408139705657959\n",
      "mini batch accuracy:0.95 and loss 0.47410422563552856\n",
      "mini batch accuracy:0.8 and loss 0.7527235746383667\n",
      "mini batch accuracy:0.9 and loss 0.17147402465343475\n",
      "mini batch accuracy:0.95 and loss 0.08910507708787918\n",
      "mini batch accuracy:0.95 and loss 0.09174767881631851\n",
      "mini batch accuracy:1.0 and loss 0.06680987030267715\n",
      "mini batch accuracy:1.0 and loss 0.1813330054283142\n",
      "mini batch accuracy:1.0 and loss 0.09193142503499985\n",
      "mini batch accuracy:0.85 and loss 0.3223966956138611\n",
      "mini batch accuracy:1.0 and loss 0.048673976212739944\n",
      "mini batch accuracy:0.95 and loss 0.2943928837776184\n",
      "mini batch accuracy:0.85 and loss 0.7615413069725037\n",
      "mini batch accuracy:0.85 and loss 0.27054351568222046\n",
      "mini batch accuracy:0.95 and loss 0.19935792684555054\n",
      "mini batch accuracy:0.95 and loss 0.26078224182128906\n",
      "mini batch accuracy:1.0 and loss 0.014569866470992565\n",
      "mini batch accuracy:0.85 and loss 0.5644108057022095\n",
      "mini batch accuracy:0.9 and loss 0.13449162244796753\n",
      "mini batch accuracy:0.9 and loss 0.3901650905609131\n",
      "mini batch accuracy:0.9 and loss 0.2083980143070221\n",
      "mini batch accuracy:0.9 and loss 0.19304242730140686\n",
      "mini batch accuracy:0.8 and loss 0.3796355128288269\n",
      "mini batch accuracy:0.95 and loss 0.24338272213935852\n",
      "mini batch accuracy:0.75 and loss 0.6295580863952637\n",
      "mini batch accuracy:0.9 and loss 0.2537840008735657\n",
      "mini batch accuracy:1.0 and loss 0.05300772190093994\n",
      "mini batch accuracy:0.95 and loss 0.17037785053253174\n",
      "mini batch accuracy:0.95 and loss 0.17582277953624725\n",
      "mini batch accuracy:0.95 and loss 0.07971755415201187\n",
      "mini batch accuracy:0.85 and loss 0.3727046549320221\n",
      "mini batch accuracy:0.95 and loss 0.18698550760746002\n",
      "mini batch accuracy:1.0 and loss 0.09809760749340057\n",
      "mini batch accuracy:0.95 and loss 0.07554652541875839\n",
      "mini batch accuracy:0.9 and loss 0.5036126375198364\n",
      "mini batch accuracy:0.85 and loss 0.36486679315567017\n",
      "mini batch accuracy:0.95 and loss 0.26145321130752563\n",
      "mini batch accuracy:0.95 and loss 0.24001140892505646\n",
      "mini batch accuracy:0.85 and loss 0.5450886487960815\n",
      "mini batch accuracy:0.95 and loss 0.13650700449943542\n",
      "mini batch accuracy:1.0 and loss 0.05647982284426689\n",
      "mini batch accuracy:1.0 and loss 0.06635449826717377\n",
      "mini batch accuracy:0.9 and loss 0.22456681728363037\n",
      "mini batch accuracy:0.95 and loss 0.33779430389404297\n",
      "mini batch accuracy:0.95 and loss 0.1699676811695099\n",
      "mini batch accuracy:0.9 and loss 0.3355484902858734\n",
      "mini batch accuracy:1.0 and loss 0.06834892928600311\n",
      "mini batch accuracy:0.95 and loss 0.329311728477478\n",
      "mini batch accuracy:0.95 and loss 0.14688780903816223\n",
      "mini batch accuracy:0.9 and loss 0.18351057171821594\n",
      "mini batch accuracy:1.0 and loss 0.04615583270788193\n",
      "mini batch accuracy:1.0 and loss 0.0025577545166015625\n",
      "mini batch accuracy:0.95 and loss 0.21918734908103943\n",
      "mini batch accuracy:0.85 and loss 0.38518521189689636\n",
      "Epoch [7/10] with accuracy of0.9230909090909091 and loss0.38518521189689636\n",
      "mini batch accuracy:0.9 and loss 0.3601345717906952\n",
      "mini batch accuracy:0.9 and loss 0.49028125405311584\n",
      "mini batch accuracy:0.95 and loss 0.09660360217094421\n",
      "mini batch accuracy:0.9 and loss 0.34815776348114014\n",
      "mini batch accuracy:0.9 and loss 0.28972890973091125\n",
      "mini batch accuracy:0.95 and loss 0.24358288943767548\n",
      "mini batch accuracy:1.0 and loss 0.07204777002334595\n",
      "mini batch accuracy:0.95 and loss 0.21762590110301971\n",
      "mini batch accuracy:1.0 and loss 0.07804641872644424\n",
      "mini batch accuracy:1.0 and loss 0.011546134948730469\n",
      "mini batch accuracy:1.0 and loss 0.10178723186254501\n",
      "mini batch accuracy:1.0 and loss 0.017286622896790504\n",
      "mini batch accuracy:0.95 and loss 0.05822863429784775\n",
      "mini batch accuracy:0.9 and loss 0.3377082347869873\n",
      "mini batch accuracy:0.95 and loss 0.07427960634231567\n",
      "mini batch accuracy:0.95 and loss 0.12091656029224396\n",
      "mini batch accuracy:1.0 and loss 0.03935713693499565\n",
      "mini batch accuracy:0.95 and loss 0.14141950011253357\n",
      "mini batch accuracy:0.9 and loss 0.30198660492897034\n",
      "mini batch accuracy:0.95 and loss 0.15160296857357025\n",
      "mini batch accuracy:0.9 and loss 0.14418447017669678\n",
      "mini batch accuracy:1.0 and loss 0.04224663972854614\n",
      "mini batch accuracy:0.9 and loss 0.34988948702812195\n",
      "mini batch accuracy:0.95 and loss 0.11951935291290283\n",
      "mini batch accuracy:1.0 and loss 0.14836367964744568\n",
      "mini batch accuracy:0.9 and loss 0.36106353998184204\n",
      "mini batch accuracy:0.95 and loss 0.18402840197086334\n",
      "mini batch accuracy:1.0 and loss 0.061708223074674606\n",
      "mini batch accuracy:0.95 and loss 0.17994645237922668\n",
      "mini batch accuracy:0.9 and loss 0.18699856102466583\n",
      "mini batch accuracy:0.95 and loss 0.25757092237472534\n",
      "mini batch accuracy:0.9 and loss 0.28600072860717773\n",
      "mini batch accuracy:0.95 and loss 0.13290928304195404\n",
      "mini batch accuracy:0.95 and loss 0.09485496580600739\n",
      "mini batch accuracy:1.0 and loss 0.038536153733730316\n",
      "mini batch accuracy:0.95 and loss 0.09677888453006744\n",
      "mini batch accuracy:0.95 and loss 0.17441809177398682\n",
      "mini batch accuracy:1.0 and loss 0.04126478359103203\n",
      "mini batch accuracy:0.95 and loss 0.09840891510248184\n",
      "mini batch accuracy:1.0 and loss 0.05093533918261528\n",
      "mini batch accuracy:0.95 and loss 0.1209445595741272\n",
      "mini batch accuracy:0.9 and loss 0.3515525460243225\n",
      "mini batch accuracy:1.0 and loss 0.007958292961120605\n",
      "mini batch accuracy:0.95 and loss 0.16391733288764954\n",
      "mini batch accuracy:1.0 and loss 0.0412939079105854\n",
      "mini batch accuracy:0.95 and loss 0.07202281057834625\n",
      "mini batch accuracy:0.9 and loss 0.2747528851032257\n",
      "mini batch accuracy:0.9 and loss 0.2861503064632416\n",
      "mini batch accuracy:0.95 and loss 0.20527403056621552\n",
      "mini batch accuracy:1.0 and loss 0.040083516389131546\n",
      "mini batch accuracy:0.95 and loss 0.08185944706201553\n",
      "mini batch accuracy:0.9 and loss 0.1303335577249527\n",
      "mini batch accuracy:0.9 and loss 0.5568920373916626\n",
      "mini batch accuracy:0.95 and loss 0.09995929151773453\n",
      "mini batch accuracy:1.0 and loss 0.04974633455276489\n",
      "mini batch accuracy:0.95 and loss 0.16252276301383972\n",
      "mini batch accuracy:1.0 and loss 0.0073174359276890755\n",
      "mini batch accuracy:0.9 and loss 0.26935455203056335\n",
      "mini batch accuracy:0.85 and loss 0.5862286686897278\n",
      "mini batch accuracy:0.9 and loss 0.23078612983226776\n",
      "mini batch accuracy:1.0 and loss 0.0827103853225708\n",
      "mini batch accuracy:0.95 and loss 0.09472350776195526\n",
      "mini batch accuracy:1.0 and loss 0.03525928407907486\n",
      "mini batch accuracy:1.0 and loss 0.06240328028798103\n",
      "mini batch accuracy:1.0 and loss 0.08068836480379105\n",
      "mini batch accuracy:0.9 and loss 0.2475273609161377\n",
      "mini batch accuracy:0.95 and loss 0.10186366736888885\n",
      "mini batch accuracy:0.95 and loss 0.25640547275543213\n",
      "mini batch accuracy:0.85 and loss 0.6628767848014832\n",
      "mini batch accuracy:0.95 and loss 0.1392967402935028\n",
      "mini batch accuracy:1.0 and loss 0.04521501064300537\n",
      "mini batch accuracy:1.0 and loss 0.04068890959024429\n",
      "mini batch accuracy:1.0 and loss 0.008865952491760254\n",
      "mini batch accuracy:0.95 and loss 0.10658005625009537\n",
      "mini batch accuracy:0.95 and loss 0.17961633205413818\n",
      "mini batch accuracy:1.0 and loss 0.05214809626340866\n",
      "mini batch accuracy:1.0 and loss 0.021661628037691116\n",
      "mini batch accuracy:0.95 and loss 0.14336445927619934\n",
      "mini batch accuracy:0.8 and loss 0.48410940170288086\n",
      "mini batch accuracy:0.95 and loss 0.08215293288230896\n",
      "mini batch accuracy:0.9 and loss 0.42518043518066406\n",
      "mini batch accuracy:0.85 and loss 0.24609649181365967\n",
      "mini batch accuracy:0.9 and loss 0.09568081051111221\n",
      "mini batch accuracy:0.8 and loss 0.6708472967147827\n",
      "mini batch accuracy:0.9 and loss 0.2983265221118927\n",
      "mini batch accuracy:0.95 and loss 0.20508208870887756\n",
      "mini batch accuracy:0.9 and loss 0.2531324028968811\n",
      "mini batch accuracy:0.85 and loss 0.28044798970222473\n",
      "mini batch accuracy:0.95 and loss 0.3043695390224457\n",
      "mini batch accuracy:0.95 and loss 0.13104447722434998\n",
      "mini batch accuracy:0.85 and loss 0.6918428540229797\n",
      "mini batch accuracy:0.9 and loss 0.416172593832016\n",
      "mini batch accuracy:0.95 and loss 0.16636371612548828\n",
      "mini batch accuracy:1.0 and loss 0.07257016748189926\n",
      "mini batch accuracy:0.95 and loss 0.34313589334487915\n",
      "mini batch accuracy:0.9 and loss 0.3328021168708801\n",
      "mini batch accuracy:0.9 and loss 0.16129548847675323\n",
      "mini batch accuracy:0.85 and loss 0.25641515851020813\n",
      "mini batch accuracy:0.85 and loss 0.4712591767311096\n",
      "mini batch accuracy:0.95 and loss 0.12517984211444855\n",
      "mini batch accuracy:1.0 and loss 0.027508676052093506\n",
      "mini batch accuracy:0.95 and loss 0.13953842222690582\n",
      "mini batch accuracy:0.95 and loss 0.2813420593738556\n",
      "mini batch accuracy:0.9 and loss 0.3489476442337036\n",
      "mini batch accuracy:0.9 and loss 0.2495841532945633\n",
      "mini batch accuracy:0.95 and loss 0.11984451115131378\n",
      "mini batch accuracy:1.0 and loss 0.018888700753450394\n",
      "mini batch accuracy:1.0 and loss 0.015857839956879616\n",
      "mini batch accuracy:0.9 and loss 0.1485171914100647\n",
      "mini batch accuracy:1.0 and loss 0.07313624024391174\n",
      "Epoch [8/10] with accuracy of0.9333181818181818 and loss0.07313624024391174\n",
      "mini batch accuracy:0.95 and loss 0.14656370878219604\n",
      "mini batch accuracy:0.9 and loss 0.3961876332759857\n",
      "mini batch accuracy:1.0 and loss 0.049219001084566116\n",
      "mini batch accuracy:0.95 and loss 0.12986792623996735\n",
      "mini batch accuracy:0.75 and loss 0.753803551197052\n",
      "mini batch accuracy:0.9 and loss 0.31932491064071655\n",
      "mini batch accuracy:0.95 and loss 0.1401917040348053\n",
      "mini batch accuracy:0.95 and loss 0.13545450568199158\n",
      "mini batch accuracy:0.95 and loss 0.1426781415939331\n",
      "mini batch accuracy:1.0 and loss 0.06430722773075104\n",
      "mini batch accuracy:0.95 and loss 0.11682765185832977\n",
      "mini batch accuracy:0.95 and loss 0.07817196846008301\n",
      "mini batch accuracy:0.85 and loss 0.2993505001068115\n",
      "mini batch accuracy:0.95 and loss 0.0878426656126976\n",
      "mini batch accuracy:0.95 and loss 0.15454593300819397\n",
      "mini batch accuracy:0.9 and loss 0.5539169311523438\n",
      "mini batch accuracy:0.9 and loss 0.17418916523456573\n",
      "mini batch accuracy:1.0 and loss 0.04874523729085922\n",
      "mini batch accuracy:0.9 and loss 0.2708011269569397\n",
      "mini batch accuracy:0.9 and loss 0.34991633892059326\n",
      "mini batch accuracy:0.95 and loss 0.27977293729782104\n",
      "mini batch accuracy:0.9 and loss 0.1662074625492096\n",
      "mini batch accuracy:1.0 and loss 0.004397654440253973\n",
      "mini batch accuracy:1.0 and loss 0.06940058618783951\n",
      "mini batch accuracy:1.0 and loss 0.02602466382086277\n",
      "mini batch accuracy:1.0 and loss 0.04461798816919327\n",
      "mini batch accuracy:0.95 and loss 0.13557395339012146\n",
      "mini batch accuracy:1.0 and loss 0.04487502574920654\n",
      "mini batch accuracy:0.95 and loss 0.10523102432489395\n",
      "mini batch accuracy:1.0 and loss 0.06113703176379204\n",
      "mini batch accuracy:0.95 and loss 0.10216627269983292\n",
      "mini batch accuracy:1.0 and loss 0.004481768701225519\n",
      "mini batch accuracy:1.0 and loss 0.015084529295563698\n",
      "mini batch accuracy:0.95 and loss 0.1078428402543068\n",
      "mini batch accuracy:0.95 and loss 0.13012467324733734\n",
      "mini batch accuracy:1.0 and loss 0.020275115966796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini batch accuracy:0.95 and loss 0.27843648195266724\n",
      "mini batch accuracy:0.95 and loss 0.3450802266597748\n",
      "mini batch accuracy:1.0 and loss 0.011340463533997536\n",
      "mini batch accuracy:0.9 and loss 0.33789655566215515\n",
      "mini batch accuracy:0.9 and loss 0.4225351810455322\n",
      "mini batch accuracy:0.9 and loss 0.42578548192977905\n",
      "mini batch accuracy:0.9 and loss 0.16334408521652222\n",
      "mini batch accuracy:0.95 and loss 0.14411118626594543\n",
      "mini batch accuracy:1.0 and loss 0.014581834897398949\n",
      "mini batch accuracy:0.95 and loss 0.10521464049816132\n",
      "mini batch accuracy:0.95 and loss 0.23995094001293182\n",
      "mini batch accuracy:0.95 and loss 0.19624067842960358\n",
      "mini batch accuracy:0.95 and loss 0.15699873864650726\n",
      "mini batch accuracy:1.0 and loss 0.08895625919103622\n",
      "mini batch accuracy:0.9 and loss 0.17015814781188965\n",
      "mini batch accuracy:0.95 and loss 0.05421411991119385\n",
      "mini batch accuracy:1.0 and loss 0.008563590236008167\n",
      "mini batch accuracy:0.85 and loss 0.20128917694091797\n",
      "mini batch accuracy:0.95 and loss 0.0931774228811264\n",
      "mini batch accuracy:0.85 and loss 0.30734843015670776\n",
      "mini batch accuracy:0.95 and loss 0.07179437577724457\n",
      "mini batch accuracy:0.95 and loss 0.2465781718492508\n",
      "mini batch accuracy:0.9 and loss 0.7428974509239197\n",
      "mini batch accuracy:0.9 and loss 0.26199668645858765\n",
      "mini batch accuracy:0.95 and loss 0.15953701734542847\n",
      "mini batch accuracy:0.95 and loss 0.07338584959506989\n",
      "mini batch accuracy:1.0 and loss 0.029812609776854515\n",
      "mini batch accuracy:1.0 and loss 0.09407646954059601\n",
      "mini batch accuracy:1.0 and loss 0.012682532891631126\n",
      "mini batch accuracy:0.95 and loss 0.16268643736839294\n",
      "mini batch accuracy:0.9 and loss 0.3707011342048645\n",
      "mini batch accuracy:0.85 and loss 0.6332345008850098\n",
      "mini batch accuracy:0.95 and loss 0.1972782015800476\n",
      "mini batch accuracy:1.0 and loss 0.04042236879467964\n",
      "mini batch accuracy:0.95 and loss 0.1844957172870636\n",
      "mini batch accuracy:0.95 and loss 0.08619855344295502\n",
      "mini batch accuracy:1.0 and loss 0.02033975161612034\n",
      "mini batch accuracy:0.9 and loss 0.27024030685424805\n",
      "mini batch accuracy:0.8 and loss 0.6553605794906616\n",
      "mini batch accuracy:0.85 and loss 0.3317227065563202\n",
      "mini batch accuracy:1.0 and loss 0.017634760588407516\n",
      "mini batch accuracy:1.0 and loss 0.06907039880752563\n",
      "mini batch accuracy:0.95 and loss 0.15603575110435486\n",
      "mini batch accuracy:0.95 and loss 0.125627338886261\n",
      "mini batch accuracy:0.85 and loss 0.37019941210746765\n",
      "mini batch accuracy:0.9 and loss 0.25781890749931335\n",
      "mini batch accuracy:0.95 and loss 0.12070002406835556\n",
      "mini batch accuracy:0.95 and loss 0.1986355483531952\n",
      "mini batch accuracy:0.95 and loss 0.07673630118370056\n",
      "mini batch accuracy:0.95 and loss 0.06706473976373672\n",
      "mini batch accuracy:0.9 and loss 0.2745593190193176\n",
      "mini batch accuracy:0.95 and loss 0.07395600527524948\n",
      "mini batch accuracy:0.9 and loss 0.3680706024169922\n",
      "mini batch accuracy:1.0 and loss 0.03255752474069595\n",
      "mini batch accuracy:0.95 and loss 0.4595077931880951\n",
      "mini batch accuracy:0.85 and loss 0.4845784604549408\n",
      "mini batch accuracy:1.0 and loss 0.10065431892871857\n",
      "mini batch accuracy:0.95 and loss 0.14777407050132751\n",
      "mini batch accuracy:0.9 and loss 0.37248721718788147\n",
      "mini batch accuracy:1.0 and loss 0.004496478941291571\n",
      "mini batch accuracy:0.95 and loss 0.10325919091701508\n",
      "mini batch accuracy:1.0 and loss 0.06718771159648895\n",
      "mini batch accuracy:0.9 and loss 0.18632861971855164\n",
      "mini batch accuracy:0.95 and loss 0.20009788870811462\n",
      "mini batch accuracy:0.9 and loss 0.2985156178474426\n",
      "mini batch accuracy:0.95 and loss 0.17369325459003448\n",
      "mini batch accuracy:1.0 and loss 0.01679474115371704\n",
      "mini batch accuracy:0.95 and loss 0.09888078272342682\n",
      "mini batch accuracy:0.95 and loss 0.11148090660572052\n",
      "mini batch accuracy:0.95 and loss 0.21411947906017303\n",
      "mini batch accuracy:0.95 and loss 0.2437162846326828\n",
      "mini batch accuracy:1.0 and loss 0.03919253498315811\n",
      "mini batch accuracy:0.85 and loss 0.23033103346824646\n",
      "mini batch accuracy:0.95 and loss 0.3383244574069977\n",
      "Epoch [9/10] with accuracy of0.9370454545454545 and loss0.3383244574069977\n",
      "mini batch accuracy:0.9 and loss 0.35443735122680664\n",
      "mini batch accuracy:0.8 and loss 0.6221517324447632\n",
      "mini batch accuracy:0.95 and loss 0.11632460355758667\n",
      "mini batch accuracy:0.9 and loss 0.227726548910141\n",
      "mini batch accuracy:0.85 and loss 0.34834548830986023\n",
      "mini batch accuracy:0.95 and loss 0.15765473246574402\n",
      "mini batch accuracy:0.85 and loss 0.28191184997558594\n",
      "mini batch accuracy:1.0 and loss 0.057586897164583206\n",
      "mini batch accuracy:1.0 and loss 0.07439921796321869\n",
      "mini batch accuracy:1.0 and loss 0.012876391410827637\n",
      "mini batch accuracy:0.95 and loss 0.2493300437927246\n",
      "mini batch accuracy:0.9 and loss 0.1664009839296341\n",
      "mini batch accuracy:0.95 and loss 0.23830142617225647\n",
      "mini batch accuracy:0.95 and loss 0.11007976531982422\n",
      "mini batch accuracy:0.9 and loss 0.18811260163784027\n",
      "mini batch accuracy:0.95 and loss 0.21736161410808563\n",
      "mini batch accuracy:0.75 and loss 0.621597170829773\n",
      "mini batch accuracy:0.95 and loss 0.06224089115858078\n",
      "mini batch accuracy:0.95 and loss 0.29359862208366394\n",
      "mini batch accuracy:0.95 and loss 0.08108498156070709\n",
      "mini batch accuracy:0.95 and loss 0.2104557454586029\n",
      "mini batch accuracy:0.9 and loss 0.2169235497713089\n",
      "mini batch accuracy:0.95 and loss 0.6320101022720337\n",
      "mini batch accuracy:0.95 and loss 0.14605431258678436\n",
      "mini batch accuracy:0.95 and loss 0.12788793444633484\n",
      "mini batch accuracy:0.95 and loss 0.15116539597511292\n",
      "mini batch accuracy:1.0 and loss 0.03140190988779068\n",
      "mini batch accuracy:0.95 and loss 0.11430267989635468\n",
      "mini batch accuracy:1.0 and loss 0.055071569979190826\n",
      "mini batch accuracy:0.9 and loss 0.4291047155857086\n",
      "mini batch accuracy:1.0 and loss 0.01544651947915554\n",
      "mini batch accuracy:1.0 and loss 0.010713291354477406\n",
      "mini batch accuracy:0.95 and loss 0.07794927805662155\n",
      "mini batch accuracy:1.0 and loss 0.0394059494137764\n",
      "mini batch accuracy:1.0 and loss 0.014685606583952904\n",
      "mini batch accuracy:0.95 and loss 0.1214190348982811\n",
      "mini batch accuracy:0.9 and loss 0.3560066521167755\n",
      "mini batch accuracy:1.0 and loss 0.04030253738164902\n",
      "mini batch accuracy:0.95 and loss 0.047976233065128326\n",
      "mini batch accuracy:0.95 and loss 0.0847298726439476\n",
      "mini batch accuracy:0.9 and loss 0.14687250554561615\n",
      "mini batch accuracy:0.95 and loss 0.24849534034729004\n",
      "mini batch accuracy:1.0 and loss 0.06896232068538666\n",
      "mini batch accuracy:1.0 and loss 0.021417688578367233\n",
      "mini batch accuracy:0.95 and loss 0.0717601329088211\n",
      "mini batch accuracy:1.0 and loss 0.04886519908905029\n",
      "mini batch accuracy:0.85 and loss 0.503465473651886\n",
      "mini batch accuracy:0.95 and loss 0.11097703874111176\n",
      "mini batch accuracy:0.95 and loss 0.21224269270896912\n",
      "mini batch accuracy:1.0 and loss 0.01928427256643772\n",
      "mini batch accuracy:1.0 and loss 0.011496377177536488\n",
      "mini batch accuracy:0.9 and loss 0.10777312517166138\n",
      "mini batch accuracy:1.0 and loss 0.014475136995315552\n",
      "mini batch accuracy:0.95 and loss 0.06338920444250107\n",
      "mini batch accuracy:1.0 and loss 0.003831410314887762\n",
      "mini batch accuracy:0.95 and loss 0.3203204572200775\n",
      "mini batch accuracy:0.95 and loss 0.1048993319272995\n",
      "mini batch accuracy:0.95 and loss 0.1905997097492218\n",
      "mini batch accuracy:0.85 and loss 0.42354339361190796\n",
      "mini batch accuracy:0.85 and loss 0.6189461946487427\n",
      "mini batch accuracy:1.0 and loss 0.030938684940338135\n",
      "mini batch accuracy:0.9 and loss 0.19813816249370575\n",
      "mini batch accuracy:1.0 and loss 0.00560386199504137\n",
      "mini batch accuracy:1.0 and loss 0.06951902061700821\n",
      "mini batch accuracy:1.0 and loss 0.026317190378904343\n",
      "mini batch accuracy:0.95 and loss 0.14965441823005676\n",
      "mini batch accuracy:1.0 and loss 0.05315253883600235\n",
      "mini batch accuracy:0.95 and loss 0.18603941798210144\n",
      "mini batch accuracy:0.85 and loss 0.19330260157585144\n",
      "mini batch accuracy:0.95 and loss 0.1871735155582428\n",
      "mini batch accuracy:1.0 and loss 0.00857853889465332\n",
      "mini batch accuracy:0.95 and loss 0.22993779182434082\n",
      "mini batch accuracy:1.0 and loss 0.010956525802612305\n",
      "mini batch accuracy:0.9 and loss 0.1645011305809021\n",
      "mini batch accuracy:1.0 and loss 0.010699224658310413\n",
      "mini batch accuracy:0.9 and loss 0.19955527782440186\n",
      "mini batch accuracy:0.95 and loss 0.13848134875297546\n",
      "mini batch accuracy:0.95 and loss 0.09413723647594452\n",
      "mini batch accuracy:0.9 and loss 0.21042020618915558\n",
      "mini batch accuracy:0.95 and loss 0.06468833237886429\n",
      "mini batch accuracy:0.9 and loss 0.2606101334095001\n",
      "mini batch accuracy:0.95 and loss 0.22476601600646973\n",
      "mini batch accuracy:0.95 and loss 0.15242478251457214\n",
      "mini batch accuracy:0.9 and loss 0.27445530891418457\n",
      "mini batch accuracy:1.0 and loss 0.10250890254974365\n",
      "mini batch accuracy:0.95 and loss 0.22819462418556213\n",
      "mini batch accuracy:0.9 and loss 0.3008488714694977\n",
      "mini batch accuracy:0.95 and loss 0.09847251325845718\n",
      "mini batch accuracy:1.0 and loss 0.046918295323848724\n",
      "mini batch accuracy:1.0 and loss 0.009430492296814919\n",
      "mini batch accuracy:0.95 and loss 0.22367489337921143\n",
      "mini batch accuracy:0.9 and loss 0.45604267716407776\n",
      "mini batch accuracy:0.8 and loss 0.5142854452133179\n",
      "mini batch accuracy:0.95 and loss 0.2818058133125305\n",
      "mini batch accuracy:0.95 and loss 0.3275631368160248\n",
      "mini batch accuracy:0.95 and loss 0.09427990019321442\n",
      "mini batch accuracy:0.95 and loss 0.1325082927942276\n",
      "mini batch accuracy:0.9 and loss 0.27941516041755676\n",
      "mini batch accuracy:1.0 and loss 0.10683520138263702\n",
      "mini batch accuracy:1.0 and loss 0.0550801046192646\n",
      "mini batch accuracy:0.95 and loss 0.1630682647228241\n",
      "mini batch accuracy:0.9 and loss 0.1214531809091568\n",
      "mini batch accuracy:0.85 and loss 0.307319700717926\n",
      "mini batch accuracy:0.95 and loss 0.07544460147619247\n",
      "mini batch accuracy:0.95 and loss 0.20614340901374817\n",
      "mini batch accuracy:1.0 and loss 0.007918357849121094\n",
      "mini batch accuracy:1.0 and loss 0.009434318169951439\n",
      "mini batch accuracy:1.0 and loss 0.0014656782150268555\n",
      "mini batch accuracy:0.95 and loss 0.26158037781715393\n",
      "mini batch accuracy:0.9 and loss 0.3366548717021942\n",
      "Epoch [10/10] with accuracy of0.9441818181818182 and loss0.3366548717021942\n"
     ]
    }
   ],
   "source": [
    "num_epoch=10\n",
    "\n",
    "for x in range(num_epoch):\n",
    "    acc=[]\n",
    "    n=0\n",
    "    for data,target in training_data:\n",
    "        mini_acc=[]\n",
    "        data,target = data.to(device),target.to(device)\n",
    "        model.train()\n",
    "        preds = model(data)\n",
    "        loss = losses(preds,target)\n",
    "        loss.backward()\n",
    "        opi.step()\n",
    "        opi.zero_grad()\n",
    "        __,predicts = torch.max(preds,dim=1)\n",
    "        acc.append(torch.sum(predicts==target).item())\n",
    "        mini_acc = torch.sum(predicts==target).item()/len(target)\n",
    "        n+=1\n",
    "        #print(mini_acc)\n",
    "        if n%10==0:\n",
    "            print(\"mini batch accuracy:{} and loss {}\".format(mini_acc,loss.item()))\n",
    "        \n",
    "    if (x+1)%1==0:\n",
    "        print(\"Epoch [{}/{}] with accuracy of{} and loss{}\".format(x+1,num_epoch,sum(acc)/train,loss.item()))\n",
    "        \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9231818181818189, 0.935909090909092, 0.9504545454545466, 0.9440909090909099, 0.947272727272728, 0.9590909090909099, 0.9577272727272739, 0.940909090909092, 0.9359090909090918, 0.9472727272727282]\n",
      "[array([0.95, 1.  , 0.9 , 0.8 , 0.85, 0.9 , 1.  , 1.  , 1.  , 0.9 , 0.95,\n",
      "       0.95, 0.95, 0.9 , 0.9 , 0.95, 1.  , 1.  , 0.85, 0.8 , 0.9 , 0.95,\n",
      "       0.9 , 0.95, 0.9 , 0.9 , 0.95, 1.  , 0.95, 0.95, 0.85, 0.8 , 0.85,\n",
      "       0.85, 0.85, 0.95, 1.  , 1.  , 0.8 , 0.9 , 0.85, 0.9 , 0.95, 0.9 ,\n",
      "       0.95, 0.9 , 1.  , 0.9 , 0.85, 0.85, 0.95, 1.  , 0.9 , 1.  , 0.7 ,\n",
      "       0.9 , 0.95, 0.95, 0.9 , 0.95, 0.85, 0.85, 0.9 , 1.  , 1.  , 0.9 ,\n",
      "       0.85, 0.9 , 0.8 , 0.85, 1.  , 0.9 , 0.95, 0.9 , 0.95, 0.85, 0.95,\n",
      "       0.95, 0.8 , 1.  , 0.95, 1.  , 0.85, 1.  , 1.  , 0.95, 0.95, 0.95,\n",
      "       0.95, 1.  , 0.95, 0.9 , 0.95, 1.  , 0.95, 1.  , 0.9 , 0.9 , 0.9 ,\n",
      "       1.  , 1.  , 0.95, 0.8 , 1.  , 0.9 , 0.95, 0.9 , 0.95, 0.95, 0.95]), array([0.95, 0.95, 1.  , 0.95, 0.95, 1.  , 0.95, 0.85, 0.95, 0.9 , 0.95,\n",
      "       0.9 , 0.9 , 1.  , 1.  , 1.  , 1.  , 0.9 , 0.95, 0.95, 1.  , 0.9 ,\n",
      "       0.9 , 0.8 , 1.  , 0.95, 0.95, 0.95, 1.  , 0.95, 0.95, 1.  , 0.95,\n",
      "       0.95, 0.9 , 0.85, 0.95, 0.85, 0.95, 0.9 , 0.95, 0.85, 0.95, 0.95,\n",
      "       0.9 , 0.9 , 0.85, 0.85, 1.  , 0.95, 1.  , 0.9 , 1.  , 0.85, 1.  ,\n",
      "       0.9 , 0.95, 0.85, 0.95, 0.75, 0.9 , 0.9 , 0.9 , 0.95, 1.  , 0.95,\n",
      "       1.  , 0.95, 0.9 , 0.95, 0.95, 0.9 , 0.95, 0.9 , 1.  , 0.95, 0.9 ,\n",
      "       0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.8 , 0.95, 0.95, 1.  , 0.9 ,\n",
      "       1.  , 0.95, 0.9 , 0.95, 0.95, 1.  , 1.  , 0.95, 1.  , 1.  , 0.9 ,\n",
      "       0.95, 0.9 , 0.95, 0.95, 0.85, 1.  , 0.9 , 1.  , 0.9 , 0.95, 0.9 ]), array([0.8 , 0.9 , 0.9 , 1.  , 1.  , 0.85, 0.85, 0.95, 1.  , 0.95, 0.95,\n",
      "       1.  , 0.9 , 0.9 , 0.95, 0.85, 1.  , 1.  , 0.9 , 0.95, 0.9 , 1.  ,\n",
      "       0.75, 1.  , 1.  , 0.9 , 1.  , 0.95, 1.  , 0.95, 1.  , 0.95, 0.95,\n",
      "       0.95, 1.  , 1.  , 0.95, 0.9 , 0.9 , 0.95, 0.95, 1.  , 0.95, 0.9 ,\n",
      "       1.  , 0.95, 0.95, 0.95, 0.95, 1.  , 0.95, 0.95, 0.95, 0.95, 0.95,\n",
      "       0.85, 0.85, 1.  , 0.95, 0.95, 0.95, 1.  , 0.95, 1.  , 0.95, 0.95,\n",
      "       1.  , 0.95, 1.  , 1.  , 0.95, 0.95, 0.95, 0.85, 0.9 , 1.  , 0.9 ,\n",
      "       0.95, 0.95, 0.9 , 0.95, 1.  , 1.  , 1.  , 0.9 , 0.95, 1.  , 0.95,\n",
      "       0.95, 1.  , 0.95, 1.  , 1.  , 1.  , 0.95, 1.  , 0.95, 0.9 , 1.  ,\n",
      "       1.  , 0.9 , 0.9 , 0.9 , 1.  , 0.95, 0.95, 1.  , 1.  , 0.95, 0.95]), array([0.9 , 0.95, 1.  , 0.95, 0.95, 0.95, 0.9 , 1.  , 0.85, 1.  , 0.95,\n",
      "       1.  , 1.  , 1.  , 0.95, 0.95, 1.  , 0.95, 0.95, 1.  , 0.9 , 0.95,\n",
      "       0.8 , 1.  , 0.95, 1.  , 0.9 , 1.  , 1.  , 0.95, 0.95, 0.95, 1.  ,\n",
      "       1.  , 0.85, 0.95, 1.  , 1.  , 0.9 , 0.9 , 0.95, 0.8 , 0.95, 0.95,\n",
      "       0.95, 0.9 , 0.95, 0.95, 0.95, 1.  , 1.  , 0.95, 1.  , 0.95, 0.95,\n",
      "       1.  , 0.9 , 0.9 , 0.95, 0.95, 0.9 , 0.95, 1.  , 1.  , 0.95, 0.9 ,\n",
      "       0.85, 0.95, 0.9 , 0.95, 1.  , 0.85, 0.95, 0.95, 0.95, 0.95, 0.95,\n",
      "       1.  , 1.  , 0.9 , 1.  , 0.8 , 0.95, 0.95, 0.85, 0.95, 0.85, 0.9 ,\n",
      "       0.9 , 0.95, 0.95, 0.85, 0.85, 1.  , 0.9 , 0.95, 0.95, 0.95, 1.  ,\n",
      "       1.  , 1.  , 1.  , 0.9 , 0.95, 0.85, 0.9 , 0.95, 0.9 , 1.  , 1.  ]), array([0.95, 0.9 , 0.95, 1.  , 0.9 , 0.95, 1.  , 0.9 , 0.85, 0.95, 1.  ,\n",
      "       0.9 , 0.85, 0.9 , 0.95, 0.9 , 1.  , 0.9 , 0.9 , 1.  , 0.95, 0.95,\n",
      "       0.9 , 0.9 , 0.95, 0.85, 0.95, 0.95, 0.95, 0.85, 0.95, 1.  , 1.  ,\n",
      "       1.  , 1.  , 0.95, 1.  , 0.95, 0.95, 0.95, 0.95, 0.85, 1.  , 1.  ,\n",
      "       0.85, 1.  , 1.  , 0.95, 0.95, 0.95, 0.95, 1.  , 0.95, 1.  , 0.9 ,\n",
      "       0.9 , 0.9 , 0.95, 0.95, 1.  , 1.  , 1.  , 1.  , 1.  , 0.95, 0.85,\n",
      "       0.85, 0.95, 0.95, 1.  , 0.85, 1.  , 0.9 , 0.9 , 1.  , 0.95, 0.95,\n",
      "       0.95, 0.95, 0.9 , 0.95, 0.95, 1.  , 0.9 , 1.  , 1.  , 0.95, 0.85,\n",
      "       0.95, 1.  , 0.95, 0.9 , 1.  , 1.  , 0.95, 0.95, 1.  , 0.95, 0.95,\n",
      "       0.95, 0.85, 0.85, 0.95, 1.  , 1.  , 1.  , 0.95, 1.  , 0.95, 1.  ]), array([1.  , 0.95, 0.95, 0.95, 0.85, 1.  , 1.  , 1.  , 0.9 , 0.95, 1.  ,\n",
      "       1.  , 1.  , 0.95, 1.  , 0.9 , 0.95, 0.95, 0.95, 0.95, 1.  , 0.9 ,\n",
      "       1.  , 1.  , 0.95, 0.95, 0.95, 1.  , 0.95, 0.95, 1.  , 0.85, 0.95,\n",
      "       1.  , 0.95, 0.9 , 0.95, 0.95, 0.95, 0.85, 0.95, 1.  , 1.  , 0.95,\n",
      "       1.  , 0.95, 1.  , 0.9 , 1.  , 0.85, 0.95, 0.9 , 0.9 , 0.95, 0.95,\n",
      "       1.  , 1.  , 0.9 , 1.  , 1.  , 1.  , 1.  , 1.  , 0.95, 0.95, 0.95,\n",
      "       0.95, 0.95, 1.  , 0.9 , 1.  , 1.  , 0.95, 0.95, 1.  , 0.85, 0.95,\n",
      "       0.9 , 1.  , 1.  , 0.9 , 0.9 , 0.9 , 1.  , 0.95, 1.  , 0.95, 1.  ,\n",
      "       1.  , 1.  , 1.  , 0.95, 1.  , 0.95, 1.  , 0.85, 0.9 , 1.  , 1.  ,\n",
      "       1.  , 0.9 , 0.95, 1.  , 1.  , 0.95, 0.95, 1.  , 1.  , 0.95, 0.95]), array([0.95, 0.95, 0.95, 1.  , 0.95, 0.9 , 1.  , 0.95, 1.  , 1.  , 1.  ,\n",
      "       1.  , 1.  , 0.95, 0.95, 1.  , 1.  , 1.  , 1.  , 0.95, 1.  , 0.9 ,\n",
      "       1.  , 1.  , 1.  , 0.9 , 1.  , 0.9 , 1.  , 0.85, 0.95, 0.95, 0.9 ,\n",
      "       0.95, 0.95, 0.9 , 1.  , 1.  , 0.9 , 0.95, 0.95, 0.9 , 0.95, 0.9 ,\n",
      "       0.95, 0.95, 0.95, 0.9 , 0.9 , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
      "       0.95, 1.  , 1.  , 0.9 , 0.95, 1.  , 0.85, 1.  , 0.95, 0.9 , 0.95,\n",
      "       1.  , 1.  , 1.  , 1.  , 0.9 , 0.95, 1.  , 0.95, 0.9 , 0.9 , 0.95,\n",
      "       0.95, 1.  , 0.9 , 0.95, 0.95, 0.95, 1.  , 1.  , 0.95, 1.  , 0.95,\n",
      "       1.  , 1.  , 0.95, 0.95, 0.95, 1.  , 0.95, 0.95, 0.9 , 1.  , 0.95,\n",
      "       0.9 , 0.95, 1.  , 0.9 , 0.95, 0.95, 0.95, 0.95, 0.9 , 0.9 , 0.95]), array([0.9 , 0.95, 1.  , 0.95, 0.9 , 0.95, 0.9 , 0.95, 0.95, 0.95, 0.95,\n",
      "       1.  , 1.  , 0.9 , 0.95, 0.95, 0.95, 1.  , 1.  , 0.9 , 0.85, 1.  ,\n",
      "       0.85, 0.9 , 0.9 , 0.95, 1.  , 1.  , 0.9 , 0.95, 0.85, 0.85, 0.95,\n",
      "       0.95, 0.95, 0.95, 0.9 , 0.95, 0.9 , 0.9 , 0.95, 0.9 , 0.95, 0.95,\n",
      "       1.  , 0.95, 0.8 , 1.  , 0.85, 0.95, 0.85, 1.  , 1.  , 0.9 , 0.9 ,\n",
      "       0.95, 0.9 , 0.95, 0.95, 0.95, 0.85, 1.  , 1.  , 0.95, 1.  , 0.85,\n",
      "       1.  , 1.  , 1.  , 0.9 , 0.95, 0.95, 1.  , 1.  , 0.85, 0.95, 0.95,\n",
      "       0.9 , 1.  , 1.  , 0.9 , 1.  , 0.95, 1.  , 0.95, 0.95, 1.  , 0.9 ,\n",
      "       1.  , 0.95, 0.9 , 0.95, 0.8 , 0.9 , 0.9 , 0.95, 1.  , 1.  , 0.95,\n",
      "       0.9 , 0.9 , 0.95, 0.95, 0.95, 0.95, 1.  , 0.9 , 0.95, 0.95, 0.95]), array([0.95, 0.95, 0.95, 0.95, 0.9 , 0.85, 0.85, 0.9 , 1.  , 1.  , 0.95,\n",
      "       0.95, 1.  , 0.85, 0.95, 0.95, 0.95, 1.  , 0.95, 1.  , 0.95, 0.9 ,\n",
      "       0.95, 0.85, 0.9 , 0.9 , 1.  , 0.95, 0.85, 0.95, 0.95, 0.95, 1.  ,\n",
      "       0.85, 1.  , 0.95, 1.  , 1.  , 0.9 , 0.9 , 0.8 , 0.95, 0.95, 0.95,\n",
      "       0.9 , 0.95, 0.95, 0.85, 0.85, 0.8 , 0.9 , 0.95, 1.  , 1.  , 0.95,\n",
      "       0.95, 0.9 , 0.95, 0.95, 0.95, 0.95, 0.85, 1.  , 0.95, 0.9 , 0.9 ,\n",
      "       0.85, 0.95, 0.9 , 0.95, 0.9 , 1.  , 0.95, 0.95, 0.85, 1.  , 0.95,\n",
      "       1.  , 1.  , 0.95, 0.95, 0.9 , 0.85, 0.8 , 1.  , 0.9 , 0.9 , 0.9 ,\n",
      "       1.  , 0.95, 0.95, 0.95, 0.95, 1.  , 1.  , 1.  , 1.  , 1.  , 0.9 ,\n",
      "       0.9 , 0.9 , 0.9 , 0.95, 0.85, 0.95, 1.  , 0.9 , 1.  , 0.95, 1.  ]), array([1.  , 0.9 , 1.  , 0.9 , 1.  , 0.9 , 0.95, 1.  , 0.9 , 1.  , 1.  ,\n",
      "       0.95, 1.  , 0.9 , 1.  , 0.9 , 1.  , 1.  , 0.95, 0.95, 0.95, 1.  ,\n",
      "       1.  , 0.9 , 0.9 , 1.  , 0.95, 1.  , 0.95, 0.9 , 0.9 , 1.  , 0.9 ,\n",
      "       0.9 , 0.9 , 0.8 , 0.95, 0.9 , 0.95, 0.85, 1.  , 1.  , 0.95, 0.9 ,\n",
      "       0.95, 1.  , 0.85, 1.  , 1.  , 0.95, 0.95, 0.85, 0.95, 0.85, 1.  ,\n",
      "       1.  , 0.95, 1.  , 0.95, 0.95, 0.95, 1.  , 0.95, 1.  , 0.95, 1.  ,\n",
      "       0.85, 0.95, 1.  , 1.  , 0.95, 1.  , 0.9 , 0.95, 1.  , 0.95, 0.95,\n",
      "       0.85, 0.95, 1.  , 1.  , 0.95, 0.85, 1.  , 0.95, 1.  , 0.95, 0.9 ,\n",
      "       0.9 , 1.  , 0.95, 0.9 , 1.  , 0.95, 0.95, 0.9 , 1.  , 1.  , 0.9 ,\n",
      "       0.95, 1.  , 0.9 , 0.8 , 0.95, 0.85, 0.95, 0.9 , 1.  , 0.95, 0.9 ])]\n",
      "[0.95, 1.0, 0.9, 0.8, 0.85, 0.9, 1.0, 1.0, 1.0, 0.9, 0.95, 0.95, 0.95, 0.9, 0.9, 0.95, 1.0, 1.0, 0.85, 0.8, 0.9, 0.95, 0.9, 0.95, 0.9, 0.9, 0.95, 1.0, 0.95, 0.95, 0.85, 0.8, 0.85, 0.85, 0.85, 0.95, 1.0, 1.0, 0.8, 0.9, 0.85, 0.9, 0.95, 0.9, 0.95, 0.9, 1.0, 0.9, 0.85, 0.85, 0.95, 1.0, 0.9, 1.0, 0.7, 0.9, 0.95, 0.95, 0.9, 0.95, 0.85, 0.85, 0.9, 1.0, 1.0, 0.9, 0.85, 0.9, 0.8, 0.85, 1.0, 0.9, 0.95, 0.9, 0.95, 0.85, 0.95, 0.95, 0.8, 1.0, 0.95, 1.0, 0.85, 1.0, 1.0, 0.95, 0.95, 0.95, 0.95, 1.0, 0.95, 0.9, 0.95, 1.0, 0.95, 1.0, 0.9, 0.9, 0.9, 1.0, 1.0, 0.95, 0.8, 1.0, 0.9, 0.95, 0.9, 0.95, 0.95, 0.95, 0.95, 0.95, 1.0, 0.95, 0.95, 1.0, 0.95, 0.85, 0.95, 0.9, 0.95, 0.9, 0.9, 1.0, 1.0, 1.0, 1.0, 0.9, 0.95, 0.95, 1.0, 0.9, 0.9, 0.8, 1.0, 0.95, 0.95, 0.95, 1.0, 0.95, 0.95, 1.0, 0.95, 0.95, 0.9, 0.85, 0.95, 0.85, 0.95, 0.9, 0.95, 0.85, 0.95, 0.95, 0.9, 0.9, 0.85, 0.85, 1.0, 0.95, 1.0, 0.9, 1.0, 0.85, 1.0, 0.9, 0.95, 0.85, 0.95, 0.75, 0.9, 0.9, 0.9, 0.95, 1.0, 0.95, 1.0, 0.95, 0.9, 0.95, 0.95, 0.9, 0.95, 0.9, 1.0, 0.95, 0.9, 0.95, 0.95, 0.95, 0.95, 0.85, 0.95, 0.8, 0.95, 0.95, 1.0, 0.9, 1.0, 0.95, 0.9, 0.95, 0.95, 1.0, 1.0, 0.95, 1.0, 1.0, 0.9, 0.95, 0.9, 0.95, 0.95, 0.85, 1.0, 0.9, 1.0, 0.9, 0.95, 0.9, 0.8, 0.9, 0.9, 1.0, 1.0, 0.85, 0.85, 0.95, 1.0, 0.95, 0.95, 1.0, 0.9, 0.9, 0.95, 0.85, 1.0, 1.0, 0.9, 0.95, 0.9, 1.0, 0.75, 1.0, 1.0, 0.9, 1.0, 0.95, 1.0, 0.95, 1.0, 0.95, 0.95, 0.95, 1.0, 1.0, 0.95, 0.9, 0.9, 0.95, 0.95, 1.0, 0.95, 0.9, 1.0, 0.95, 0.95, 0.95, 0.95, 1.0, 0.95, 0.95, 0.95, 0.95, 0.95, 0.85, 0.85, 1.0, 0.95, 0.95, 0.95, 1.0, 0.95, 1.0, 0.95, 0.95, 1.0, 0.95, 1.0, 1.0, 0.95, 0.95, 0.95, 0.85, 0.9, 1.0, 0.9, 0.95, 0.95, 0.9, 0.95, 1.0, 1.0, 1.0, 0.9, 0.95, 1.0, 0.95, 0.95, 1.0, 0.95, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 0.9, 1.0, 1.0, 0.9, 0.9, 0.9, 1.0, 0.95, 0.95, 1.0, 1.0, 0.95, 0.95, 0.9, 0.95, 1.0, 0.95, 0.95, 0.95, 0.9, 1.0, 0.85, 1.0, 0.95, 1.0, 1.0, 1.0, 0.95, 0.95, 1.0, 0.95, 0.95, 1.0, 0.9, 0.95, 0.8, 1.0, 0.95, 1.0, 0.9, 1.0, 1.0, 0.95, 0.95, 0.95, 1.0, 1.0, 0.85, 0.95, 1.0, 1.0, 0.9, 0.9, 0.95, 0.8, 0.95, 0.95, 0.95, 0.9, 0.95, 0.95, 0.95, 1.0, 1.0, 0.95, 1.0, 0.95, 0.95, 1.0, 0.9, 0.9, 0.95, 0.95, 0.9, 0.95, 1.0, 1.0, 0.95, 0.9, 0.85, 0.95, 0.9, 0.95, 1.0, 0.85, 0.95, 0.95, 0.95, 0.95, 0.95, 1.0, 1.0, 0.9, 1.0, 0.8, 0.95, 0.95, 0.85, 0.95, 0.85, 0.9, 0.9, 0.95, 0.95, 0.85, 0.85, 1.0, 0.9, 0.95, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 0.95, 0.85, 0.9, 0.95, 0.9, 1.0, 1.0, 0.95, 0.9, 0.95, 1.0, 0.9, 0.95, 1.0, 0.9, 0.85, 0.95, 1.0, 0.9, 0.85, 0.9, 0.95, 0.9, 1.0, 0.9, 0.9, 1.0, 0.95, 0.95, 0.9, 0.9, 0.95, 0.85, 0.95, 0.95, 0.95, 0.85, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 0.95, 0.95, 0.95, 0.85, 1.0, 1.0, 0.85, 1.0, 1.0, 0.95, 0.95, 0.95, 0.95, 1.0, 0.95, 1.0, 0.9, 0.9, 0.9, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 0.85, 0.85, 0.95, 0.95, 1.0, 0.85, 1.0, 0.9, 0.9, 1.0, 0.95, 0.95, 0.95, 0.95, 0.9, 0.95, 0.95, 1.0, 0.9, 1.0, 1.0, 0.95, 0.85, 0.95, 1.0, 0.95, 0.9, 1.0, 1.0, 0.95, 0.95, 1.0, 0.95, 0.95, 0.95, 0.85, 0.85, 0.95, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 1.0, 1.0, 0.95, 0.95, 0.95, 0.85, 1.0, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 1.0, 0.95, 1.0, 0.9, 0.95, 0.95, 0.95, 0.95, 1.0, 0.9, 1.0, 1.0, 0.95, 0.95, 0.95, 1.0, 0.95, 0.95, 1.0, 0.85, 0.95, 1.0, 0.95, 0.9, 0.95, 0.95, 0.95, 0.85, 0.95, 1.0, 1.0, 0.95, 1.0, 0.95, 1.0, 0.9, 1.0, 0.85, 0.95, 0.9, 0.9, 0.95, 0.95, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 0.95, 0.95, 0.95, 0.95, 1.0, 0.9, 1.0, 1.0, 0.95, 0.95, 1.0, 0.85, 0.95, 0.9, 1.0, 1.0, 0.9, 0.9, 0.9, 1.0, 0.95, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 0.95, 1.0, 0.85, 0.9, 1.0, 1.0, 1.0, 0.9, 0.95, 1.0, 1.0, 0.95, 0.95, 1.0, 1.0, 0.95, 0.95, 0.95, 0.95, 0.95, 1.0, 0.95, 0.9, 1.0, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 0.9, 1.0, 1.0, 1.0, 0.9, 1.0, 0.9, 1.0, 0.85, 0.95, 0.95, 0.9, 0.95, 0.95, 0.9, 1.0, 1.0, 0.9, 0.95, 0.95, 0.9, 0.95, 0.9, 0.95, 0.95, 0.95, 0.9, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.95, 1.0, 1.0, 0.9, 0.95, 1.0, 0.85, 1.0, 0.95, 0.9, 0.95, 1.0, 1.0, 1.0, 1.0, 0.9, 0.95, 1.0, 0.95, 0.9, 0.9, 0.95, 0.95, 1.0, 0.9, 0.95, 0.95, 0.95, 1.0, 1.0, 0.95, 1.0, 0.95, 1.0, 1.0, 0.95, 0.95, 0.95, 1.0, 0.95, 0.95, 0.9, 1.0, 0.95, 0.9, 0.95, 1.0, 0.9, 0.95, 0.95, 0.95, 0.95, 0.9, 0.9, 0.95, 0.9, 0.95, 1.0, 0.95, 0.9, 0.95, 0.9, 0.95, 0.95, 0.95, 0.95, 1.0, 1.0, 0.9, 0.95, 0.95, 0.95, 1.0, 1.0, 0.9, 0.85, 1.0, 0.85, 0.9, 0.9, 0.95, 1.0, 1.0, 0.9, 0.95, 0.85, 0.85, 0.95, 0.95, 0.95, 0.95, 0.9, 0.95, 0.9, 0.9, 0.95, 0.9, 0.95, 0.95, 1.0, 0.95, 0.8, 1.0, 0.85, 0.95, 0.85, 1.0, 1.0, 0.9, 0.9, 0.95, 0.9, 0.95, 0.95, 0.95, 0.85, 1.0, 1.0, 0.95, 1.0, 0.85, 1.0, 1.0, 1.0, 0.9, 0.95, 0.95, 1.0, 1.0, 0.85, 0.95, 0.95, 0.9, 1.0, 1.0, 0.9, 1.0, 0.95, 1.0, 0.95, 0.95, 1.0, 0.9, 1.0, 0.95, 0.9, 0.95, 0.8, 0.9, 0.9, 0.95, 1.0, 1.0, 0.95, 0.9, 0.9, 0.95, 0.95, 0.95, 0.95, 1.0, 0.9, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.9, 0.85, 0.85, 0.9, 1.0, 1.0, 0.95, 0.95, 1.0, 0.85, 0.95, 0.95, 0.95, 1.0, 0.95, 1.0, 0.95, 0.9, 0.95, 0.85, 0.9, 0.9, 1.0, 0.95, 0.85, 0.95, 0.95, 0.95, 1.0, 0.85, 1.0, 0.95, 1.0, 1.0, 0.9, 0.9, 0.8, 0.95, 0.95, 0.95, 0.9, 0.95, 0.95, 0.85, 0.85, 0.8, 0.9, 0.95, 1.0, 1.0, 0.95, 0.95, 0.9, 0.95, 0.95, 0.95, 0.95, 0.85, 1.0, 0.95, 0.9, 0.9, 0.85, 0.95, 0.9, 0.95, 0.9, 1.0, 0.95, 0.95, 0.85, 1.0, 0.95, 1.0, 1.0, 0.95, 0.95, 0.9, 0.85, 0.8, 1.0, 0.9, 0.9, 0.9, 1.0, 0.95, 0.95, 0.95, 0.95, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 0.9, 0.9, 0.9, 0.95, 0.85, 0.95, 1.0, 0.9, 1.0, 0.95, 1.0, 1.0, 0.9, 1.0, 0.9, 1.0, 0.9, 0.95, 1.0, 0.9, 1.0, 1.0, 0.95, 1.0, 0.9, 1.0, 0.9, 1.0, 1.0, 0.95, 0.95, 0.95, 1.0, 1.0, 0.9, 0.9, 1.0, 0.95, 1.0, 0.95, 0.9, 0.9, 1.0, 0.9, 0.9, 0.9, 0.8, 0.95, 0.9, 0.95, 0.85, 1.0, 1.0, 0.95, 0.9, 0.95, 1.0, 0.85, 1.0, 1.0, 0.95, 0.95, 0.85, 0.95, 0.85, 1.0, 1.0, 0.95, 1.0, 0.95, 0.95, 0.95, 1.0, 0.95, 1.0, 0.95, 1.0, 0.85, 0.95, 1.0, 1.0, 0.95, 1.0, 0.9, 0.95, 1.0, 0.95, 0.95, 0.85, 0.95, 1.0, 1.0, 0.95, 0.85, 1.0, 0.95, 1.0, 0.95, 0.9, 0.9, 1.0, 0.95, 0.9, 1.0, 0.95, 0.95, 0.9, 1.0, 1.0, 0.9, 0.95, 1.0, 0.9, 0.8, 0.95, 0.85, 0.95, 0.9, 1.0, 0.95, 0.9]\n"
     ]
    }
   ],
   "source": [
    "mini_accc=[]\n",
    "for x in acc:\n",
    "    mini_accc.append(x/20)\n",
    "len(mini_accc)\n",
    "\n",
    "a = np.array_split(mini_accc,10)\n",
    "hist=[]\n",
    "for x in a:\n",
    "    c=sum(x)/110\n",
    "    hist.append(c)\n",
    "print(hist)\n",
    "print(a)\n",
    "print(mini_accc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19,\n",
       " 20,\n",
       " 18,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 17,\n",
       " 16,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 16,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 16,\n",
       " 18,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 20,\n",
       " 18,\n",
       " 17,\n",
       " 17,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 14,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 17,\n",
       " 18,\n",
       " 16,\n",
       " 17,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 17,\n",
       " 19,\n",
       " 19,\n",
       " 16,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 17,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 16,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 17,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 16,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 17,\n",
       " 19,\n",
       " 17,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 17,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 17,\n",
       " 17,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 17,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 17,\n",
       " 19,\n",
       " 15,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 19,\n",
       " 16,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 16,\n",
       " 18,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 17,\n",
       " 17,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 17,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 20,\n",
       " 15,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 17,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 18,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 20,\n",
       " 17,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 16,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 17,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 16,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 17,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 17,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 16,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 19,\n",
       " 17,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 17,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 17,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 17,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 20,\n",
       " 20,\n",
       " 17,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 17,\n",
       " 17,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 17,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 17,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 17,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 17,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 17,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 17,\n",
       " 19,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 17,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 17,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 17,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 17,\n",
       " 20,\n",
       " 17,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 17,\n",
       " 17,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 16,\n",
       " 20,\n",
       " 17,\n",
       " 19,\n",
       " 17,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 17,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 17,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 16,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 17,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 17,\n",
       " 18,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 17,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 17,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 16,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 17,\n",
       " 16,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 18,\n",
       " 17,\n",
       " 19,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 17,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 18,\n",
       " 17,\n",
       " 16,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 17,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 20,\n",
       " ...]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95 1.   0.9  0.8  0.85 0.9  1.   1.   1.   0.9  0.95 0.95 0.95 0.9\n",
      " 0.9  0.95 1.   1.   0.85 0.8  0.9  0.95 0.9  0.95 0.9  0.9  0.95 1.\n",
      " 0.95 0.95 0.85 0.8  0.85 0.85 0.85 0.95 1.   1.   0.8  0.9  0.85 0.9\n",
      " 0.95 0.9  0.95 0.9  1.   0.9  0.85 0.85 0.95 1.   0.9  1.   0.7  0.9\n",
      " 0.95 0.95 0.9  0.95 0.85 0.85 0.9  1.   1.   0.9  0.85 0.9  0.8  0.85\n",
      " 1.   0.9  0.95 0.9  0.95 0.85 0.95 0.95 0.8  1.   0.95 1.   0.85 1.\n",
      " 1.   0.95 0.95 0.95 0.95 1.   0.95 0.9  0.95 1.   0.95 1.   0.9  0.9\n",
      " 0.9  1.   1.   0.95 0.8  1.   0.9  0.95 0.9  0.95 0.95 0.95]\n"
     ]
    }
   ],
   "source": [
    "for x in a:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on testdata is:0.8827470686767169\n"
     ]
    }
   ],
   "source": [
    "###test###\n",
    "with torch.no_grad():\n",
    "    result=[]\n",
    "    for x,y in testing_data:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        model.eval()\n",
    "        prediction=model(x)\n",
    "        __,predict=torch.max(prediction,dim=1)\n",
    "        result.append(torch.sum(predict==y).item())\n",
    "    print(\"Performance on testdata is:{}\".format(sum(result)/test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
