{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load rawdata using Pandas\n",
    "data = pd.read_csv('airfares.csv')\n",
    "data2 = pd.read_csv('holidays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ID</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>46.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>68.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>77.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>57.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>43.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  ID  Price\n",
       "0  2017-01-01   0  46.91\n",
       "1  2017-01-01   1  68.12\n",
       "2  2017-01-01   2  77.69\n",
       "3  2017-01-01   3  57.44\n",
       "4  2017-01-01   4  43.88"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get year and month only from \"Date\" column\n",
    "def spliter(data):\n",
    "    a,b,c = data.split('-')\n",
    "    return a+'-'+b\n",
    "\n",
    "# Function to calculate average monthly price and add in \"Term\" data\n",
    "def monthly_average_with_term(df1,df2):\n",
    "    period = df1['Date'].apply(spliter)\n",
    "    df1['Year-Month'] = period\n",
    "    data = df1.groupby('Year-Month')\n",
    "    data = data.mean()\n",
    "    df2.columns=['Year-Month','Term']\n",
    "    final = pd.merge(data, df2, on=\"Year-Month\")\n",
    "    del final['ID']\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year-Month      Price  Term\n",
      "0     2017-01  58.551110     0\n",
      "1     2017-02  59.792207     0\n",
      "2     2017-03  82.417306     1\n",
      "3     2017-04  59.822363     0\n",
      "4     2017-05  64.695732     0\n",
      "5     2017-06  61.664843     2\n",
      "6     2017-07  59.031855     0\n",
      "7     2017-08  54.484890     0\n",
      "8     2017-09  71.092687     3\n",
      "9     2017-10  63.358058     0\n",
      "10    2017-11  62.707230     0\n",
      "11    2017-12  84.881152     4\n",
      "12    2018-01  59.918052     0\n",
      "13    2018-02  63.873096     0\n",
      "14    2018-03  78.880468     1\n",
      "15    2018-04  61.793867     0\n",
      "16    2018-05  60.951487     0\n",
      "17    2018-06  69.653710     2\n",
      "18    2018-07  62.716990     0\n",
      "19    2018-08  61.644003     0\n",
      "20    2018-09  72.645490     3\n",
      "21    2018-10  68.648984     0\n",
      "22    2018-11  66.377553     0\n",
      "23    2018-12  92.485945     4\n",
      "24    2019-01  59.988210     0\n",
      "25    2019-02  60.409186     0\n",
      "26    2019-03  60.937274     0\n",
      "27    2019-04  75.562997     1\n",
      "28    2019-05  56.166297     0\n",
      "29    2019-06  64.860803     2\n",
      "30    2019-07  60.743268     0\n",
      "31    2019-08  58.546726     0\n",
      "32    2019-09  68.253587     3\n",
      "33    2019-10  61.389658     0\n",
      "34    2019-11  62.868093     0\n",
      "35    2019-12  88.348990     4\n",
      "Length:  36\n"
     ]
    }
   ],
   "source": [
    "# New output with three fields only: year-month, average monthly price and term\n",
    "df=monthly_average_with_term(data,data2)\n",
    "\n",
    "print(df)\n",
    "print('Length: ',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "aaa = np.array(list(df['Price']))\n",
    "scaler.fit(aaa.reshape(-1,1)[:26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1070028 ],\n",
       "       [0.13966236],\n",
       "       [0.73504318],\n",
       "       [0.14045592],\n",
       "       [0.26869891],\n",
       "       [0.18894089],\n",
       "       [0.11965364],\n",
       "       [0.        ],\n",
       "       [0.43703514],\n",
       "       [0.23349793]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_price = scaler.transform(aaa.reshape(-1,1))\n",
    "scaled_price[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of training data ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "#To convert year-month into numbers as it is quantitative feature\n",
    "# period_data = pd.to_datetime(dataset['Year-Month'])\n",
    "# period = period_data.map(dt.datetime.toordinal)\n",
    "\n",
    "# To convert 'Holidays Terms' into one hot vector as it is categorical data\n",
    "# Then to combine with the above quantitative feature to form training data\n",
    "for x,y in zip(df['Term'],scaled_price):#df['Price']):\n",
    "    one_hot = [0]*5\n",
    "    one_hot[x] = 1\n",
    "    one_hot.append(y)\n",
    "    X.append(one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=[]\n",
    "label=[]\n",
    "for z,y in enumerate(X):\n",
    "    if z<32:\n",
    "        dataset.append(X[z:z+4])\n",
    "        label.append(X[z+4][-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.tensor(dataset[:26],dtype=torch.float32),\n",
    "                           torch.tensor(label[:26],dtype=torch.float32))\n",
    "test_data = TensorDataset(torch.tensor(dataset[26:],dtype=torch.float32),\n",
    "                         torch.tensor(label[26:],dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "train = DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
    "test = DataLoader(test_data,batch_size=10,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLSTM(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,output_dim):\n",
    "        super(myLSTM,self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = nn.Dropout(0.5,inplace=True)\n",
    "        self.LSTM = nn.LSTM(input_dim,hidden_dim,num_layers=2,bidirectional=True,batch_first=True,dropout=0.5)\n",
    "        self.linear = nn.Linear(hidden_dim*2,1)\n",
    "    \n",
    "    def forward(self,data):\n",
    "        output,(hidden,cell) = self.LSTM(data)\n",
    "        hidden2 = self.dropout(torch.cat((hidden[-1,:,:],hidden[-2,:,:]),dim=1))\n",
    "        out = self.linear(hidden2)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = myLSTM(6,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fun = F.mse_loss\n",
    "\n",
    "loss_fun = nn.L1Loss(reduction='mean')\n",
    "opt = torch.optim.Adam(mymodel.parameters(),lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 training loss: 2.0222803130745888\n",
      "epoch 40 training loss: 2.043647348880768\n",
      "test_loss for epoch 40 is 0.18161650002002716\n",
      "epoch 60 training loss: 1.768291749060154\n",
      "epoch 80 training loss: 1.9493482932448387\n",
      "test_loss for epoch 80 is 0.13469968736171722\n",
      "epoch 100 training loss: 1.8477842509746552\n",
      "epoch 120 training loss: 1.6590181812644005\n",
      "test_loss for epoch 120 is 0.1031985878944397\n",
      "epoch 140 training loss: 1.8600210100412369\n",
      "epoch 160 training loss: 1.5221568420529366\n",
      "test_loss for epoch 160 is 0.10615455359220505\n",
      "epoch 180 training loss: 1.5318097174167633\n",
      "epoch 200 training loss: 1.6389653570950031\n",
      "test_loss for epoch 200 is 0.07475299388170242\n",
      "epoch 220 training loss: 1.413439393043518\n",
      "epoch 240 training loss: 1.5920233950018883\n",
      "test_loss for epoch 240 is 0.08725061267614365\n",
      "epoch 260 training loss: 1.3124487698078156\n",
      "epoch 280 training loss: 1.4397313743829727\n",
      "test_loss for epoch 280 is 0.0779285803437233\n",
      "epoch 300 training loss: 1.370222620666027\n",
      "epoch 320 training loss: 1.7454835772514343\n",
      "test_loss for epoch 320 is 0.08261237293481827\n",
      "epoch 340 training loss: 1.2372876591980457\n",
      "epoch 360 training loss: 1.2200361639261246\n",
      "test_loss for epoch 360 is 0.05338503420352936\n",
      "epoch 380 training loss: 1.1308110132813454\n",
      "epoch 400 training loss: 1.3669271618127823\n",
      "test_loss for epoch 400 is 0.05761096999049187\n",
      "epoch 420 training loss: 1.2716688066720963\n",
      "epoch 440 training loss: 1.3339966088533401\n",
      "test_loss for epoch 440 is 0.05270885303616524\n",
      "epoch 460 training loss: 1.616109848022461\n",
      "epoch 480 training loss: 1.5079722441732883\n",
      "test_loss for epoch 480 is 0.0476788766682148\n",
      "epoch 500 training loss: 1.2511865496635437\n",
      "epoch 520 training loss: 1.5834609046578407\n",
      "test_loss for epoch 520 is 0.07720804214477539\n",
      "epoch 540 training loss: 1.3087519817054272\n",
      "epoch 560 training loss: 1.5538358837366104\n",
      "test_loss for epoch 560 is 0.0701884850859642\n",
      "epoch 580 training loss: 1.5379809588193893\n",
      "epoch 600 training loss: 1.2186033129692078\n",
      "test_loss for epoch 600 is 0.043002497404813766\n",
      "epoch 620 training loss: 1.130217544734478\n",
      "epoch 640 training loss: 1.0507179833948612\n",
      "test_loss for epoch 640 is 0.04987752437591553\n",
      "epoch 660 training loss: 1.126388594508171\n",
      "epoch 680 training loss: 1.2828538566827774\n",
      "test_loss for epoch 680 is 0.07166106253862381\n",
      "epoch 700 training loss: 1.3244468718767166\n",
      "epoch 720 training loss: 1.6176577843725681\n",
      "test_loss for epoch 720 is 0.053668614476919174\n",
      "epoch 740 training loss: 1.4412195533514023\n",
      "epoch 760 training loss: 1.061259001493454\n",
      "test_loss for epoch 760 is 0.0644000917673111\n",
      "epoch 780 training loss: 1.153781644999981\n",
      "epoch 800 training loss: 1.827918291091919\n",
      "test_loss for epoch 800 is 0.0477910190820694\n",
      "epoch 820 training loss: 1.313574194908142\n",
      "epoch 840 training loss: 1.1468094028532505\n",
      "test_loss for epoch 840 is 0.08402123302221298\n",
      "epoch 860 training loss: 1.2398736551404\n",
      "epoch 880 training loss: 1.564530685544014\n",
      "test_loss for epoch 880 is 0.07339267432689667\n",
      "epoch 900 training loss: 1.228239767253399\n",
      "epoch 920 training loss: 1.276175819337368\n",
      "test_loss for epoch 920 is 0.054156024008989334\n",
      "epoch 940 training loss: 1.4917604625225067\n",
      "epoch 960 training loss: 1.4381767772138119\n",
      "test_loss for epoch 960 is 0.09091529995203018\n",
      "epoch 980 training loss: 1.3145429715514183\n",
      "epoch 1000 training loss: 1.4035694003105164\n",
      "test_loss for epoch 1000 is 0.053433384746313095\n",
      "epoch 1020 training loss: 1.2134917974472046\n",
      "epoch 1040 training loss: 1.435781978070736\n",
      "test_loss for epoch 1040 is 0.06198329105973244\n",
      "epoch 1060 training loss: 1.587299920618534\n",
      "epoch 1080 training loss: 1.0209859982132912\n",
      "test_loss for epoch 1080 is 0.0369284562766552\n",
      "epoch 1100 training loss: 1.3012951351702213\n",
      "epoch 1120 training loss: 1.2120216265320778\n",
      "test_loss for epoch 1120 is 0.056813567876815796\n",
      "epoch 1140 training loss: 1.1521293334662914\n",
      "epoch 1160 training loss: 1.0691816955804825\n",
      "test_loss for epoch 1160 is 0.0601327009499073\n",
      "epoch 1180 training loss: 1.2316720336675644\n",
      "epoch 1200 training loss: 1.3514919504523277\n",
      "test_loss for epoch 1200 is 0.07548263669013977\n",
      "epoch 1220 training loss: 1.0602422580122948\n",
      "epoch 1240 training loss: 1.2148003093898296\n",
      "test_loss for epoch 1240 is 0.04261557385325432\n",
      "epoch 1260 training loss: 1.2366049215197563\n",
      "epoch 1280 training loss: 1.024704247713089\n",
      "test_loss for epoch 1280 is 0.056817684322595596\n",
      "epoch 1300 training loss: 1.404755998402834\n",
      "epoch 1320 training loss: 1.41040900349617\n",
      "test_loss for epoch 1320 is 0.06459667533636093\n",
      "epoch 1340 training loss: 0.794160507619381\n",
      "epoch 1360 training loss: 1.2282972820103168\n",
      "test_loss for epoch 1360 is 0.058681562542915344\n",
      "epoch 1380 training loss: 1.027639139443636\n",
      "epoch 1400 training loss: 0.9274303466081619\n",
      "test_loss for epoch 1400 is 0.04563652351498604\n",
      "epoch 1420 training loss: 1.5605182573199272\n",
      "epoch 1440 training loss: 1.152003113180399\n",
      "test_loss for epoch 1440 is 0.07696101814508438\n",
      "epoch 1460 training loss: 0.9804217591881752\n",
      "epoch 1480 training loss: 0.9256874695420265\n",
      "test_loss for epoch 1480 is 0.07472775131464005\n",
      "epoch 1500 training loss: 1.383144710212946\n",
      "epoch 1520 training loss: 1.3436245173215866\n",
      "test_loss for epoch 1520 is 0.06381077319383621\n",
      "epoch 1540 training loss: 1.3443407118320465\n",
      "epoch 1560 training loss: 1.103103257715702\n",
      "test_loss for epoch 1560 is 0.07019902020692825\n",
      "epoch 1580 training loss: 0.9841032661497593\n",
      "epoch 1600 training loss: 1.0773131847381592\n",
      "test_loss for epoch 1600 is 0.07581675797700882\n",
      "epoch 1620 training loss: 1.0490053407847881\n",
      "epoch 1640 training loss: 0.961086630821228\n",
      "test_loss for epoch 1640 is 0.07832363247871399\n",
      "epoch 1660 training loss: 1.2746070176362991\n",
      "epoch 1680 training loss: 1.2811176106333733\n",
      "test_loss for epoch 1680 is 0.08230701833963394\n",
      "epoch 1700 training loss: 1.2354830279946327\n",
      "epoch 1720 training loss: 0.956724040210247\n",
      "test_loss for epoch 1720 is 0.05367812514305115\n",
      "epoch 1740 training loss: 1.1110989972949028\n",
      "epoch 1760 training loss: 1.1607972383499146\n",
      "test_loss for epoch 1760 is 0.05880166217684746\n",
      "epoch 1780 training loss: 1.1715338975191116\n",
      "epoch 1800 training loss: 0.8570156656205654\n",
      "test_loss for epoch 1800 is 0.07010958343744278\n",
      "epoch 1820 training loss: 0.9746191576123238\n",
      "epoch 1840 training loss: 1.0822242349386215\n",
      "test_loss for epoch 1840 is 0.06090960279107094\n",
      "epoch 1860 training loss: 1.1537088714540005\n",
      "epoch 1880 training loss: 1.19543781504035\n",
      "test_loss for epoch 1880 is 0.07611031085252762\n",
      "epoch 1900 training loss: 1.1802904456853867\n",
      "epoch 1920 training loss: 1.2575884461402893\n",
      "test_loss for epoch 1920 is 0.07707887887954712\n",
      "epoch 1940 training loss: 0.973866194486618\n",
      "epoch 1960 training loss: 0.8710772059857845\n",
      "test_loss for epoch 1960 is 0.068352609872818\n",
      "epoch 1980 training loss: 1.0295374542474747\n",
      "epoch 2000 training loss: 1.4863474443554878\n",
      "test_loss for epoch 2000 is 0.08562586456537247\n"
     ]
    }
   ],
   "source": [
    "epoch=2000\n",
    "for n in range(epoch):\n",
    "    losses=0\n",
    "    mymodel.train()\n",
    "    for x,y in train:\n",
    "        opt.zero_grad()\n",
    "        prediction = mymodel(x)\n",
    "        loss = loss_fun(prediction,y.view(-1,1))\n",
    "        losses+=loss.item()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    if (n+1)%20==0:\n",
    "        print('epoch {} training loss: {}'.format(n+1,losses))\n",
    "    \n",
    "    if (n+1)%40==0:\n",
    "        mymodel.eval()\n",
    "        for a,b in test:\n",
    "            pred = mymodel(a)\n",
    "            loss_test = loss_fun(pred,b)\n",
    "            print('test_loss for epoch {} is {}'.format(n+1,loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61.749924]\n",
      " [62.691334]\n",
      " [70.74741 ]\n",
      " [63.809563]\n",
      " [63.536026]\n",
      " [79.55868 ]]\n",
      "30    60.743268\n",
      "31    58.546726\n",
      "32    68.253587\n",
      "33    61.389658\n",
      "34    62.868093\n",
      "35    88.348990\n",
      "Name: Price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "###this is to check how model performing against unscaled test label\n",
    "mymodel.eval()\n",
    "for x,y in test:\n",
    "    an=mymodel(x)\n",
    "    ans=an.detach().numpy()\n",
    "    \n",
    "    ans = scaler.inverse_transform(ans.reshape(-1,1))\n",
    "    print(ans)\n",
    "    print(df.loc[30:,'Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To make forecast on future data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generator(x,y):\n",
    "    dic = {3:1,6:2,9:3,12:4}\n",
    "    list = [0]*6\n",
    "    list[-1] = y\n",
    "    try:\n",
    "        list[dic[x]] =1\n",
    "    except:\n",
    "        list[0] = 1\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-1 with forecast price of: 61.54224395751953:\n",
      "2020-2 with forecast price of: 62.57268524169922:\n",
      "2020-3 with forecast price of: 71.1337890625:\n",
      "2020-4 with forecast price of: 62.41482162475586:\n",
      "2020-5 with forecast price of: 63.55333709716797:\n",
      "2020-6 with forecast price of: 63.33482360839844:\n",
      "2020-7 with forecast price of: 62.057891845703125:\n",
      "2020-8 with forecast price of: 61.48052978515625:\n",
      "2020-9 with forecast price of: 72.29559326171875:\n",
      "2020-10 with forecast price of: 63.85159683227539:\n",
      "2020-11 with forecast price of: 63.7620849609375:\n",
      "2020-12 with forecast price of: 80.38516998291016:\n",
      "2021-1 with forecast price of: 61.542449951171875:\n",
      "2021-2 with forecast price of: 62.624568939208984:\n",
      "2021-3 with forecast price of: 75.51900482177734:\n",
      "2021-4 with forecast price of: 62.339447021484375:\n",
      "2021-5 with forecast price of: 63.52370071411133:\n",
      "2021-6 with forecast price of: 63.372745513916016:\n",
      "2021-7 with forecast price of: 62.04526901245117:\n",
      "2021-8 with forecast price of: 61.48279571533203:\n",
      "2021-9 with forecast price of: 72.28820037841797:\n",
      "2021-10 with forecast price of: 63.85197067260742:\n",
      "2021-11 with forecast price of: 63.76190185546875:\n",
      "2021-12 with forecast price of: 80.3859634399414:\n"
     ]
    }
   ],
   "source": [
    "current = X[-4:]\n",
    "mymodel.eval()\n",
    "year=2019\n",
    "\n",
    "for m in range(0,2):\n",
    "    year += 1\n",
    "    month = 0\n",
    "    for n in range(1,13):\n",
    "        latest = current[-4:]\n",
    "        input = torch.tensor(latest,dtype=torch.float32).view(1,4,6)\n",
    "        pred = mymodel(input)\n",
    "        pred_final = pred.detach().numpy()\n",
    "        current.append(feature_generator(n,pred_final.squeeze(0)))\n",
    "        month += 1\n",
    "        forecast = scaler.inverse_transform(pred_final.reshape(-1,1)).squeeze(0)\n",
    "        print('{}-{} with forecast price of: {}:'.format(year,month,forecast[0]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
