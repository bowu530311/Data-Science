{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import statistics as st\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans1 = transforms.Compose([transforms.RandomCrop(32,padding=4,padding_mode=\"reflect\"),\n",
    "                             transforms.RandomHorizontalFlip(p=0.5),\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Normalize(mean=[0.4914,0.4822,0.4465],\n",
    "                                                  std=[0.2023,0.1994,0.2010])])\n",
    "trans2 = transforms.Compose([transforms.ToTensor(),\n",
    "                             transforms.Normalize(mean=[0.4914,0.4822,0.4465],\n",
    "                                                  std=[0.2023,0.1994,0.2010])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "train_cifar = torchvision.datasets.CIFAR100(\"Cifar100\",train=True,download=True,transform=trans1)\n",
    "test_cifar = torchvision.datasets.CIFAR100(\"Cifar100\",train=False,download=True,transform=trans2)\n",
    "\n",
    "print(len(train_cifar))\n",
    "print(len(test_cifar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=0\n",
    "# while n<100:\n",
    "#     for x,y in train_cifar:\n",
    "#         print(y)\n",
    "#         n+=1\n",
    "print(train_cifar.classes)\n",
    "print(train_cifar.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "train_data = DataLoader(train_cifar,batch_size=batch_size,shuffle=True,num_workers=1,pin_memory=True)\n",
    "test_data = DataLoader(test_cifar,batch_size=batch_size,shuffle=False,num_workers=1,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in dir(models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = models.resnet50()\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block1(in_channel,out_channel):\n",
    "    layers = [nn.Conv2d(in_channel,out_channel,kernel_size=3,padding=1,bias=False),\n",
    "              nn.BatchNorm2d(out_channel,momentum=0.1),\n",
    "              nn.Conv2d(out_channel,out_channel,kernel_size=3,padding=1,bias=False),\n",
    "              nn.BatchNorm2d(out_channel,momentum=0.1),\n",
    "              nn.Conv2d(out_channel,out_channel,kernel_size=3,padding=1,bias=False),\n",
    "              nn.BatchNorm2d(out_channel,momentum=0.1),\n",
    "              nn.ReLU(inplace=True),\n",
    "              nn.Conv2d(out_channel,out_channel,kernel_size=3,padding=1,bias=False)]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def batch_norm(in_channel):\n",
    "    layers = [nn.BatchNorm2d(in_channel,momentum=0.1),\n",
    "             nn.ReLU(inplace=True)]\n",
    "    \n",
    "    return nn.Sequential(*layers)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet_x(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,16,kernel_size=3,padding=1,bias=False)\n",
    "        self.conv2 = batch_norm(16)\n",
    "        self.conv2_1 = nn.Conv2d(16,96,kernel_size=1,bias=False)\n",
    "        \n",
    "        self.conv3 = conv_block1(16,96)\n",
    "        self.conv3_2 = batch_norm(96)\n",
    "        self.conv4 = conv_block1(96,96)\n",
    "        self.conv4_2=batch_norm(96)\n",
    "        self.conv5 = conv_block1(96,96)\n",
    "        self.conv5_2 = batch_norm(96)\n",
    "        self.conv6 = conv_block1(96,96)\n",
    "        self.conv6_2 = batch_norm(96)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(96,192,kernel_size=1,bias=False)\n",
    "        self.conv8 = conv_block1(96,192)\n",
    "        self.conv8_2 = batch_norm(192)\n",
    "        self.conv9 = conv_block1(192,192)\n",
    "        self.conv9_2 = batch_norm(192)\n",
    "        self.conv10 = conv_block1(192,192)\n",
    "        self.conv10_2 = batch_norm(192)\n",
    "        self.conv11 = conv_block1(192,192)\n",
    "        self.conv11_2 = batch_norm(192)\n",
    "        \n",
    "        self.conv12 = nn.Conv2d(192,384,kernel_size=1,bias=False)\n",
    "        self.conv13 = conv_block1(192,384)\n",
    "        self.conv13_2 = batch_norm(384)\n",
    "#         self.conv14 = conv_block1(384,384)\n",
    "#         self.conv14_2 = batch_norm(384)\n",
    "#         self.conv15 = conv_block1(384,384)\n",
    "#         self.conv15_2 = batch_norm(384)\n",
    "#         self.conv16 = conv_block1(384,384)\n",
    "#         self.conv16_2 = batch_norm(384)\n",
    "        \n",
    "#         self.conv17 = nn.Conv2d(384,768,kernel_size=1,bias=False)\n",
    "#         self.conv18 = conv_block1(384,768)\n",
    "#         self.conv18_2 = batch_norm(768)\n",
    "#         self.conv19 = conv_block1(768,768)\n",
    "#         self.conv19_2 = batch_norm(768)\n",
    "#         self.conv20 = conv_block1(768,768)\n",
    "#         self.conv20_2 = batch_norm(768)\n",
    "#         self.conv21 = conv_block1(768,768)\n",
    "#         self.conv21_2 = batch_norm(768)\n",
    "        \n",
    "        self.linear1 = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.linear2 = nn.Linear(384,100)\n",
    "    \n",
    "    \n",
    "    def forward(self,data):\n",
    "        out = self.conv1(data)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv2_1(out)+self.conv3(out)\n",
    "        out = self.conv3_2(out)\n",
    "        out = out + self.conv4(out)\n",
    "        out = self.conv4_2(out)\n",
    "        out = out + self.conv5(out)\n",
    "        out = self.conv5_2(out)\n",
    "        out = out + self.conv6(out)\n",
    "        out = self.conv6_2(out)\n",
    "        \n",
    "        out = self.conv7(out)+self.conv8(out)\n",
    "        out = self.conv8_2(out)\n",
    "        out = out + self.conv9(out)\n",
    "        out = self.conv9_2(out)\n",
    "        out = out + self.conv10(out)\n",
    "        out = self.conv10_2(out)\n",
    "        out = out +self.conv11(out)\n",
    "        out = self.conv11_2(out)\n",
    "        \n",
    "        out = self.conv12(out) + self.conv13(out)\n",
    "        out = self.conv13_2(out)\n",
    "#         out = out+ self.conv14(out)\n",
    "#         out = self.conv14_2(out)\n",
    "#         out = out + self.conv15(out)\n",
    "#         out = self.conv15_2(out)\n",
    "#         out = out + self.conv16(out)\n",
    "#         out = self.conv16_2(out)\n",
    "        \n",
    "#         out = self.conv17(out) + self.conv18(out)\n",
    "#         out = self.conv18_2(out)\n",
    "#         out = out + self.conv19(out)\n",
    "#         out = self.conv19_2(out)\n",
    "#         out = out + self.conv20(out)\n",
    "#         out = self.conv20_2(out)\n",
    "#         out = out + self.conv21(out)\n",
    "#         out = self.conv21_2(out)\n",
    "        \n",
    "        out = self.linear1(out)\n",
    "        out = out.reshape(-1,384)\n",
    "        out = self.linear2(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = resnet_x().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in train_data:\n",
    "#     a = mymodel(x)\n",
    "#     print(a.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch,train,test,model,loss_fun,opt):\n",
    "    \n",
    "    for a in range(epoch):\n",
    "        n=1\n",
    "        his=[]\n",
    "        for x,y in train:\n",
    "            x,y = x.to(device),y.to(device)\n",
    "            pred = model(x)\n",
    "            __,preds = torch.max(pred,dim=1)\n",
    "            acc = torch.sum(preds==y).item()/len(y)\n",
    "            his.append(torch.sum(preds==y).item())\n",
    "            loss = loss_fun(pred,y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            n+=1\n",
    "            if n%10==0:\n",
    "                print(\"Epoch # [{}/{}], batch # {} with mini batch accuracy of {:.3%} and loss of {:.3f}\"\\\n",
    "                      .format(a+1,epoch,n,acc,loss.item()))\n",
    "        if (a+1)%1==0:\n",
    "            print(\"Epoch # [{}/{}] with overall accuracy of {:.3%}\".format(a+1,epoch,sum(his)/len(train_cifar)))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            history=[]\n",
    "            for x,y in test:\n",
    "                x,y = x.to(device),y.to(device)\n",
    "                p = model(x)\n",
    "                __,prediction = torch.max(p,dim=1)\n",
    "                result = torch.sum(prediction==y).item()\n",
    "                history.append(result)\n",
    "            print(\"Test result of epoch [{}/{}] has accuracy of {:.3%}\".format(a+1,epoch,sum(history)/len(test_cifar)))\n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fun = F.cross_entropy\n",
    "opt = torch.optim.Adam(mymodel.parameters(),lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # [1/10], batch # 10 with mini batch accuracy of 71.000% and loss of 0.959\n",
      "Epoch # [1/10], batch # 20 with mini batch accuracy of 76.000% and loss of 0.916\n",
      "Epoch # [1/10], batch # 30 with mini batch accuracy of 67.000% and loss of 1.177\n",
      "Epoch # [1/10], batch # 40 with mini batch accuracy of 63.000% and loss of 1.218\n",
      "Epoch # [1/10], batch # 50 with mini batch accuracy of 75.000% and loss of 0.937\n",
      "Epoch # [1/10], batch # 60 with mini batch accuracy of 66.000% and loss of 1.225\n",
      "Epoch # [1/10], batch # 70 with mini batch accuracy of 79.000% and loss of 0.822\n",
      "Epoch # [1/10], batch # 80 with mini batch accuracy of 67.000% and loss of 1.135\n",
      "Epoch # [1/10], batch # 90 with mini batch accuracy of 72.000% and loss of 1.015\n",
      "Epoch # [1/10], batch # 100 with mini batch accuracy of 64.000% and loss of 1.095\n",
      "Epoch # [1/10], batch # 110 with mini batch accuracy of 71.000% and loss of 0.947\n",
      "Epoch # [1/10], batch # 120 with mini batch accuracy of 67.000% and loss of 1.023\n",
      "Epoch # [1/10], batch # 130 with mini batch accuracy of 76.000% and loss of 1.046\n",
      "Epoch # [1/10], batch # 140 with mini batch accuracy of 69.000% and loss of 1.254\n",
      "Epoch # [1/10], batch # 150 with mini batch accuracy of 66.000% and loss of 1.050\n",
      "Epoch # [1/10], batch # 160 with mini batch accuracy of 72.000% and loss of 1.002\n",
      "Epoch # [1/10], batch # 170 with mini batch accuracy of 62.000% and loss of 1.178\n",
      "Epoch # [1/10], batch # 180 with mini batch accuracy of 67.000% and loss of 1.055\n",
      "Epoch # [1/10], batch # 190 with mini batch accuracy of 70.000% and loss of 0.963\n",
      "Epoch # [1/10], batch # 200 with mini batch accuracy of 71.000% and loss of 1.186\n",
      "Epoch # [1/10], batch # 210 with mini batch accuracy of 67.000% and loss of 1.026\n",
      "Epoch # [1/10], batch # 220 with mini batch accuracy of 67.000% and loss of 1.152\n",
      "Epoch # [1/10], batch # 230 with mini batch accuracy of 64.000% and loss of 1.255\n",
      "Epoch # [1/10], batch # 240 with mini batch accuracy of 69.000% and loss of 1.008\n",
      "Epoch # [1/10], batch # 250 with mini batch accuracy of 76.000% and loss of 1.039\n",
      "Epoch # [1/10], batch # 260 with mini batch accuracy of 74.000% and loss of 0.991\n",
      "Epoch # [1/10], batch # 270 with mini batch accuracy of 70.000% and loss of 1.080\n",
      "Epoch # [1/10], batch # 280 with mini batch accuracy of 72.000% and loss of 0.960\n",
      "Epoch # [1/10], batch # 290 with mini batch accuracy of 70.000% and loss of 1.002\n",
      "Epoch # [1/10], batch # 300 with mini batch accuracy of 66.000% and loss of 1.226\n",
      "Epoch # [1/10], batch # 310 with mini batch accuracy of 66.000% and loss of 1.166\n",
      "Epoch # [1/10], batch # 320 with mini batch accuracy of 58.000% and loss of 1.333\n",
      "Epoch # [1/10], batch # 330 with mini batch accuracy of 67.000% and loss of 1.168\n",
      "Epoch # [1/10], batch # 340 with mini batch accuracy of 65.000% and loss of 1.241\n",
      "Epoch # [1/10], batch # 350 with mini batch accuracy of 66.000% and loss of 1.110\n",
      "Epoch # [1/10], batch # 360 with mini batch accuracy of 63.000% and loss of 1.219\n",
      "Epoch # [1/10], batch # 370 with mini batch accuracy of 59.000% and loss of 1.093\n",
      "Epoch # [1/10], batch # 380 with mini batch accuracy of 66.000% and loss of 1.240\n",
      "Epoch # [1/10], batch # 390 with mini batch accuracy of 67.000% and loss of 1.138\n",
      "Epoch # [1/10], batch # 400 with mini batch accuracy of 74.000% and loss of 0.891\n",
      "Epoch # [1/10], batch # 410 with mini batch accuracy of 73.000% and loss of 0.990\n",
      "Epoch # [1/10], batch # 420 with mini batch accuracy of 65.000% and loss of 1.111\n",
      "Epoch # [1/10], batch # 430 with mini batch accuracy of 65.000% and loss of 1.100\n",
      "Epoch # [1/10], batch # 440 with mini batch accuracy of 71.000% and loss of 1.062\n",
      "Epoch # [1/10], batch # 450 with mini batch accuracy of 72.000% and loss of 0.983\n",
      "Epoch # [1/10], batch # 460 with mini batch accuracy of 67.000% and loss of 1.042\n",
      "Epoch # [1/10], batch # 470 with mini batch accuracy of 66.000% and loss of 1.216\n",
      "Epoch # [1/10], batch # 480 with mini batch accuracy of 62.000% and loss of 1.135\n",
      "Epoch # [1/10], batch # 490 with mini batch accuracy of 66.000% and loss of 0.977\n",
      "Epoch # [1/10], batch # 500 with mini batch accuracy of 62.000% and loss of 1.259\n",
      "Epoch # [1/10] with overall accuracy of 68.738%\n",
      "Test result of epoch [1/10] has accuracy of 57.370%\n",
      "Epoch # [2/10], batch # 10 with mini batch accuracy of 75.000% and loss of 0.892\n",
      "Epoch # [2/10], batch # 20 with mini batch accuracy of 73.000% and loss of 1.065\n",
      "Epoch # [2/10], batch # 30 with mini batch accuracy of 78.000% and loss of 0.879\n",
      "Epoch # [2/10], batch # 40 with mini batch accuracy of 74.000% and loss of 0.950\n",
      "Epoch # [2/10], batch # 50 with mini batch accuracy of 73.000% and loss of 1.002\n",
      "Epoch # [2/10], batch # 60 with mini batch accuracy of 64.000% and loss of 1.168\n",
      "Epoch # [2/10], batch # 70 with mini batch accuracy of 63.000% and loss of 1.296\n",
      "Epoch # [2/10], batch # 80 with mini batch accuracy of 68.000% and loss of 1.166\n",
      "Epoch # [2/10], batch # 90 with mini batch accuracy of 68.000% and loss of 1.147\n",
      "Epoch # [2/10], batch # 100 with mini batch accuracy of 63.000% and loss of 1.289\n",
      "Epoch # [2/10], batch # 110 with mini batch accuracy of 69.000% and loss of 1.026\n",
      "Epoch # [2/10], batch # 120 with mini batch accuracy of 64.000% and loss of 1.221\n",
      "Epoch # [2/10], batch # 130 with mini batch accuracy of 72.000% and loss of 0.972\n",
      "Epoch # [2/10], batch # 140 with mini batch accuracy of 59.000% and loss of 1.079\n",
      "Epoch # [2/10], batch # 150 with mini batch accuracy of 74.000% and loss of 1.036\n",
      "Epoch # [2/10], batch # 160 with mini batch accuracy of 66.000% and loss of 1.005\n",
      "Epoch # [2/10], batch # 170 with mini batch accuracy of 58.000% and loss of 1.201\n",
      "Epoch # [2/10], batch # 180 with mini batch accuracy of 60.000% and loss of 1.365\n",
      "Epoch # [2/10], batch # 190 with mini batch accuracy of 70.000% and loss of 1.007\n",
      "Epoch # [2/10], batch # 200 with mini batch accuracy of 75.000% and loss of 0.944\n",
      "Epoch # [2/10], batch # 210 with mini batch accuracy of 66.000% and loss of 1.087\n",
      "Epoch # [2/10], batch # 220 with mini batch accuracy of 69.000% and loss of 1.108\n",
      "Epoch # [2/10], batch # 230 with mini batch accuracy of 75.000% and loss of 0.911\n",
      "Epoch # [2/10], batch # 240 with mini batch accuracy of 64.000% and loss of 1.191\n",
      "Epoch # [2/10], batch # 250 with mini batch accuracy of 73.000% and loss of 0.904\n",
      "Epoch # [2/10], batch # 260 with mini batch accuracy of 62.000% and loss of 1.130\n",
      "Epoch # [2/10], batch # 270 with mini batch accuracy of 69.000% and loss of 1.002\n",
      "Epoch # [2/10], batch # 280 with mini batch accuracy of 70.000% and loss of 1.075\n",
      "Epoch # [2/10], batch # 290 with mini batch accuracy of 67.000% and loss of 1.103\n",
      "Epoch # [2/10], batch # 300 with mini batch accuracy of 69.000% and loss of 1.003\n",
      "Epoch # [2/10], batch # 310 with mini batch accuracy of 76.000% and loss of 0.898\n",
      "Epoch # [2/10], batch # 320 with mini batch accuracy of 70.000% and loss of 0.982\n",
      "Epoch # [2/10], batch # 330 with mini batch accuracy of 68.000% and loss of 1.193\n",
      "Epoch # [2/10], batch # 340 with mini batch accuracy of 71.000% and loss of 1.045\n",
      "Epoch # [2/10], batch # 350 with mini batch accuracy of 68.000% and loss of 1.035\n",
      "Epoch # [2/10], batch # 360 with mini batch accuracy of 67.000% and loss of 1.186\n",
      "Epoch # [2/10], batch # 370 with mini batch accuracy of 70.000% and loss of 1.012\n",
      "Epoch # [2/10], batch # 380 with mini batch accuracy of 72.000% and loss of 0.983\n",
      "Epoch # [2/10], batch # 390 with mini batch accuracy of 69.000% and loss of 1.080\n",
      "Epoch # [2/10], batch # 400 with mini batch accuracy of 72.000% and loss of 0.950\n",
      "Epoch # [2/10], batch # 410 with mini batch accuracy of 71.000% and loss of 0.966\n",
      "Epoch # [2/10], batch # 420 with mini batch accuracy of 74.000% and loss of 0.939\n",
      "Epoch # [2/10], batch # 430 with mini batch accuracy of 61.000% and loss of 1.280\n",
      "Epoch # [2/10], batch # 440 with mini batch accuracy of 72.000% and loss of 0.932\n",
      "Epoch # [2/10], batch # 450 with mini batch accuracy of 73.000% and loss of 0.886\n",
      "Epoch # [2/10], batch # 460 with mini batch accuracy of 67.000% and loss of 1.016\n",
      "Epoch # [2/10], batch # 470 with mini batch accuracy of 66.000% and loss of 1.045\n",
      "Epoch # [2/10], batch # 480 with mini batch accuracy of 71.000% and loss of 0.964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # [2/10], batch # 490 with mini batch accuracy of 65.000% and loss of 0.991\n",
      "Epoch # [2/10], batch # 500 with mini batch accuracy of 69.000% and loss of 1.101\n",
      "Epoch # [2/10] with overall accuracy of 68.648%\n",
      "Test result of epoch [2/10] has accuracy of 57.780%\n",
      "Epoch # [3/10], batch # 10 with mini batch accuracy of 75.000% and loss of 0.936\n",
      "Epoch # [3/10], batch # 20 with mini batch accuracy of 70.000% and loss of 0.846\n",
      "Epoch # [3/10], batch # 30 with mini batch accuracy of 66.000% and loss of 1.098\n",
      "Epoch # [3/10], batch # 40 with mini batch accuracy of 68.000% and loss of 1.126\n",
      "Epoch # [3/10], batch # 50 with mini batch accuracy of 70.000% and loss of 0.980\n",
      "Epoch # [3/10], batch # 60 with mini batch accuracy of 72.000% and loss of 0.935\n",
      "Epoch # [3/10], batch # 70 with mini batch accuracy of 76.000% and loss of 0.970\n",
      "Epoch # [3/10], batch # 80 with mini batch accuracy of 63.000% and loss of 1.111\n",
      "Epoch # [3/10], batch # 90 with mini batch accuracy of 65.000% and loss of 0.942\n",
      "Epoch # [3/10], batch # 100 with mini batch accuracy of 71.000% and loss of 0.906\n",
      "Epoch # [3/10], batch # 110 with mini batch accuracy of 74.000% and loss of 0.876\n",
      "Epoch # [3/10], batch # 120 with mini batch accuracy of 69.000% and loss of 1.098\n",
      "Epoch # [3/10], batch # 130 with mini batch accuracy of 79.000% and loss of 0.791\n",
      "Epoch # [3/10], batch # 140 with mini batch accuracy of 64.000% and loss of 1.136\n",
      "Epoch # [3/10], batch # 150 with mini batch accuracy of 73.000% and loss of 0.894\n",
      "Epoch # [3/10], batch # 160 with mini batch accuracy of 72.000% and loss of 1.208\n",
      "Epoch # [3/10], batch # 170 with mini batch accuracy of 68.000% and loss of 1.056\n",
      "Epoch # [3/10], batch # 180 with mini batch accuracy of 64.000% and loss of 1.131\n",
      "Epoch # [3/10], batch # 190 with mini batch accuracy of 74.000% and loss of 0.897\n",
      "Epoch # [3/10], batch # 200 with mini batch accuracy of 69.000% and loss of 0.948\n",
      "Epoch # [3/10], batch # 210 with mini batch accuracy of 74.000% and loss of 0.843\n",
      "Epoch # [3/10], batch # 220 with mini batch accuracy of 69.000% and loss of 1.106\n",
      "Epoch # [3/10], batch # 230 with mini batch accuracy of 71.000% and loss of 0.935\n",
      "Epoch # [3/10], batch # 240 with mini batch accuracy of 76.000% and loss of 0.822\n",
      "Epoch # [3/10], batch # 250 with mini batch accuracy of 70.000% and loss of 0.970\n",
      "Epoch # [3/10], batch # 260 with mini batch accuracy of 62.000% and loss of 1.276\n",
      "Epoch # [3/10], batch # 270 with mini batch accuracy of 73.000% and loss of 0.939\n",
      "Epoch # [3/10], batch # 280 with mini batch accuracy of 74.000% and loss of 0.874\n",
      "Epoch # [3/10], batch # 290 with mini batch accuracy of 68.000% and loss of 1.111\n",
      "Epoch # [3/10], batch # 300 with mini batch accuracy of 64.000% and loss of 1.204\n",
      "Epoch # [3/10], batch # 310 with mini batch accuracy of 62.000% and loss of 1.297\n",
      "Epoch # [3/10], batch # 320 with mini batch accuracy of 65.000% and loss of 1.260\n",
      "Epoch # [3/10], batch # 330 with mini batch accuracy of 76.000% and loss of 0.973\n",
      "Epoch # [3/10], batch # 340 with mini batch accuracy of 69.000% and loss of 1.142\n",
      "Epoch # [3/10], batch # 350 with mini batch accuracy of 71.000% and loss of 0.887\n",
      "Epoch # [3/10], batch # 360 with mini batch accuracy of 75.000% and loss of 1.048\n",
      "Epoch # [3/10], batch # 370 with mini batch accuracy of 67.000% and loss of 1.134\n",
      "Epoch # [3/10], batch # 380 with mini batch accuracy of 59.000% and loss of 1.201\n",
      "Epoch # [3/10], batch # 390 with mini batch accuracy of 70.000% and loss of 1.133\n",
      "Epoch # [3/10], batch # 400 with mini batch accuracy of 69.000% and loss of 1.015\n",
      "Epoch # [3/10], batch # 410 with mini batch accuracy of 61.000% and loss of 1.142\n",
      "Epoch # [3/10], batch # 420 with mini batch accuracy of 68.000% and loss of 1.132\n",
      "Epoch # [3/10], batch # 430 with mini batch accuracy of 78.000% and loss of 0.805\n",
      "Epoch # [3/10], batch # 440 with mini batch accuracy of 63.000% and loss of 1.148\n",
      "Epoch # [3/10], batch # 450 with mini batch accuracy of 70.000% and loss of 0.928\n",
      "Epoch # [3/10], batch # 460 with mini batch accuracy of 70.000% and loss of 1.039\n",
      "Epoch # [3/10], batch # 470 with mini batch accuracy of 78.000% and loss of 0.936\n",
      "Epoch # [3/10], batch # 480 with mini batch accuracy of 71.000% and loss of 1.096\n",
      "Epoch # [3/10], batch # 490 with mini batch accuracy of 77.000% and loss of 1.062\n",
      "Epoch # [3/10], batch # 500 with mini batch accuracy of 68.000% and loss of 1.175\n",
      "Epoch # [3/10] with overall accuracy of 69.244%\n",
      "Test result of epoch [3/10] has accuracy of 58.420%\n",
      "Epoch # [4/10], batch # 10 with mini batch accuracy of 70.000% and loss of 1.017\n",
      "Epoch # [4/10], batch # 20 with mini batch accuracy of 75.000% and loss of 0.968\n",
      "Epoch # [4/10], batch # 30 with mini batch accuracy of 72.000% and loss of 1.056\n",
      "Epoch # [4/10], batch # 40 with mini batch accuracy of 76.000% and loss of 0.887\n",
      "Epoch # [4/10], batch # 50 with mini batch accuracy of 68.000% and loss of 1.079\n",
      "Epoch # [4/10], batch # 60 with mini batch accuracy of 70.000% and loss of 1.026\n",
      "Epoch # [4/10], batch # 70 with mini batch accuracy of 67.000% and loss of 1.086\n",
      "Epoch # [4/10], batch # 80 with mini batch accuracy of 69.000% and loss of 0.929\n",
      "Epoch # [4/10], batch # 90 with mini batch accuracy of 67.000% and loss of 1.019\n",
      "Epoch # [4/10], batch # 100 with mini batch accuracy of 73.000% and loss of 1.027\n",
      "Epoch # [4/10], batch # 110 with mini batch accuracy of 69.000% and loss of 0.941\n",
      "Epoch # [4/10], batch # 120 with mini batch accuracy of 67.000% and loss of 0.951\n",
      "Epoch # [4/10], batch # 130 with mini batch accuracy of 71.000% and loss of 0.927\n",
      "Epoch # [4/10], batch # 140 with mini batch accuracy of 67.000% and loss of 1.048\n",
      "Epoch # [4/10], batch # 150 with mini batch accuracy of 65.000% and loss of 1.012\n",
      "Epoch # [4/10], batch # 160 with mini batch accuracy of 69.000% and loss of 0.961\n",
      "Epoch # [4/10], batch # 170 with mini batch accuracy of 66.000% and loss of 1.141\n",
      "Epoch # [4/10], batch # 180 with mini batch accuracy of 77.000% and loss of 0.802\n",
      "Epoch # [4/10], batch # 190 with mini batch accuracy of 73.000% and loss of 1.014\n",
      "Epoch # [4/10], batch # 200 with mini batch accuracy of 68.000% and loss of 1.040\n",
      "Epoch # [4/10], batch # 210 with mini batch accuracy of 72.000% and loss of 1.075\n",
      "Epoch # [4/10], batch # 220 with mini batch accuracy of 78.000% and loss of 0.782\n",
      "Epoch # [4/10], batch # 230 with mini batch accuracy of 75.000% and loss of 0.781\n",
      "Epoch # [4/10], batch # 240 with mini batch accuracy of 67.000% and loss of 1.093\n",
      "Epoch # [4/10], batch # 250 with mini batch accuracy of 67.000% and loss of 1.092\n",
      "Epoch # [4/10], batch # 260 with mini batch accuracy of 67.000% and loss of 1.156\n",
      "Epoch # [4/10], batch # 270 with mini batch accuracy of 61.000% and loss of 1.325\n",
      "Epoch # [4/10], batch # 280 with mini batch accuracy of 70.000% and loss of 0.992\n",
      "Epoch # [4/10], batch # 290 with mini batch accuracy of 64.000% and loss of 1.192\n",
      "Epoch # [4/10], batch # 300 with mini batch accuracy of 67.000% and loss of 1.378\n",
      "Epoch # [4/10], batch # 310 with mini batch accuracy of 69.000% and loss of 1.048\n",
      "Epoch # [4/10], batch # 320 with mini batch accuracy of 64.000% and loss of 1.178\n",
      "Epoch # [4/10], batch # 330 with mini batch accuracy of 74.000% and loss of 0.922\n",
      "Epoch # [4/10], batch # 340 with mini batch accuracy of 68.000% and loss of 1.148\n",
      "Epoch # [4/10], batch # 350 with mini batch accuracy of 71.000% and loss of 0.911\n",
      "Epoch # [4/10], batch # 360 with mini batch accuracy of 67.000% and loss of 1.144\n",
      "Epoch # [4/10], batch # 370 with mini batch accuracy of 65.000% and loss of 0.908\n",
      "Epoch # [4/10], batch # 380 with mini batch accuracy of 74.000% and loss of 0.981\n",
      "Epoch # [4/10], batch # 390 with mini batch accuracy of 62.000% and loss of 1.069\n",
      "Epoch # [4/10], batch # 400 with mini batch accuracy of 74.000% and loss of 0.923\n",
      "Epoch # [4/10], batch # 410 with mini batch accuracy of 68.000% and loss of 1.108\n",
      "Epoch # [4/10], batch # 420 with mini batch accuracy of 68.000% and loss of 1.070\n",
      "Epoch # [4/10], batch # 430 with mini batch accuracy of 66.000% and loss of 1.148\n",
      "Epoch # [4/10], batch # 440 with mini batch accuracy of 71.000% and loss of 1.047\n",
      "Epoch # [4/10], batch # 450 with mini batch accuracy of 68.000% and loss of 1.131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # [4/10], batch # 460 with mini batch accuracy of 65.000% and loss of 1.034\n",
      "Epoch # [4/10], batch # 470 with mini batch accuracy of 69.000% and loss of 1.082\n",
      "Epoch # [4/10], batch # 480 with mini batch accuracy of 63.000% and loss of 1.118\n",
      "Epoch # [4/10], batch # 490 with mini batch accuracy of 68.000% and loss of 1.108\n",
      "Epoch # [4/10], batch # 500 with mini batch accuracy of 72.000% and loss of 0.877\n",
      "Epoch # [4/10] with overall accuracy of 69.500%\n",
      "Test result of epoch [4/10] has accuracy of 57.840%\n",
      "Epoch # [5/10], batch # 10 with mini batch accuracy of 72.000% and loss of 0.994\n",
      "Epoch # [5/10], batch # 20 with mini batch accuracy of 69.000% and loss of 1.016\n",
      "Epoch # [5/10], batch # 30 with mini batch accuracy of 68.000% and loss of 0.979\n",
      "Epoch # [5/10], batch # 40 with mini batch accuracy of 69.000% and loss of 1.160\n",
      "Epoch # [5/10], batch # 50 with mini batch accuracy of 73.000% and loss of 0.870\n",
      "Epoch # [5/10], batch # 60 with mini batch accuracy of 63.000% and loss of 1.263\n",
      "Epoch # [5/10], batch # 70 with mini batch accuracy of 72.000% and loss of 0.880\n",
      "Epoch # [5/10], batch # 80 with mini batch accuracy of 71.000% and loss of 0.924\n",
      "Epoch # [5/10], batch # 90 with mini batch accuracy of 68.000% and loss of 1.058\n",
      "Epoch # [5/10], batch # 100 with mini batch accuracy of 65.000% and loss of 1.172\n",
      "Epoch # [5/10], batch # 110 with mini batch accuracy of 66.000% and loss of 1.008\n",
      "Epoch # [5/10], batch # 120 with mini batch accuracy of 66.000% and loss of 0.989\n",
      "Epoch # [5/10], batch # 130 with mini batch accuracy of 76.000% and loss of 0.831\n",
      "Epoch # [5/10], batch # 140 with mini batch accuracy of 72.000% and loss of 0.788\n",
      "Epoch # [5/10], batch # 150 with mini batch accuracy of 67.000% and loss of 1.100\n",
      "Epoch # [5/10], batch # 160 with mini batch accuracy of 69.000% and loss of 1.013\n",
      "Epoch # [5/10], batch # 170 with mini batch accuracy of 70.000% and loss of 0.932\n",
      "Epoch # [5/10], batch # 180 with mini batch accuracy of 66.000% and loss of 1.188\n",
      "Epoch # [5/10], batch # 190 with mini batch accuracy of 72.000% and loss of 1.204\n",
      "Epoch # [5/10], batch # 200 with mini batch accuracy of 63.000% and loss of 1.061\n",
      "Epoch # [5/10], batch # 210 with mini batch accuracy of 71.000% and loss of 0.921\n",
      "Epoch # [5/10], batch # 220 with mini batch accuracy of 69.000% and loss of 1.088\n",
      "Epoch # [5/10], batch # 230 with mini batch accuracy of 67.000% and loss of 1.029\n",
      "Epoch # [5/10], batch # 240 with mini batch accuracy of 73.000% and loss of 1.163\n",
      "Epoch # [5/10], batch # 250 with mini batch accuracy of 66.000% and loss of 1.149\n",
      "Epoch # [5/10], batch # 260 with mini batch accuracy of 71.000% and loss of 0.995\n",
      "Epoch # [5/10], batch # 270 with mini batch accuracy of 67.000% and loss of 1.067\n",
      "Epoch # [5/10], batch # 280 with mini batch accuracy of 70.000% and loss of 1.011\n",
      "Epoch # [5/10], batch # 290 with mini batch accuracy of 67.000% and loss of 1.070\n",
      "Epoch # [5/10], batch # 300 with mini batch accuracy of 67.000% and loss of 0.978\n",
      "Epoch # [5/10], batch # 310 with mini batch accuracy of 69.000% and loss of 0.956\n",
      "Epoch # [5/10], batch # 320 with mini batch accuracy of 73.000% and loss of 0.907\n",
      "Epoch # [5/10], batch # 330 with mini batch accuracy of 69.000% and loss of 1.103\n",
      "Epoch # [5/10], batch # 340 with mini batch accuracy of 68.000% and loss of 1.097\n",
      "Epoch # [5/10], batch # 350 with mini batch accuracy of 63.000% and loss of 0.992\n",
      "Epoch # [5/10], batch # 360 with mini batch accuracy of 69.000% and loss of 1.160\n",
      "Epoch # [5/10], batch # 370 with mini batch accuracy of 69.000% and loss of 1.023\n",
      "Epoch # [5/10], batch # 380 with mini batch accuracy of 66.000% and loss of 1.152\n",
      "Epoch # [5/10], batch # 390 with mini batch accuracy of 60.000% and loss of 1.199\n",
      "Epoch # [5/10], batch # 400 with mini batch accuracy of 71.000% and loss of 0.970\n",
      "Epoch # [5/10], batch # 410 with mini batch accuracy of 69.000% and loss of 1.270\n",
      "Epoch # [5/10], batch # 420 with mini batch accuracy of 71.000% and loss of 1.021\n",
      "Epoch # [5/10], batch # 430 with mini batch accuracy of 72.000% and loss of 0.942\n",
      "Epoch # [5/10], batch # 440 with mini batch accuracy of 69.000% and loss of 0.985\n",
      "Epoch # [5/10], batch # 450 with mini batch accuracy of 71.000% and loss of 0.899\n",
      "Epoch # [5/10], batch # 460 with mini batch accuracy of 66.000% and loss of 1.142\n",
      "Epoch # [5/10], batch # 470 with mini batch accuracy of 68.000% and loss of 1.015\n",
      "Epoch # [5/10], batch # 480 with mini batch accuracy of 67.000% and loss of 1.041\n",
      "Epoch # [5/10], batch # 490 with mini batch accuracy of 71.000% and loss of 0.937\n",
      "Epoch # [5/10], batch # 500 with mini batch accuracy of 69.000% and loss of 1.008\n",
      "Epoch # [5/10] with overall accuracy of 69.728%\n",
      "Test result of epoch [5/10] has accuracy of 58.370%\n",
      "Epoch # [6/10], batch # 10 with mini batch accuracy of 68.000% and loss of 0.928\n",
      "Epoch # [6/10], batch # 20 with mini batch accuracy of 72.000% and loss of 0.958\n",
      "Epoch # [6/10], batch # 30 with mini batch accuracy of 71.000% and loss of 1.072\n",
      "Epoch # [6/10], batch # 40 with mini batch accuracy of 66.000% and loss of 1.057\n",
      "Epoch # [6/10], batch # 50 with mini batch accuracy of 66.000% and loss of 1.046\n",
      "Epoch # [6/10], batch # 60 with mini batch accuracy of 71.000% and loss of 0.917\n",
      "Epoch # [6/10], batch # 70 with mini batch accuracy of 77.000% and loss of 0.977\n",
      "Epoch # [6/10], batch # 80 with mini batch accuracy of 72.000% and loss of 0.979\n",
      "Epoch # [6/10], batch # 90 with mini batch accuracy of 64.000% and loss of 1.079\n",
      "Epoch # [6/10], batch # 100 with mini batch accuracy of 70.000% and loss of 1.053\n",
      "Epoch # [6/10], batch # 110 with mini batch accuracy of 62.000% and loss of 1.239\n",
      "Epoch # [6/10], batch # 120 with mini batch accuracy of 71.000% and loss of 0.960\n",
      "Epoch # [6/10], batch # 130 with mini batch accuracy of 73.000% and loss of 0.972\n",
      "Epoch # [6/10], batch # 140 with mini batch accuracy of 75.000% and loss of 0.896\n",
      "Epoch # [6/10], batch # 150 with mini batch accuracy of 67.000% and loss of 1.050\n",
      "Epoch # [6/10], batch # 160 with mini batch accuracy of 62.000% and loss of 1.181\n",
      "Epoch # [6/10], batch # 170 with mini batch accuracy of 73.000% and loss of 0.986\n",
      "Epoch # [6/10], batch # 180 with mini batch accuracy of 66.000% and loss of 1.041\n",
      "Epoch # [6/10], batch # 190 with mini batch accuracy of 70.000% and loss of 1.017\n",
      "Epoch # [6/10], batch # 200 with mini batch accuracy of 68.000% and loss of 1.007\n",
      "Epoch # [6/10], batch # 210 with mini batch accuracy of 67.000% and loss of 1.094\n",
      "Epoch # [6/10], batch # 220 with mini batch accuracy of 74.000% and loss of 0.885\n",
      "Epoch # [6/10], batch # 230 with mini batch accuracy of 72.000% and loss of 0.888\n",
      "Epoch # [6/10], batch # 240 with mini batch accuracy of 67.000% and loss of 1.028\n",
      "Epoch # [6/10], batch # 250 with mini batch accuracy of 63.000% and loss of 1.262\n",
      "Epoch # [6/10], batch # 260 with mini batch accuracy of 74.000% and loss of 0.830\n",
      "Epoch # [6/10], batch # 270 with mini batch accuracy of 76.000% and loss of 0.947\n",
      "Epoch # [6/10], batch # 280 with mini batch accuracy of 72.000% and loss of 0.818\n",
      "Epoch # [6/10], batch # 290 with mini batch accuracy of 66.000% and loss of 1.041\n",
      "Epoch # [6/10], batch # 300 with mini batch accuracy of 68.000% and loss of 0.937\n",
      "Epoch # [6/10], batch # 310 with mini batch accuracy of 63.000% and loss of 1.243\n",
      "Epoch # [6/10], batch # 320 with mini batch accuracy of 71.000% and loss of 1.029\n",
      "Epoch # [6/10], batch # 330 with mini batch accuracy of 64.000% and loss of 1.089\n",
      "Epoch # [6/10], batch # 340 with mini batch accuracy of 73.000% and loss of 0.882\n",
      "Epoch # [6/10], batch # 350 with mini batch accuracy of 75.000% and loss of 0.884\n",
      "Epoch # [6/10], batch # 360 with mini batch accuracy of 62.000% and loss of 1.184\n",
      "Epoch # [6/10], batch # 370 with mini batch accuracy of 69.000% and loss of 1.079\n",
      "Epoch # [6/10], batch # 380 with mini batch accuracy of 75.000% and loss of 1.008\n",
      "Epoch # [6/10], batch # 390 with mini batch accuracy of 66.000% and loss of 1.005\n",
      "Epoch # [6/10], batch # 400 with mini batch accuracy of 75.000% and loss of 0.947\n",
      "Epoch # [6/10], batch # 410 with mini batch accuracy of 64.000% and loss of 1.185\n",
      "Epoch # [6/10], batch # 420 with mini batch accuracy of 68.000% and loss of 0.987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # [6/10], batch # 430 with mini batch accuracy of 66.000% and loss of 1.113\n",
      "Epoch # [6/10], batch # 440 with mini batch accuracy of 67.000% and loss of 1.108\n",
      "Epoch # [6/10], batch # 450 with mini batch accuracy of 66.000% and loss of 1.059\n",
      "Epoch # [6/10], batch # 460 with mini batch accuracy of 67.000% and loss of 1.000\n",
      "Epoch # [6/10], batch # 470 with mini batch accuracy of 64.000% and loss of 1.122\n",
      "Epoch # [6/10], batch # 480 with mini batch accuracy of 68.000% and loss of 1.051\n",
      "Epoch # [6/10], batch # 490 with mini batch accuracy of 77.000% and loss of 1.231\n",
      "Epoch # [6/10], batch # 500 with mini batch accuracy of 61.000% and loss of 1.230\n",
      "Epoch # [6/10] with overall accuracy of 70.070%\n",
      "Test result of epoch [6/10] has accuracy of 57.750%\n",
      "Epoch # [7/10], batch # 10 with mini batch accuracy of 77.000% and loss of 0.835\n",
      "Epoch # [7/10], batch # 20 with mini batch accuracy of 67.000% and loss of 1.139\n",
      "Epoch # [7/10], batch # 30 with mini batch accuracy of 73.000% and loss of 0.808\n",
      "Epoch # [7/10], batch # 40 with mini batch accuracy of 69.000% and loss of 1.076\n",
      "Epoch # [7/10], batch # 50 with mini batch accuracy of 78.000% and loss of 0.908\n",
      "Epoch # [7/10], batch # 60 with mini batch accuracy of 71.000% and loss of 1.099\n",
      "Epoch # [7/10], batch # 70 with mini batch accuracy of 68.000% and loss of 0.963\n",
      "Epoch # [7/10], batch # 80 with mini batch accuracy of 77.000% and loss of 0.868\n",
      "Epoch # [7/10], batch # 90 with mini batch accuracy of 65.000% and loss of 1.056\n",
      "Epoch # [7/10], batch # 100 with mini batch accuracy of 76.000% and loss of 0.856\n",
      "Epoch # [7/10], batch # 110 with mini batch accuracy of 68.000% and loss of 0.982\n",
      "Epoch # [7/10], batch # 120 with mini batch accuracy of 71.000% and loss of 0.925\n",
      "Epoch # [7/10], batch # 130 with mini batch accuracy of 68.000% and loss of 1.008\n",
      "Epoch # [7/10], batch # 140 with mini batch accuracy of 81.000% and loss of 0.903\n",
      "Epoch # [7/10], batch # 150 with mini batch accuracy of 81.000% and loss of 0.718\n",
      "Epoch # [7/10], batch # 160 with mini batch accuracy of 73.000% and loss of 0.902\n",
      "Epoch # [7/10], batch # 170 with mini batch accuracy of 64.000% and loss of 1.041\n",
      "Epoch # [7/10], batch # 180 with mini batch accuracy of 81.000% and loss of 0.812\n",
      "Epoch # [7/10], batch # 190 with mini batch accuracy of 73.000% and loss of 0.877\n",
      "Epoch # [7/10], batch # 200 with mini batch accuracy of 76.000% and loss of 1.062\n",
      "Epoch # [7/10], batch # 210 with mini batch accuracy of 67.000% and loss of 1.141\n",
      "Epoch # [7/10], batch # 220 with mini batch accuracy of 74.000% and loss of 0.783\n",
      "Epoch # [7/10], batch # 230 with mini batch accuracy of 72.000% and loss of 0.943\n",
      "Epoch # [7/10], batch # 240 with mini batch accuracy of 71.000% and loss of 0.940\n",
      "Epoch # [7/10], batch # 250 with mini batch accuracy of 62.000% and loss of 1.127\n",
      "Epoch # [7/10], batch # 260 with mini batch accuracy of 74.000% and loss of 1.097\n",
      "Epoch # [7/10], batch # 270 with mini batch accuracy of 74.000% and loss of 0.966\n",
      "Epoch # [7/10], batch # 280 with mini batch accuracy of 70.000% and loss of 1.105\n",
      "Epoch # [7/10], batch # 290 with mini batch accuracy of 69.000% and loss of 1.064\n",
      "Epoch # [7/10], batch # 300 with mini batch accuracy of 68.000% and loss of 0.941\n",
      "Epoch # [7/10], batch # 310 with mini batch accuracy of 71.000% and loss of 1.141\n",
      "Epoch # [7/10], batch # 320 with mini batch accuracy of 70.000% and loss of 1.046\n",
      "Epoch # [7/10], batch # 330 with mini batch accuracy of 76.000% and loss of 0.785\n",
      "Epoch # [7/10], batch # 340 with mini batch accuracy of 72.000% and loss of 0.923\n",
      "Epoch # [7/10], batch # 350 with mini batch accuracy of 80.000% and loss of 0.790\n",
      "Epoch # [7/10], batch # 360 with mini batch accuracy of 74.000% and loss of 0.919\n",
      "Epoch # [7/10], batch # 370 with mini batch accuracy of 70.000% and loss of 1.060\n",
      "Epoch # [7/10], batch # 380 with mini batch accuracy of 64.000% and loss of 1.273\n",
      "Epoch # [7/10], batch # 390 with mini batch accuracy of 71.000% and loss of 1.000\n",
      "Epoch # [7/10], batch # 400 with mini batch accuracy of 73.000% and loss of 0.938\n",
      "Epoch # [7/10], batch # 410 with mini batch accuracy of 70.000% and loss of 0.971\n",
      "Epoch # [7/10], batch # 420 with mini batch accuracy of 63.000% and loss of 1.085\n",
      "Epoch # [7/10], batch # 430 with mini batch accuracy of 69.000% and loss of 1.047\n",
      "Epoch # [7/10], batch # 440 with mini batch accuracy of 74.000% and loss of 1.036\n",
      "Epoch # [7/10], batch # 450 with mini batch accuracy of 71.000% and loss of 1.142\n",
      "Epoch # [7/10], batch # 460 with mini batch accuracy of 74.000% and loss of 1.020\n",
      "Epoch # [7/10], batch # 470 with mini batch accuracy of 71.000% and loss of 0.953\n",
      "Epoch # [7/10], batch # 480 with mini batch accuracy of 69.000% and loss of 1.120\n",
      "Epoch # [7/10], batch # 490 with mini batch accuracy of 82.000% and loss of 0.812\n",
      "Epoch # [7/10], batch # 500 with mini batch accuracy of 76.000% and loss of 0.957\n",
      "Epoch # [7/10] with overall accuracy of 70.740%\n",
      "Test result of epoch [7/10] has accuracy of 58.210%\n",
      "Epoch # [8/10], batch # 10 with mini batch accuracy of 71.000% and loss of 0.856\n",
      "Epoch # [8/10], batch # 20 with mini batch accuracy of 63.000% and loss of 1.126\n",
      "Epoch # [8/10], batch # 30 with mini batch accuracy of 75.000% and loss of 0.838\n",
      "Epoch # [8/10], batch # 40 with mini batch accuracy of 68.000% and loss of 1.068\n",
      "Epoch # [8/10], batch # 50 with mini batch accuracy of 72.000% and loss of 0.923\n",
      "Epoch # [8/10], batch # 60 with mini batch accuracy of 76.000% and loss of 0.859\n",
      "Epoch # [8/10], batch # 70 with mini batch accuracy of 70.000% and loss of 0.900\n",
      "Epoch # [8/10], batch # 80 with mini batch accuracy of 73.000% and loss of 0.928\n",
      "Epoch # [8/10], batch # 90 with mini batch accuracy of 79.000% and loss of 0.778\n",
      "Epoch # [8/10], batch # 100 with mini batch accuracy of 73.000% and loss of 0.871\n",
      "Epoch # [8/10], batch # 110 with mini batch accuracy of 70.000% and loss of 1.034\n",
      "Epoch # [8/10], batch # 120 with mini batch accuracy of 83.000% and loss of 0.707\n",
      "Epoch # [8/10], batch # 130 with mini batch accuracy of 72.000% and loss of 1.081\n",
      "Epoch # [8/10], batch # 140 with mini batch accuracy of 74.000% and loss of 0.970\n",
      "Epoch # [8/10], batch # 150 with mini batch accuracy of 72.000% and loss of 1.002\n",
      "Epoch # [8/10], batch # 160 with mini batch accuracy of 61.000% and loss of 1.208\n",
      "Epoch # [8/10], batch # 170 with mini batch accuracy of 72.000% and loss of 0.938\n",
      "Epoch # [8/10], batch # 180 with mini batch accuracy of 69.000% and loss of 0.989\n",
      "Epoch # [8/10], batch # 190 with mini batch accuracy of 67.000% and loss of 1.046\n",
      "Epoch # [8/10], batch # 200 with mini batch accuracy of 59.000% and loss of 1.247\n",
      "Epoch # [8/10], batch # 210 with mini batch accuracy of 73.000% and loss of 0.972\n",
      "Epoch # [8/10], batch # 220 with mini batch accuracy of 77.000% and loss of 0.876\n",
      "Epoch # [8/10], batch # 230 with mini batch accuracy of 78.000% and loss of 0.891\n",
      "Epoch # [8/10], batch # 240 with mini batch accuracy of 77.000% and loss of 0.929\n",
      "Epoch # [8/10], batch # 250 with mini batch accuracy of 64.000% and loss of 1.071\n",
      "Epoch # [8/10], batch # 260 with mini batch accuracy of 74.000% and loss of 0.863\n",
      "Epoch # [8/10], batch # 270 with mini batch accuracy of 65.000% and loss of 1.021\n",
      "Epoch # [8/10], batch # 280 with mini batch accuracy of 74.000% and loss of 0.915\n",
      "Epoch # [8/10], batch # 290 with mini batch accuracy of 71.000% and loss of 1.086\n",
      "Epoch # [8/10], batch # 300 with mini batch accuracy of 67.000% and loss of 0.926\n",
      "Epoch # [8/10], batch # 310 with mini batch accuracy of 69.000% and loss of 1.049\n",
      "Epoch # [8/10], batch # 320 with mini batch accuracy of 83.000% and loss of 0.761\n",
      "Epoch # [8/10], batch # 330 with mini batch accuracy of 75.000% and loss of 1.021\n",
      "Epoch # [8/10], batch # 340 with mini batch accuracy of 68.000% and loss of 1.023\n",
      "Epoch # [8/10], batch # 350 with mini batch accuracy of 71.000% and loss of 0.997\n",
      "Epoch # [8/10], batch # 360 with mini batch accuracy of 61.000% and loss of 1.110\n",
      "Epoch # [8/10], batch # 370 with mini batch accuracy of 71.000% and loss of 1.003\n",
      "Epoch # [8/10], batch # 380 with mini batch accuracy of 59.000% and loss of 1.253\n",
      "Epoch # [8/10], batch # 390 with mini batch accuracy of 65.000% and loss of 1.119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # [8/10], batch # 400 with mini batch accuracy of 71.000% and loss of 1.022\n",
      "Epoch # [8/10], batch # 410 with mini batch accuracy of 69.000% and loss of 1.075\n",
      "Epoch # [8/10], batch # 420 with mini batch accuracy of 70.000% and loss of 1.056\n",
      "Epoch # [8/10], batch # 430 with mini batch accuracy of 70.000% and loss of 1.065\n",
      "Epoch # [8/10], batch # 440 with mini batch accuracy of 64.000% and loss of 1.088\n",
      "Epoch # [8/10], batch # 450 with mini batch accuracy of 73.000% and loss of 1.009\n",
      "Epoch # [8/10], batch # 460 with mini batch accuracy of 66.000% and loss of 1.255\n",
      "Epoch # [8/10], batch # 470 with mini batch accuracy of 71.000% and loss of 0.905\n",
      "Epoch # [8/10], batch # 480 with mini batch accuracy of 67.000% and loss of 1.007\n",
      "Epoch # [8/10], batch # 490 with mini batch accuracy of 72.000% and loss of 1.091\n",
      "Epoch # [8/10], batch # 500 with mini batch accuracy of 74.000% and loss of 0.920\n",
      "Epoch # [8/10] with overall accuracy of 70.884%\n",
      "Test result of epoch [8/10] has accuracy of 57.610%\n",
      "Epoch # [9/10], batch # 10 with mini batch accuracy of 75.000% and loss of 0.821\n",
      "Epoch # [9/10], batch # 20 with mini batch accuracy of 76.000% and loss of 0.877\n",
      "Epoch # [9/10], batch # 30 with mini batch accuracy of 73.000% and loss of 1.034\n",
      "Epoch # [9/10], batch # 40 with mini batch accuracy of 66.000% and loss of 1.109\n",
      "Epoch # [9/10], batch # 50 with mini batch accuracy of 76.000% and loss of 0.837\n",
      "Epoch # [9/10], batch # 60 with mini batch accuracy of 83.000% and loss of 0.797\n",
      "Epoch # [9/10], batch # 70 with mini batch accuracy of 73.000% and loss of 0.929\n",
      "Epoch # [9/10], batch # 80 with mini batch accuracy of 78.000% and loss of 0.849\n",
      "Epoch # [9/10], batch # 90 with mini batch accuracy of 69.000% and loss of 0.922\n",
      "Epoch # [9/10], batch # 100 with mini batch accuracy of 74.000% and loss of 0.958\n",
      "Epoch # [9/10], batch # 110 with mini batch accuracy of 70.000% and loss of 1.030\n",
      "Epoch # [9/10], batch # 120 with mini batch accuracy of 76.000% and loss of 0.716\n",
      "Epoch # [9/10], batch # 130 with mini batch accuracy of 74.000% and loss of 0.846\n",
      "Epoch # [9/10], batch # 140 with mini batch accuracy of 68.000% and loss of 0.979\n",
      "Epoch # [9/10], batch # 150 with mini batch accuracy of 67.000% and loss of 0.979\n",
      "Epoch # [9/10], batch # 160 with mini batch accuracy of 78.000% and loss of 0.861\n",
      "Epoch # [9/10], batch # 170 with mini batch accuracy of 70.000% and loss of 0.914\n",
      "Epoch # [9/10], batch # 180 with mini batch accuracy of 62.000% and loss of 1.292\n",
      "Epoch # [9/10], batch # 190 with mini batch accuracy of 76.000% and loss of 0.839\n",
      "Epoch # [9/10], batch # 200 with mini batch accuracy of 69.000% and loss of 0.992\n",
      "Epoch # [9/10], batch # 210 with mini batch accuracy of 77.000% and loss of 0.831\n",
      "Epoch # [9/10], batch # 220 with mini batch accuracy of 63.000% and loss of 1.065\n",
      "Epoch # [9/10], batch # 230 with mini batch accuracy of 61.000% and loss of 1.111\n",
      "Epoch # [9/10], batch # 240 with mini batch accuracy of 68.000% and loss of 0.995\n",
      "Epoch # [9/10], batch # 250 with mini batch accuracy of 67.000% and loss of 0.984\n",
      "Epoch # [9/10], batch # 260 with mini batch accuracy of 66.000% and loss of 1.154\n",
      "Epoch # [9/10], batch # 270 with mini batch accuracy of 80.000% and loss of 0.783\n",
      "Epoch # [9/10], batch # 280 with mini batch accuracy of 69.000% and loss of 0.950\n",
      "Epoch # [9/10], batch # 290 with mini batch accuracy of 74.000% and loss of 1.001\n",
      "Epoch # [9/10], batch # 300 with mini batch accuracy of 65.000% and loss of 1.170\n",
      "Epoch # [9/10], batch # 310 with mini batch accuracy of 72.000% and loss of 0.949\n",
      "Epoch # [9/10], batch # 320 with mini batch accuracy of 74.000% and loss of 0.905\n",
      "Epoch # [9/10], batch # 330 with mini batch accuracy of 71.000% and loss of 0.916\n",
      "Epoch # [9/10], batch # 340 with mini batch accuracy of 77.000% and loss of 0.775\n",
      "Epoch # [9/10], batch # 350 with mini batch accuracy of 68.000% and loss of 1.109\n",
      "Epoch # [9/10], batch # 360 with mini batch accuracy of 62.000% and loss of 1.108\n",
      "Epoch # [9/10], batch # 370 with mini batch accuracy of 73.000% and loss of 0.969\n",
      "Epoch # [9/10], batch # 380 with mini batch accuracy of 71.000% and loss of 0.921\n",
      "Epoch # [9/10], batch # 390 with mini batch accuracy of 68.000% and loss of 0.988\n",
      "Epoch # [9/10], batch # 400 with mini batch accuracy of 68.000% and loss of 1.001\n",
      "Epoch # [9/10], batch # 410 with mini batch accuracy of 75.000% and loss of 0.893\n",
      "Epoch # [9/10], batch # 420 with mini batch accuracy of 72.000% and loss of 0.922\n",
      "Epoch # [9/10], batch # 430 with mini batch accuracy of 77.000% and loss of 0.823\n",
      "Epoch # [9/10], batch # 440 with mini batch accuracy of 76.000% and loss of 0.825\n",
      "Epoch # [9/10], batch # 450 with mini batch accuracy of 75.000% and loss of 0.865\n",
      "Epoch # [9/10], batch # 460 with mini batch accuracy of 72.000% and loss of 1.010\n",
      "Epoch # [9/10], batch # 470 with mini batch accuracy of 73.000% and loss of 0.902\n",
      "Epoch # [9/10], batch # 480 with mini batch accuracy of 68.000% and loss of 1.027\n",
      "Epoch # [9/10], batch # 490 with mini batch accuracy of 78.000% and loss of 0.781\n",
      "Epoch # [9/10], batch # 500 with mini batch accuracy of 72.000% and loss of 1.028\n",
      "Epoch # [9/10] with overall accuracy of 71.184%\n",
      "Test result of epoch [9/10] has accuracy of 58.560%\n",
      "Epoch # [10/10], batch # 10 with mini batch accuracy of 67.000% and loss of 0.984\n",
      "Epoch # [10/10], batch # 20 with mini batch accuracy of 66.000% and loss of 1.083\n",
      "Epoch # [10/10], batch # 30 with mini batch accuracy of 73.000% and loss of 0.901\n",
      "Epoch # [10/10], batch # 40 with mini batch accuracy of 70.000% and loss of 0.924\n",
      "Epoch # [10/10], batch # 50 with mini batch accuracy of 81.000% and loss of 0.732\n",
      "Epoch # [10/10], batch # 60 with mini batch accuracy of 68.000% and loss of 1.096\n",
      "Epoch # [10/10], batch # 70 with mini batch accuracy of 75.000% and loss of 0.842\n",
      "Epoch # [10/10], batch # 80 with mini batch accuracy of 66.000% and loss of 1.092\n",
      "Epoch # [10/10], batch # 90 with mini batch accuracy of 82.000% and loss of 0.740\n",
      "Epoch # [10/10], batch # 100 with mini batch accuracy of 76.000% and loss of 0.972\n",
      "Epoch # [10/10], batch # 110 with mini batch accuracy of 72.000% and loss of 0.877\n",
      "Epoch # [10/10], batch # 120 with mini batch accuracy of 71.000% and loss of 0.858\n",
      "Epoch # [10/10], batch # 130 with mini batch accuracy of 70.000% and loss of 1.001\n",
      "Epoch # [10/10], batch # 140 with mini batch accuracy of 70.000% and loss of 1.017\n",
      "Epoch # [10/10], batch # 150 with mini batch accuracy of 79.000% and loss of 0.859\n",
      "Epoch # [10/10], batch # 160 with mini batch accuracy of 72.000% and loss of 0.928\n",
      "Epoch # [10/10], batch # 170 with mini batch accuracy of 72.000% and loss of 0.838\n",
      "Epoch # [10/10], batch # 180 with mini batch accuracy of 68.000% and loss of 1.044\n",
      "Epoch # [10/10], batch # 190 with mini batch accuracy of 64.000% and loss of 1.001\n",
      "Epoch # [10/10], batch # 200 with mini batch accuracy of 69.000% and loss of 0.953\n",
      "Epoch # [10/10], batch # 210 with mini batch accuracy of 67.000% and loss of 1.035\n",
      "Epoch # [10/10], batch # 220 with mini batch accuracy of 70.000% and loss of 0.796\n",
      "Epoch # [10/10], batch # 230 with mini batch accuracy of 72.000% and loss of 1.000\n",
      "Epoch # [10/10], batch # 240 with mini batch accuracy of 72.000% and loss of 0.870\n",
      "Epoch # [10/10], batch # 250 with mini batch accuracy of 68.000% and loss of 1.026\n",
      "Epoch # [10/10], batch # 260 with mini batch accuracy of 75.000% and loss of 0.980\n",
      "Epoch # [10/10], batch # 270 with mini batch accuracy of 68.000% and loss of 0.965\n",
      "Epoch # [10/10], batch # 280 with mini batch accuracy of 79.000% and loss of 0.776\n",
      "Epoch # [10/10], batch # 290 with mini batch accuracy of 70.000% and loss of 0.967\n",
      "Epoch # [10/10], batch # 300 with mini batch accuracy of 71.000% and loss of 1.056\n",
      "Epoch # [10/10], batch # 310 with mini batch accuracy of 77.000% and loss of 0.902\n",
      "Epoch # [10/10], batch # 320 with mini batch accuracy of 67.000% and loss of 1.028\n",
      "Epoch # [10/10], batch # 330 with mini batch accuracy of 65.000% and loss of 0.975\n",
      "Epoch # [10/10], batch # 340 with mini batch accuracy of 64.000% and loss of 1.202\n",
      "Epoch # [10/10], batch # 350 with mini batch accuracy of 69.000% and loss of 0.818\n",
      "Epoch # [10/10], batch # 360 with mini batch accuracy of 60.000% and loss of 1.093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # [10/10], batch # 370 with mini batch accuracy of 65.000% and loss of 1.052\n",
      "Epoch # [10/10], batch # 380 with mini batch accuracy of 70.000% and loss of 1.134\n",
      "Epoch # [10/10], batch # 390 with mini batch accuracy of 79.000% and loss of 0.969\n",
      "Epoch # [10/10], batch # 400 with mini batch accuracy of 60.000% and loss of 1.260\n",
      "Epoch # [10/10], batch # 410 with mini batch accuracy of 67.000% and loss of 0.983\n",
      "Epoch # [10/10], batch # 420 with mini batch accuracy of 75.000% and loss of 0.997\n",
      "Epoch # [10/10], batch # 430 with mini batch accuracy of 71.000% and loss of 0.904\n",
      "Epoch # [10/10], batch # 440 with mini batch accuracy of 71.000% and loss of 1.003\n",
      "Epoch # [10/10], batch # 450 with mini batch accuracy of 68.000% and loss of 1.087\n",
      "Epoch # [10/10], batch # 460 with mini batch accuracy of 73.000% and loss of 1.006\n",
      "Epoch # [10/10], batch # 470 with mini batch accuracy of 72.000% and loss of 1.035\n",
      "Epoch # [10/10], batch # 480 with mini batch accuracy of 75.000% and loss of 0.893\n",
      "Epoch # [10/10], batch # 490 with mini batch accuracy of 65.000% and loss of 1.220\n",
      "Epoch # [10/10], batch # 500 with mini batch accuracy of 66.000% and loss of 1.076\n",
      "Epoch # [10/10] with overall accuracy of 71.168%\n",
      "Test result of epoch [10/10] has accuracy of 57.940%\n"
     ]
    }
   ],
   "source": [
    "fit(10,train_data,test_data,mymodel,loss_fun,opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = [1,3,4]\n",
    "# np.argmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########use fastai to run###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FASTAI INSTALLATION###\n",
    "\n",
    "#conda install -c pytorch -c fastai fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.basic_data import DataBunch\n",
    "# from fastai.train import Learner\n",
    "# from fastai.metrics import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = DataBunch.create(train_cifar,test_cifar,bs=50,path='./fastai/cifar100')\n",
    "# learner = Learner(data,mymodel,loss_func=F.cross_entropy,metrics=[accuracy])\n",
    "# learner.clip=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fit_one_cycle(9,5e-3,wd=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
